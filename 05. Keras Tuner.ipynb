{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98e7f83e",
   "metadata": {},
   "source": [
    "# Keras Tuner\n",
    "https://www.tensorflow.org/tutorials/keras/keras_tuner?hl=ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad2a3d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a82ae2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa13f7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import IPython\n",
    "\n",
    "# !pip install -q -U keras-tuner\n",
    "import keras_tuner as kt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import Dropout, InputLayer\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb33ccff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6182, 10, 4069), (6182,), (1545, 10, 4069), (1545,))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random    \n",
    "random.seed(seed_num)\n",
    "\n",
    "x = np.load('/project/LSH/x_(7727,10,4069).npy')\n",
    "y = np.load('/project/LSH/y_(7727,1).npy')\n",
    "\n",
    "idx = list(range(len(x)))\n",
    "random.shuffle(idx)\n",
    "\n",
    "i = round(x.shape[0]*0.8)\n",
    "X_train, y_train = x[idx[:i],:,:], y[idx[:i]]\n",
    "X_test, y_test = x[idx[i:],:,:], y[idx[i:]]\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7fedb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "    \n",
    "    # Tune the number of units in the first Dense layer\n",
    "    # Choose an optimal value between 32-512\n",
    "    hp_units = hp.Int('units', min_value = 32, max_value = 512, step = 32)\n",
    "    model.add(LSTM(units = hp_units, activation = 'hard_sigmoid', return_sequences=True))\n",
    "    model.add(LSTM(units = hp_units, activation = 'hard_sigmoid', return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units = hp_units, activation = 'hard_sigmoid', return_sequences=True))\n",
    "    model.add(LSTM(units = hp_units, activation = 'hard_sigmoid', return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Tune the learning rate for the optimizer \n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \n",
    "\n",
    "    model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate),\n",
    "                loss = \"binary_crossentropy\", \n",
    "                metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7fb4816",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project my_dir/intro_to_kt/oracle.json\n"
     ]
    }
   ],
   "source": [
    "ep = 500\n",
    "pa = 10\n",
    "early_stop = EarlyStopping(monitor='val_acc', patience=pa, verbose=1, restore_best_weights=True)\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective = 'val_accuracy', \n",
    "                     max_epochs = ep,\n",
    "                     factor = 3,\n",
    "                     directory = 'my_dir',\n",
    "                     project_name = 'intro_to_kt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c84ea63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
    "    def on_train_end(*args, **kwargs):\n",
    "        IPython.display.clear_output(wait = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb21e9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner.search(X_train, y_train, epochs = 10, validation_data = (X_test, y_test), callbacks = [ClearTrainingOutput()])\n",
    "\n",
    "# # Get the optimal hyperparameters\n",
    "# best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "\n",
    "# print(f\"\"\"\n",
    "#         The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "#         layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "#         is {best_hps.get('learning_rate')}.\n",
    "#         \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e900a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.fit(X_train, y_train, epochs = 500, validation_data = (X_test, y_test), callbacks=[early_stop], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60db9b98",
   "metadata": {},
   "source": [
    "## Deeper and Deeper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "db7049e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "    \n",
    "    # Tune the number of units in the first Dense layer\n",
    "    # Choose an optimal value between 32-512\n",
    "    hp_units1 = hp.Int('units1', min_value = 32, max_value = 512, step = 32)\n",
    "    hp_units2 = hp.Int('units2', min_value = 32, max_value = 512, step = 32)\n",
    "    hp_units3 = hp.Int('units3', min_value = 32, max_value = 512, step = 32)\n",
    "    hp_units4 = hp.Int('units4', min_value = 32, max_value = 512, step = 32)\n",
    "    \n",
    "    hp_activ1 = hp.Choice('activation1', values=['relu', 'tanh', 'hard_sigmoid'], default='hard_sigmoid')\n",
    "    hp_activ2 = hp.Choice('activation2', values=['relu', 'tanh', 'hard_sigmoid'], default='hard_sigmoid')\n",
    "    hp_activ3 = hp.Choice('activation3', values=['relu', 'tanh', 'hard_sigmoid'], default='hard_sigmoid')\n",
    "    hp_activ4 = hp.Choice('activation4', values=['relu', 'tanh', 'hard_sigmoid'], default='hard_sigmoid')\n",
    "    \n",
    "    hp_drop1 = hp.Float('dropout1', min_value=0.0,max_value=0.5,default=0.2,step=0.05)\n",
    "    hp_drop2 = hp.Float('dropout2', min_value=0.0,max_value=0.5,default=0.2,step=0.05)\n",
    "    \n",
    "    hp_activ_dense = hp.Choice('dense_activation', values=['relu', 'tanh', 'sigmoid'], default='sigmoid')\n",
    "    #model\n",
    "    model.add(LSTM(units = hp_units1, activation = hp_activ1, return_sequences=True))\n",
    "    model.add(LSTM(units = hp_units2, activation = hp_activ2, return_sequences=True))\n",
    "    model.add(Dropout(rate=hp_drop1))\n",
    "    model.add(LSTM(units = hp_units3, activation = hp_activ3, return_sequences=True))\n",
    "    model.add(LSTM(units = hp_units4, activation = hp_activ4, return_sequences=False))\n",
    "    model.add(Dropout(rate=hp_drop2))\n",
    "    model.add(Dense(1, activation=hp_activ_dense))\n",
    "\n",
    "    # Tune the learning rate for the optimizer \n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \n",
    "\n",
    "    model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate),\n",
    "                loss = \"binary_crossentropy\", \n",
    "                metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0949a7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project my_dir/intro_to_kt/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from my_dir/intro_to_kt/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "ep = 500\n",
    "pa = 10\n",
    "early_stop = EarlyStopping(monitor='val_acc', patience=pa, verbose=1, restore_best_weights=True)\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective = 'val_accuracy', \n",
    "                     max_epochs = ep,\n",
    "                     factor = 3,\n",
    "                     directory = 'my_dir',\n",
    "                     project_name = 'intro_to_kt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f932cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 106 Complete [00h 01m 44s]\n",
      "val_accuracy: 0.7864077687263489\n",
      "\n",
      "Best val_accuracy So Far: 0.798705518245697\n",
      "Total elapsed time: 01h 23m 59s\n",
      "\n",
      "Search: Running Trial #107\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "units             |384               |384               \n",
      "learning_rate     |0.0001            |0.001             \n",
      "activation        |tanh              |hard_sigmoid      \n",
      "dropout           |0                 |0.35              \n",
      "dense_activation  |tanh              |sigmoid           \n",
      "tuner/epochs      |3                 |3                 \n",
      "tuner/initial_e...|0                 |0                 \n",
      "tuner/bracket     |5                 |5                 \n",
      "tuner/round       |0                 |0                 \n",
      "\n",
      "Epoch 1/3\n",
      "194/194 [==============================] - 33s 154ms/step - loss: 0.8279 - accuracy: 0.5718 - val_loss: 0.6372 - val_accuracy: 0.6291\n",
      "Epoch 2/3\n",
      "109/194 [===============>..............] - ETA: 11s - loss: 0.6257 - accuracy: 0.6692"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tuner.search(X_train, y_train, epochs = 10, validation_data = (X_test, y_test), callbacks = [ClearTrainingOutput()])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "        The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "        layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "        is {best_hps.get('learning_rate')}.\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4669b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.fit(X_train, y_train, epochs = 500, validation_data = (X_test, y_test), callbacks=[early_stop], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef671841",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

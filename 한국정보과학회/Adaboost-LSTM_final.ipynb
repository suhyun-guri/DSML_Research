{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import warnings \n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Dropout, LSTM, InputLayer\n",
    "from sklearn.ensemble import VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics \n",
    "from tensorflow import keras\n",
    "import random  \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "seed_num = 42\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '-1'\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "    try:\n",
    "        for i in range(len(gpus)):\n",
    "            tf.config.experimental.set_memory_growth(gpus[i], True)\n",
    "    except RuntimeError as e:\n",
    "        # 프로그램 시작시에 메모리 증가가 설정되어야만 합니다\n",
    "        print(e)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "seed_num = 42\n",
    "random.seed(seed_num)\n",
    "\n",
    "x = np.load('/project/LSH/x_(7727,10,4068).npy')\n",
    "y = np.load('/project/LSH/y_(7727,1).npy')\n",
    "\n",
    "idx = list(range(len(x)))\n",
    "random.shuffle(idx)\n",
    "\n",
    "i = round(x.shape[0]*0.8)\n",
    "X_train, y_train = x[idx[:i],:,:], y[idx[:i]]\n",
    "X_test, y_test = x[idx[i:],:,:], y[idx[i:]]\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    lstm = Sequential()\n",
    "    lstm.add(InputLayer(input_shape=(x.shape[1],x.shape[2])))\n",
    "    lstm.add(LSTM(units=128, activation='hard_sigmoid', return_sequences=True))\n",
    "    lstm.add(LSTM(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "    lstm.add(Dropout(0.2))\n",
    "    lstm.add(LSTM(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "    lstm.add(LSTM(units=32, activation='hard_sigmoid', return_sequences=False))\n",
    "    lstm.add(Dropout(0.2))\n",
    "    lstm.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    lstm.compile(optimizer= keras.optimizers.Adam(learning_rate = 0.001), \n",
    "                 loss = \"binary_crossentropy\", metrics=['acc'])\n",
    "    return lstm\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "class MyKerasClassifier(KerasClassifier):\n",
    "    def fit(self, x, y, sample_weight=None, **kwargs):\n",
    "        y = np.array(y)\n",
    "        if len(y.shape) == 2 and y.shape[1] > 1:\n",
    "            self.classes_ = np.arange(y.shape[1])\n",
    "        elif (len(y.shape) == 2 and y.shape[1] == 1) or len(y.shape) == 1:\n",
    "            self.classes_ = np.unique(y)\n",
    "            y = np.searchsorted(self.classes_, y)\n",
    "        else:\n",
    "            raise ValueError('Invalid shape for y: ' + str(y.shape))\n",
    "        self.n_classes_ = len(self.classes_)\n",
    "        #---------------수정---------------\n",
    "        if sample_weight is not None:\n",
    "            print('sample weight : ', sample_weight)\n",
    "            if sample_weight[0] == 0.00016175994823681658:\n",
    "                print('x, y', x.shape, x.sum().sum())\n",
    "                return super(MyKerasClassifier, self).fit(x, y, **kwargs)\n",
    "            weights = sample_weight / sum(sample_weight)\n",
    "            random_range = [(sum(weights[:i]), sum(weights[:i])+weights[i]) if i!=0 else (0, weights[i]) for i in range(len(weights))]\n",
    "            random_nums = [random.random() for _ in range(len(weights))]\n",
    "            idx_list = []\n",
    "            for i in random_nums:\n",
    "                for j in random_range:\n",
    "                    if j[0] < i <= j[1]:\n",
    "                        idx_list.append(random_range.index(j))\n",
    "                        break\n",
    "            new_x = x[idx_list, :, :]\n",
    "            new_y = y[idx_list]\n",
    "            print(new_x.sum().sum())\n",
    "            print('new_x, new_y', new_x.shape, new_y.shape)\n",
    "            return super(MyKerasClassifier, self).fit(new_x, new_y, **kwargs)\n",
    "        \n",
    "    def predict(self, x, **kwargs):\n",
    "        return super(MyKerasClassifier, self).predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import warnings \n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Dropout, LSTM, InputLayer\n",
    "from sklearn.ensemble import VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics \n",
    "from tensorflow import keras\n",
    "import random  \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "seed_num = 42\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '-1'\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "    try:\n",
    "        for i in range(len(gpus)):\n",
    "            tf.config.experimental.set_memory_growth(gpus[i], True)\n",
    "    except RuntimeError as e:\n",
    "        # 프로그램 시작시에 메모리 증가가 설정되어야만 합니다\n",
    "        print(e)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "seed_num = 42\n",
    "random.seed(seed_num)\n",
    "\n",
    "x = np.load('/project/LSH/x_(7727,10,4068).npy')\n",
    "y = np.load('/project/LSH/y_(7727,1).npy')\n",
    "\n",
    "idx = list(range(len(x)))\n",
    "random.shuffle(idx)\n",
    "\n",
    "i = round(x.shape[0]*0.8)\n",
    "X_train, y_train = x[idx[:i],:,:], y[idx[:i]]\n",
    "X_test, y_test = x[idx[i:],:,:], y[idx[i:]]\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    lstm = Sequential()\n",
    "    lstm.add(InputLayer(input_shape=(x.shape[1],x.shape[2])))\n",
    "    lstm.add(LSTM(units=128, activation='hard_sigmoid', return_sequences=True))\n",
    "    lstm.add(LSTM(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "    lstm.add(Dropout(0.2))\n",
    "    lstm.add(LSTM(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "    lstm.add(LSTM(units=32, activation='hard_sigmoid', return_sequences=False))\n",
    "    lstm.add(Dropout(0.2))\n",
    "    lstm.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    lstm.compile(optimizer= keras.optimizers.Adam(learning_rate = 0.001), \n",
    "                 loss = \"binary_crossentropy\", metrics=['acc'])\n",
    "    return lstm\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import random\n",
    "class MyKerasClassifier(KerasClassifier):\n",
    "    def fit(self, x, y, sample_weight=None, validation_split=0.25, **kwargs):\n",
    "        y = np.array(y)\n",
    "        if len(y.shape) == 2 and y.shape[1] > 1:\n",
    "            self.classes_ = np.arange(y.shape[1])\n",
    "        elif (len(y.shape) == 2 and y.shape[1] == 1) or len(y.shape) == 1:\n",
    "            self.classes_ = np.unique(y)\n",
    "            y = np.searchsorted(self.classes_, y)\n",
    "        else:\n",
    "            raise ValueError('Invalid shape for y: ' + str(y.shape))\n",
    "        self.n_classes_ = len(self.classes_)\n",
    "        #---------------수정---------------\n",
    "        if sample_weight is not None:\n",
    "            print('sample weight : ', sample_weight)\n",
    "            if sample_weight[0] == 0.00016175994823681658:\n",
    "                print('x, y', x.shape, x.sum().sum())\n",
    "                return super(MyKerasClassifier, self).fit(x, y, **kwargs)\n",
    "            print('x sum', x.sum().sum())\n",
    "            \n",
    "            idx = np.arange(len(x))\n",
    "            random.shuffle(idx)\n",
    "            i = int(len(x)*0.75)\n",
    "            train_x, train_y = x[idx[:i],:,:], y[idx[:i]]\n",
    "            val_x, val_y = x[idx[i:],:,:], y[idx[i:]]\n",
    "            \n",
    "            \n",
    "            train_sw, val_sw = sample_weight[idx[:i]], sample_weight[idx[i:]]\n",
    "            train_sw, val_sw = train_sw/sum(train_sw)*len(train_sw), val_sw/sum(val_sw)*len(val_sw)\n",
    "            \n",
    "            weights = val_sw / sum(val_sw)\n",
    "            random_range = [(sum(weights[:i]), sum(weights[:i])+weights[i]) if i!=0 else (0, weights[i]) for i in range(len(weights))]\n",
    "            random_nums = [random.random() for _ in range(len(weights))]\n",
    "            idx_list = []\n",
    "            for i in random_nums:\n",
    "                for j in random_range:\n",
    "                    if j[0] < i <= j[1]:\n",
    "                        idx_list.append(random_range.index(j))\n",
    "                        break\n",
    "            new_val_x = val_x[idx_list, :, :]\n",
    "            new_val_y = val_y[idx_list]\n",
    "            \n",
    "            kwargs['validation_data'] = (new_val_x, new_val_y)\n",
    "            kwargs['sample_weight'] = train_sw\n",
    "            return super(MyKerasClassifier, self).fit(train_x, train_y, **kwargs)\n",
    "        \n",
    "        return super(MyKerasClassifier, self).fit(x, y, **kwargs)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def predict(self, x, **kwargs):\n",
    "        return super(MyKerasClassifier, self).predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost-LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6182, 10, 4068)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7267, 6914,  990, ..., 2575, 3450, 1696])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.arange(7727)\n",
    "random.shuffle(idx)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single LSTM Start\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/50\n",
      "37/37 [==============================] - 6s 81ms/step - loss: 0.6736 - acc: 0.6055 - val_loss: 0.6657 - val_acc: 0.6177\n",
      "Epoch 2/50\n",
      "37/37 [==============================] - 3s 70ms/step - loss: 0.6696 - acc: 0.6100 - val_loss: 0.6509 - val_acc: 0.6177\n",
      "Epoch 3/50\n",
      "37/37 [==============================] - 3s 70ms/step - loss: 0.6045 - acc: 0.6706 - val_loss: 0.5288 - val_acc: 0.7510\n",
      "Epoch 4/50\n",
      "37/37 [==============================] - 3s 70ms/step - loss: 0.4900 - acc: 0.7821 - val_loss: 0.4942 - val_acc: 0.7639\n",
      "Epoch 5/50\n",
      "37/37 [==============================] - 3s 71ms/step - loss: 0.4187 - acc: 0.8261 - val_loss: 0.4894 - val_acc: 0.7743\n",
      "Epoch 6/50\n",
      "37/37 [==============================] - 3s 70ms/step - loss: 0.3760 - acc: 0.8503 - val_loss: 0.5036 - val_acc: 0.7743\n",
      "Epoch 7/50\n",
      "37/37 [==============================] - 3s 71ms/step - loss: 0.3591 - acc: 0.8613 - val_loss: 0.5329 - val_acc: 0.7587\n",
      "Epoch 8/50\n",
      "37/37 [==============================] - 3s 71ms/step - loss: 0.3100 - acc: 0.8865 - val_loss: 0.5534 - val_acc: 0.7762\n",
      "Epoch 9/50\n",
      "37/37 [==============================] - 3s 70ms/step - loss: 0.2800 - acc: 0.8999 - val_loss: 0.6007 - val_acc: 0.7684\n",
      "Epoch 10/50\n",
      "37/37 [==============================] - 3s 71ms/step - loss: 0.2586 - acc: 0.9109 - val_loss: 0.6084 - val_acc: 0.7600\n",
      "Epoch 11/50\n",
      "37/37 [==============================] - 3s 71ms/step - loss: 0.2435 - acc: 0.9176 - val_loss: 0.6325 - val_acc: 0.7542\n",
      "Epoch 12/50\n",
      "37/37 [==============================] - 3s 72ms/step - loss: 0.2243 - acc: 0.9247 - val_loss: 0.6608 - val_acc: 0.7477\n",
      "Epoch 13/50\n",
      "37/37 [==============================] - 3s 70ms/step - loss: 0.2028 - acc: 0.9359 - val_loss: 0.6891 - val_acc: 0.7561\n",
      "Epoch 14/50\n",
      "37/37 [==============================] - 3s 71ms/step - loss: 0.1863 - acc: 0.9439 - val_loss: 0.7386 - val_acc: 0.7529\n",
      "Epoch 15/50\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1758 - acc: 0.9487Restoring model weights from the end of the best epoch: 5.\n",
      "37/37 [==============================] - 3s 70ms/step - loss: 0.1758 - acc: 0.9487 - val_loss: 0.7440 - val_acc: 0.7406\n",
      "Epoch 00015: early stopping\n",
      "accuracy : 0.7618122977346279, precision : 0.8083700440528634, recall : 0.790948275862069, f1 : 0.7995642701525053, roc_auc : 0.7544692756944056\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    print(\"Single LSTM Start\")\n",
    "    model = get_model()\n",
    "    \n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
    "    cb_checkpoint = ModelCheckpoint(filepath='./models/single_lstm.h5', monitor='val_loss',\n",
    "                                    verbose=1, save_best_only=True)\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=128, validation_split=0.25, callbacks=[early_stop, cb_checkpoint])\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    preds[preds>0.5]=1\n",
    "    preds[preds<=0.5]=0\n",
    "    precision = precision_score(y_test, preds)\n",
    "    recall = recall_score(y_test, preds)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    roc_auc = roc_auc_score(y_test, preds)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "\n",
    "    print(f'accuracy : {acc}, precision : {precision}, recall : {recall}, f1 : {f1}, roc_auc : {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost LSTM Start\n",
      "sample weight :  [0.00016176 0.00016176 0.00016176 ... 0.00016176 0.00016176 0.00016176]\n",
      "x, y (6182, 10, 4068) 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/300\n",
      "1/1 [==============================] - 27s 27s/step - loss: 0.6860 - acc: 0.5528 - val_loss: 0.6703 - val_acc: 0.6177\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6799 - acc: 0.5796 - val_loss: 0.6663 - val_acc: 0.6177\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6785 - acc: 0.5936 - val_loss: 0.6652 - val_acc: 0.6177\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6767 - acc: 0.6085 - val_loss: 0.6657 - val_acc: 0.6177\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6808 - acc: 0.6098 - val_loss: 0.6664 - val_acc: 0.6177\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6788 - acc: 0.6100 - val_loss: 0.6667 - val_acc: 0.6177\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6761 - acc: 0.6091 - val_loss: 0.6664 - val_acc: 0.6177\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6768 - acc: 0.6061 - val_loss: 0.6658 - val_acc: 0.6177\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6752 - acc: 0.6107 - val_loss: 0.6654 - val_acc: 0.6177\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6746 - acc: 0.6059 - val_loss: 0.6651 - val_acc: 0.6177\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6748 - acc: 0.6089 - val_loss: 0.6651 - val_acc: 0.6177\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6741 - acc: 0.6081 - val_loss: 0.6654 - val_acc: 0.6177\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6734 - acc: 0.6042 - val_loss: 0.6657 - val_acc: 0.6177\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6725 - acc: 0.6059 - val_loss: 0.6660 - val_acc: 0.6177\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6769 - acc: 0.6053 - val_loss: 0.6662 - val_acc: 0.6177\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6764 - acc: 0.5947 - val_loss: 0.6662 - val_acc: 0.6177\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6748 - acc: 0.6003 - val_loss: 0.6661 - val_acc: 0.6177\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6741 - acc: 0.6022 - val_loss: 0.6659 - val_acc: 0.6177\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6760 - acc: 0.5973 - val_loss: 0.6656 - val_acc: 0.6177\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6697 - acc: 0.6063 - val_loss: 0.6654 - val_acc: 0.6177\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6731 - acc: 0.6070 - val_loss: 0.6652 - val_acc: 0.6177\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6728 - acc: 0.6076 - val_loss: 0.6650 - val_acc: 0.6177\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6750 - acc: 0.6076 - val_loss: 0.6650 - val_acc: 0.6177\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6717 - acc: 0.6079 - val_loss: 0.6649 - val_acc: 0.6177\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6741 - acc: 0.6098 - val_loss: 0.6649 - val_acc: 0.6177\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6743 - acc: 0.6109 - val_loss: 0.6649 - val_acc: 0.6177\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6712 - acc: 0.6102 - val_loss: 0.6649 - val_acc: 0.6177\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6731 - acc: 0.6124 - val_loss: 0.6648 - val_acc: 0.6177\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6750 - acc: 0.6102 - val_loss: 0.6648 - val_acc: 0.6177\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6721 - acc: 0.6107 - val_loss: 0.6647 - val_acc: 0.6177\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6714 - acc: 0.6085 - val_loss: 0.6647 - val_acc: 0.6177\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6709 - acc: 0.6122 - val_loss: 0.6647 - val_acc: 0.6177\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6700 - acc: 0.6098 - val_loss: 0.6647 - val_acc: 0.6177\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6718 - acc: 0.6087 - val_loss: 0.6647 - val_acc: 0.6177\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6725 - acc: 0.6081 - val_loss: 0.6647 - val_acc: 0.6177\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6716 - acc: 0.6098 - val_loss: 0.6647 - val_acc: 0.6177\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6684 - acc: 0.6102 - val_loss: 0.6646 - val_acc: 0.6177\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6704 - acc: 0.6115 - val_loss: 0.6645 - val_acc: 0.6177\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6694 - acc: 0.6100 - val_loss: 0.6643 - val_acc: 0.6177\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6717 - acc: 0.6094 - val_loss: 0.6642 - val_acc: 0.6177\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6695 - acc: 0.6115 - val_loss: 0.6640 - val_acc: 0.6177\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6723 - acc: 0.6100 - val_loss: 0.6637 - val_acc: 0.6177\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6697 - acc: 0.6087 - val_loss: 0.6634 - val_acc: 0.6177\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6684 - acc: 0.6104 - val_loss: 0.6631 - val_acc: 0.6177\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6672 - acc: 0.6117 - val_loss: 0.6627 - val_acc: 0.6177\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6700 - acc: 0.6107 - val_loss: 0.6623 - val_acc: 0.6177\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6683 - acc: 0.6111 - val_loss: 0.6618 - val_acc: 0.6177\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6695 - acc: 0.6115 - val_loss: 0.6612 - val_acc: 0.6177\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6672 - acc: 0.6124 - val_loss: 0.6605 - val_acc: 0.6177\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6665 - acc: 0.6107 - val_loss: 0.6596 - val_acc: 0.6177\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6655 - acc: 0.6115 - val_loss: 0.6585 - val_acc: 0.6177\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6628 - acc: 0.6113 - val_loss: 0.6571 - val_acc: 0.6177\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6635 - acc: 0.6109 - val_loss: 0.6555 - val_acc: 0.6177\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6608 - acc: 0.6132 - val_loss: 0.6536 - val_acc: 0.6177\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6606 - acc: 0.6126 - val_loss: 0.6513 - val_acc: 0.6177\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6563 - acc: 0.6139 - val_loss: 0.6486 - val_acc: 0.6177\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6536 - acc: 0.6113 - val_loss: 0.6455 - val_acc: 0.6177\n",
      "Epoch 58/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.6510 - acc: 0.6130 - val_loss: 0.6419 - val_acc: 0.6177\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6484 - acc: 0.6119 - val_loss: 0.6378 - val_acc: 0.6177\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6409 - acc: 0.6193 - val_loss: 0.6333 - val_acc: 0.6177\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6377 - acc: 0.6182 - val_loss: 0.6284 - val_acc: 0.6177\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6313 - acc: 0.6221 - val_loss: 0.6230 - val_acc: 0.6177\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6276 - acc: 0.6251 - val_loss: 0.6172 - val_acc: 0.6177\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6208 - acc: 0.6322 - val_loss: 0.6110 - val_acc: 0.6177\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6159 - acc: 0.6346 - val_loss: 0.6042 - val_acc: 0.6177\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6061 - acc: 0.6560 - val_loss: 0.5970 - val_acc: 0.6772\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.5973 - acc: 0.6769 - val_loss: 0.5892 - val_acc: 0.7076\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5882 - acc: 0.6941 - val_loss: 0.5807 - val_acc: 0.7186\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.5768 - acc: 0.7049 - val_loss: 0.5713 - val_acc: 0.7296\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.5689 - acc: 0.7245 - val_loss: 0.5616 - val_acc: 0.7354\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.5569 - acc: 0.7377 - val_loss: 0.5531 - val_acc: 0.7374\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.5484 - acc: 0.7401 - val_loss: 0.5429 - val_acc: 0.7464\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.5372 - acc: 0.7565 - val_loss: 0.5351 - val_acc: 0.7458\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.5222 - acc: 0.7701 - val_loss: 0.5301 - val_acc: 0.7451\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.5089 - acc: 0.7735 - val_loss: 0.5221 - val_acc: 0.7574\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4983 - acc: 0.7871 - val_loss: 0.5186 - val_acc: 0.7523\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4879 - acc: 0.7893 - val_loss: 0.5140 - val_acc: 0.7594\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4772 - acc: 0.7942 - val_loss: 0.5094 - val_acc: 0.7594\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4699 - acc: 0.8005 - val_loss: 0.5134 - val_acc: 0.7568\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4605 - acc: 0.8061 - val_loss: 0.5070 - val_acc: 0.7658\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4486 - acc: 0.8160 - val_loss: 0.5098 - val_acc: 0.7607\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4380 - acc: 0.8238 - val_loss: 0.5177 - val_acc: 0.7587\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4312 - acc: 0.8289 - val_loss: 0.5142 - val_acc: 0.7697\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4290 - acc: 0.8305 - val_loss: 0.5247 - val_acc: 0.7607\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4189 - acc: 0.8328 - val_loss: 0.5210 - val_acc: 0.7710\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4054 - acc: 0.8430 - val_loss: 0.5218 - val_acc: 0.7671\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4031 - acc: 0.8432 - val_loss: 0.5316 - val_acc: 0.7607\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3974 - acc: 0.8447 - val_loss: 0.5259 - val_acc: 0.7710\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3864 - acc: 0.8531 - val_loss: 0.5277 - val_acc: 0.7665\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3850 - acc: 0.8572 - val_loss: 0.5339 - val_acc: 0.7658\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3789 - acc: 0.8570 - val_loss: 0.5313 - val_acc: 0.7678\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3715 - acc: 0.8637 - val_loss: 0.5334 - val_acc: 0.7665\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3632 - acc: 0.8712 - val_loss: 0.5405 - val_acc: 0.7613\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3597 - acc: 0.8682 - val_loss: 0.5384 - val_acc: 0.7626\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3530 - acc: 0.8766 - val_loss: 0.5413 - val_acc: 0.7671\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3478 - acc: 0.8788 - val_loss: 0.5466 - val_acc: 0.7639\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3418 - acc: 0.8809 - val_loss: 0.5488 - val_acc: 0.7646\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3363 - acc: 0.8855 - val_loss: 0.5533 - val_acc: 0.7633\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3316 - acc: 0.8872 - val_loss: 0.5588 - val_acc: 0.7639\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3263 - acc: 0.8878 - val_loss: 0.5629 - val_acc: 0.7607\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3236 - acc: 0.8945 - val_loss: 0.5692 - val_acc: 0.7626\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3141 - acc: 0.8945 - val_loss: 0.5719 - val_acc: 0.7594\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3100 - acc: 0.8958 - val_loss: 0.5772 - val_acc: 0.7574\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3105 - acc: 0.9021 - val_loss: 0.5851 - val_acc: 0.7613\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3053 - acc: 0.8993 - val_loss: 0.5867 - val_acc: 0.7555\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3035 - acc: 0.9031 - val_loss: 0.5882 - val_acc: 0.7639\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2923 - acc: 0.9077 - val_loss: 0.5933 - val_acc: 0.7620\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2933 - acc: 0.9075 - val_loss: 0.5985 - val_acc: 0.7555\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2913 - acc: 0.9083 - val_loss: 0.5986 - val_acc: 0.7652\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2807 - acc: 0.9124 - val_loss: 0.6016 - val_acc: 0.7633\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2805 - acc: 0.9144 - val_loss: 0.6099 - val_acc: 0.7549\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2806 - acc: 0.9146 - val_loss: 0.6102 - val_acc: 0.7658\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2757 - acc: 0.9144 - val_loss: 0.6110 - val_acc: 0.7639\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2678 - acc: 0.9200 - val_loss: 0.6195 - val_acc: 0.7568\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2667 - acc: 0.9191 - val_loss: 0.6202 - val_acc: 0.7646\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2603 - acc: 0.9182 - val_loss: 0.6207 - val_acc: 0.7607\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2564 - acc: 0.9262 - val_loss: 0.6290 - val_acc: 0.7523\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2587 - acc: 0.9226 - val_loss: 0.6312 - val_acc: 0.7626\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2550 - acc: 0.9236 - val_loss: 0.6311 - val_acc: 0.7600\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2468 - acc: 0.9292 - val_loss: 0.6391 - val_acc: 0.7529\n",
      "Epoch 121/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step - loss: 0.2494 - acc: 0.9308 - val_loss: 0.6405 - val_acc: 0.7607\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2451 - acc: 0.9305 - val_loss: 0.6436 - val_acc: 0.7555\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2430 - acc: 0.9316 - val_loss: 0.6523 - val_acc: 0.7484\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2438 - acc: 0.9325 - val_loss: 0.6539 - val_acc: 0.7555\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2392 - acc: 0.9340 - val_loss: 0.6583 - val_acc: 0.7536\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2410 - acc: 0.9323 - val_loss: 0.6669 - val_acc: 0.7484\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2388 - acc: 0.9340 - val_loss: 0.6665 - val_acc: 0.7549\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2339 - acc: 0.9359 - val_loss: 0.6712 - val_acc: 0.7529\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2283 - acc: 0.9366 - val_loss: 0.6762 - val_acc: 0.7497\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2315 - acc: 0.9357Restoring model weights from the end of the best epoch: 80.\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2315 - acc: 0.9357 - val_loss: 0.6775 - val_acc: 0.7523\n",
      "Epoch 00130: early stopping\n",
      "sample weight :  [1.61176578e-04 1.37281087e-04 7.09629689e-05 ... 7.01470277e-05\n",
      " 6.87722046e-05 1.06704776e-04]\n",
      "x sum 1644947.0\n",
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/300\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.7184 - acc: 0.5893 - val_loss: 0.6941 - val_acc: 0.6195\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7047 - acc: 0.5821 - val_loss: 0.6910 - val_acc: 0.6195\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7005 - acc: 0.5407 - val_loss: 0.6907 - val_acc: 0.6195\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7036 - acc: 0.5154 - val_loss: 0.6922 - val_acc: 0.3805\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7028 - acc: 0.4869 - val_loss: 0.6941 - val_acc: 0.3805\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7084 - acc: 0.4513 - val_loss: 0.6952 - val_acc: 0.3805\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7066 - acc: 0.4533 - val_loss: 0.6951 - val_acc: 0.3805\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7031 - acc: 0.4676 - val_loss: 0.6943 - val_acc: 0.3805\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7002 - acc: 0.4610 - val_loss: 0.6931 - val_acc: 0.3805\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7042 - acc: 0.4694 - val_loss: 0.6920 - val_acc: 0.3805\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7025 - acc: 0.4866 - val_loss: 0.6912 - val_acc: 0.3805\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6982 - acc: 0.5027 - val_loss: 0.6907 - val_acc: 0.6195\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7034 - acc: 0.5027 - val_loss: 0.6905 - val_acc: 0.6195\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6995 - acc: 0.5174 - val_loss: 0.6905 - val_acc: 0.6195\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6979 - acc: 0.5372 - val_loss: 0.6906 - val_acc: 0.6195\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6973 - acc: 0.5413 - val_loss: 0.6907 - val_acc: 0.6195\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7029 - acc: 0.5341 - val_loss: 0.6907 - val_acc: 0.6195\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6951 - acc: 0.5493 - val_loss: 0.6906 - val_acc: 0.6195\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7000 - acc: 0.5470 - val_loss: 0.6906 - val_acc: 0.6195\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7028 - acc: 0.5217 - val_loss: 0.6905 - val_acc: 0.6195\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6975 - acc: 0.5286 - val_loss: 0.6905 - val_acc: 0.6195\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7000 - acc: 0.5145 - val_loss: 0.6906 - val_acc: 0.6195\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7020 - acc: 0.5039 - val_loss: 0.6907 - val_acc: 0.6195\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6981 - acc: 0.5119 - val_loss: 0.6908 - val_acc: 0.6195\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6957 - acc: 0.5174 - val_loss: 0.6910 - val_acc: 0.6195\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6983 - acc: 0.5013 - val_loss: 0.6912 - val_acc: 0.4202\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6977 - acc: 0.5079 - val_loss: 0.6913 - val_acc: 0.3805\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7019 - acc: 0.4904 - val_loss: 0.6913 - val_acc: 0.3805\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6998 - acc: 0.4958 - val_loss: 0.6913 - val_acc: 0.3805\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7003 - acc: 0.4904 - val_loss: 0.6912 - val_acc: 0.3805\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7034 - acc: 0.4927 - val_loss: 0.6911 - val_acc: 0.6195\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6963 - acc: 0.5093 - val_loss: 0.6909 - val_acc: 0.6195\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6972 - acc: 0.5108 - val_loss: 0.6908 - val_acc: 0.6195\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6998 - acc: 0.5122 - val_loss: 0.6907 - val_acc: 0.6195\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7003 - acc: 0.5180 - val_loss: 0.6906 - val_acc: 0.6195\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6968 - acc: 0.5211 - val_loss: 0.6906 - val_acc: 0.6195\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7003 - acc: 0.5191 - val_loss: 0.6906 - val_acc: 0.6195\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6966 - acc: 0.5335 - val_loss: 0.6905 - val_acc: 0.6195\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6991 - acc: 0.5217 - val_loss: 0.6905 - val_acc: 0.6195\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6983 - acc: 0.5229 - val_loss: 0.6905 - val_acc: 0.6195\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6971 - acc: 0.5309 - val_loss: 0.6906 - val_acc: 0.6195\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6982 - acc: 0.5162 - val_loss: 0.6906 - val_acc: 0.6195\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6992 - acc: 0.5157 - val_loss: 0.6906 - val_acc: 0.6195\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6962 - acc: 0.5148 - val_loss: 0.6907 - val_acc: 0.6195\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6964 - acc: 0.5165 - val_loss: 0.6907 - val_acc: 0.6195\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6979 - acc: 0.5065 - val_loss: 0.6908 - val_acc: 0.6195\n",
      "Epoch 47/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.6959 - acc: 0.5186 - val_loss: 0.6908 - val_acc: 0.6195\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6994 - acc: 0.5091 - val_loss: 0.6908 - val_acc: 0.6195\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6973 - acc: 0.5007 - val_loss: 0.6908 - val_acc: 0.6195\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6975 - acc: 0.5088 - val_loss: 0.6908 - val_acc: 0.6195\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6978 - acc: 0.5001 - val_loss: 0.6908 - val_acc: 0.6195\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6949 - acc: 0.5139 - val_loss: 0.6907 - val_acc: 0.6195\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6963 - acc: 0.5171 - val_loss: 0.6907 - val_acc: 0.6195\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6972 - acc: 0.5280 - val_loss: 0.6906 - val_acc: 0.6195\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6990 - acc: 0.5234 - val_loss: 0.6906 - val_acc: 0.6195\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6974 - acc: 0.5099 - val_loss: 0.6906 - val_acc: 0.6195\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6947 - acc: 0.5209 - val_loss: 0.6905 - val_acc: 0.6195\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6941 - acc: 0.5352 - val_loss: 0.6905 - val_acc: 0.6195\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6957 - acc: 0.5272 - val_loss: 0.6906 - val_acc: 0.6195\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6965 - acc: 0.5168 - val_loss: 0.6906 - val_acc: 0.6195\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6972 - acc: 0.5203 - val_loss: 0.6906 - val_acc: 0.6195\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6939 - acc: 0.5165 - val_loss: 0.6906 - val_acc: 0.6195\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6978 - acc: 0.5154 - val_loss: 0.6906 - val_acc: 0.6195\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6992 - acc: 0.5234 - val_loss: 0.6906 - val_acc: 0.6195\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6972 - acc: 0.5116 - val_loss: 0.6906 - val_acc: 0.6195\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6961 - acc: 0.5160 - val_loss: 0.6906 - val_acc: 0.6195\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6960 - acc: 0.5114 - val_loss: 0.6905 - val_acc: 0.6195\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6976 - acc: 0.5148 - val_loss: 0.6905 - val_acc: 0.6195\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7007 - acc: 0.5076 - val_loss: 0.6904 - val_acc: 0.6195\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6958 - acc: 0.5324 - val_loss: 0.6904 - val_acc: 0.6195\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6969 - acc: 0.5137 - val_loss: 0.6904 - val_acc: 0.6195\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6932 - acc: 0.5335 - val_loss: 0.6903 - val_acc: 0.6195\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6922 - acc: 0.5410 - val_loss: 0.6903 - val_acc: 0.6195\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6951 - acc: 0.5303 - val_loss: 0.6902 - val_acc: 0.6195\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6971 - acc: 0.5309 - val_loss: 0.6902 - val_acc: 0.6195\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=50, verbose=1, restore_best_weights=True)\n",
    "#     cb_checkpoint = ModelCheckpoint(filepath='./models/adaboost_lstm.h5', monitor='val_acc',\n",
    "#                                     verbose=1, save_best_only=True)\n",
    "    base_estimator = MyKerasClassifier(build_fn=get_model, epochs=300, batch_size=10000,\n",
    "                                       validation_split=0.25, callbacks=[early_stop])\n",
    "#     base_estimator = MyKerasClassifier(build_fn=get_model, epochs=50, batch_size=128, validation_split=0.25)\n",
    "\n",
    "    boosted_classifier = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=5, random_state=42, learning_rate=1)\n",
    "    \n",
    "    print(\"Adaboost LSTM Start\")\n",
    "    boosted_classifier.fit(X_train, y_train)\n",
    "    preds = boosted_classifier.predict(X_test)\n",
    "\n",
    "    precision = precision_score(y_test, preds)\n",
    "    recall = recall_score(y_test, preds)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    roc_auc = roc_auc_score(y_test, preds)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "\n",
    "    print(f'Adaboost accuracy : {acc}, precision : {precision}, recall : {recall}, f1 : {f1}, roc_auc : {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.21392679, 0.7860732 ],\n",
       "        [0.1088379 , 0.8911621 ],\n",
       "        [0.10452993, 0.8954701 ],\n",
       "        ...,\n",
       "        [0.13649817, 0.86350185],\n",
       "        [0.13144238, 0.86855763],\n",
       "        [0.34920388, 0.6507961 ]], dtype=float32),\n",
       " array([[0.08810271, 0.9118973 ],\n",
       "        [0.75865805, 0.24134195],\n",
       "        [0.04114843, 0.9588516 ],\n",
       "        ...,\n",
       "        [0.05042784, 0.9495722 ],\n",
       "        [0.04614718, 0.95385283],\n",
       "        [0.10021538, 0.89978456]], dtype=float32),\n",
       " array([[0.04759111, 0.9524089 ],\n",
       "        [0.3257683 , 0.67423177],\n",
       "        [0.02678806, 0.97321194],\n",
       "        ...,\n",
       "        [0.06111384, 0.93888617],\n",
       "        [0.31160578, 0.6883942 ],\n",
       "        [0.21938969, 0.7806103 ]], dtype=float32),\n",
       " array([[0.1002076 , 0.8997924 ],\n",
       "        [0.37915742, 0.62084264],\n",
       "        [0.06648135, 0.93351865],\n",
       "        ...,\n",
       "        [0.11955763, 0.8804423 ],\n",
       "        [0.36769423, 0.6323058 ],\n",
       "        [0.28912866, 0.7108714 ]], dtype=float32),\n",
       " array([[0.14107035, 0.85892963],\n",
       "        [0.39056277, 0.60943717],\n",
       "        [0.10302409, 0.8969759 ],\n",
       "        ...,\n",
       "        [0.16140816, 0.8385919 ],\n",
       "        [0.381266  , 0.618734  ],\n",
       "        [0.31643894, 0.6835611 ]], dtype=float32)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [i for i in boosted_classifier.staged_predict_proba(X_test)]\n",
    "len(a[0])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 0, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = [i for i in boosted_classifier.staged_predict(X_test)]\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7611650485436893,\n",
       " 0.7042071197411003,\n",
       " 0.7294498381877023,\n",
       " 0.7255663430420712,\n",
       " 0.7281553398058253]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[accuracy_score(y_test,i) for i in boosted_classifier.staged_predict(X_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosted_classifier.estimator_errors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- .fit(new_x, new_y) : Adaboost accuracy : 0.7501618122977346, precision : 0.7742914979757085, recall : 0.8243534482758621, f1 : 0.7985386221294364, roc_auc : 0.7314635960990331\n",
    "- .fit(new_x, new_y, **kwargs) : accuracy : 0.7430420711974111, precision : 0.7734294541709578, recall : 0.8092672413793104, f1 : 0.7909426013691417, roc_auc : 0.7263516109651819\n",
    "- .fit(new_x, new_y, sample_weight=sample_weight) : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.7430420711974111, precision : 0.7734294541709578, recall : 0.8092672413793104, f1 : 0.7909426013691417, roc_auc : 0.7263516109651819\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = boosted_classifier.predict(X_test)\n",
    "\n",
    "y_pred_test[y_pred_test>0.5]=1\n",
    "y_pred_test[y_pred_test<=0.5]=0\n",
    "precision = precision_score(y_test, y_pred_test)\n",
    "recall = recall_score(y_test, y_pred_test)\n",
    "f1 = f1_score(y_test, y_pred_test)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_test)\n",
    "acc = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(f'accuracy : {acc}, precision : {precision}, recall : {recall}, f1 : {f1}, roc_auc : {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://4fc3a096-2c5e-42aa-8ed7-0d35dd718c6c/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1f891f3f10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1f881728e0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1f803f70a0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1f803f0760> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://3f4d161d-ae84-45e1-b949-b9e25640463a/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://3f4d161d-ae84-45e1-b949-b9e25640463a/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1df849c0a0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1df83455e0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1dd4262df0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1dd4264610> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://aea38500-abca-43c1-9f03-3d652beb35d0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://aea38500-abca-43c1-9f03-3d652beb35d0/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1d987c3f10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1d7809a6a0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1dd425cf10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1d9871ba60> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://d8af8a47-726a-41d3-be0d-0593228ced6d/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://d8af8a47-726a-41d3-be0d-0593228ced6d/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1d147e3ca0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1d146eb7c0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1d14692280> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1d1469e8e0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://f103218e-4d08-43a8-b7ad-52bd21b3ac7f/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://f103218e-4d08-43a8-b7ad-52bd21b3ac7f/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1ccc6d7070> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1ccc6d7820> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1ccc69d2e0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1ccc662af0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://d990fedd-2b25-49b4-969d-be78df877613/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://d990fedd-2b25-49b4-969d-be78df877613/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1c9878d880> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1c98698340> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1c98665220> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1c98629310> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://e6789a93-f575-469c-93b0-687ba122780c/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://e6789a93-f575-469c-93b0-687ba122780c/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1c6867d940> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1c685861c0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1c6855b520> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1c68518370> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://a414dbcf-accd-4e11-a6f7-61ffa027a2fe/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://a414dbcf-accd-4e11-a6f7-61ffa027a2fe/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1c1071c9a0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1c10624520> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1c105ca190> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1c105cffa0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://878dedc5-d1ab-447a-9325-76d09d8e4c61/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://878dedc5-d1ab-447a-9325-76d09d8e4c61/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1bd060d940> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1bd05191c0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1bd04bab20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1bd05195e0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://9d9a03cd-e0f8-48d3-83b3-5dc29a0c49b3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://9d9a03cd-e0f8-48d3-83b3-5dc29a0c49b3/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1bd0556b80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1b76216700> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1b7617c850> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1b7612b430> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://7f4b6df1-1710-4b94-b145-4df49eb2c1df/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://7f4b6df1-1710-4b94-b145-4df49eb2c1df/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1b4421a9d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1b44123370> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1b4412ae50> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1b440b53d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://6882bb5a-c30f-45d5-a61f-6f5376d4b070/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://6882bb5a-c30f-45d5-a61f-6f5376d4b070/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1b0410a220> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1b0410ab80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1ae47dd460> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1b0415ec10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://928e318e-066e-448b-b9e4-fa49130710d1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://928e318e-066e-448b-b9e4-fa49130710d1/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1adc21b340> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1adc21b160> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1adc12ea00> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1adc0b82e0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://2dec7e68-30b3-412b-8dc2-4baace97d62b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://2dec7e68-30b3-412b-8dc2-4baace97d62b/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1a9c10daf0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1a6c7d82e0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1a6c7d8b20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1a6c741ca0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://d6187611-ec92-4789-a080-27933b012dcc/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://d6187611-ec92-4789-a080-27933b012dcc/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1a4403ef40> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1a9c0a1820> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1a9c081940> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1a24730ee0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://499bb4db-f428-4561-bc88-a98f49c11e17/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://499bb4db-f428-4561-bc88-a98f49c11e17/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1a08115400> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1a08115190> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f19e47e5e50> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f19e476b490> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://12e1fa1c-0401-497a-90da-48a9b4f0b715/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://12e1fa1c-0401-497a-90da-48a9b4f0b715/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f19ac7c1bb0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f19ac6c9550> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f19ac6f2cd0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f19ac694130> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://94288a7f-24f6-4f72-9a74-76d071b01a68/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://94288a7f-24f6-4f72-9a74-76d071b01a68/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f19ac70b370> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f19ac70b100> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f19ac7783a0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f197c53eeb0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://53037386-12b4-4385-b5cb-98f69aed3181/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://53037386-12b4-4385-b5cb-98f69aed3181/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f19ac724fa0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1924f33ca0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f197c68e9a0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1924eb8a30> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://56c8a39b-d555-4124-a103-af0a24f06b89/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://56c8a39b-d555-4124-a103-af0a24f06b89/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1924f74430> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1924f741c0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1915f02eb0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f1915e80040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_49 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_49 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_65 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_65 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_67 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_67 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_68 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_68 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_69 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_69 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_72 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_72 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_73 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_73 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "\n",
    "joblib.dump(boosted_classifier, './models/adaboost_lstm.pkl') \n",
    "reload_model = joblib.load('./models/adaboost_lstm.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.14671701, 0.853283  ],\n",
       "        [0.15134184, 0.84865814],\n",
       "        [0.09548907, 0.9045109 ],\n",
       "        ...,\n",
       "        [0.12648392, 0.8735161 ],\n",
       "        [0.10223823, 0.89776176],\n",
       "        [0.23039924, 0.76960075]], dtype=float32),\n",
       " array([[0.8154902 , 0.18450987],\n",
       "        [0.8216686 , 0.17833138],\n",
       "        [0.0754172 , 0.9245828 ],\n",
       "        ...,\n",
       "        [0.20071441, 0.7992856 ],\n",
       "        [0.06067883, 0.9393212 ],\n",
       "        [0.0725329 , 0.9274671 ]], dtype=float32),\n",
       " array([[0.34155625, 0.6584438 ],\n",
       "        [0.34451336, 0.6554866 ],\n",
       "        [0.03459236, 0.9654076 ],\n",
       "        ...,\n",
       "        [0.08024294, 0.919757  ],\n",
       "        [0.04676704, 0.95323294],\n",
       "        [0.12316583, 0.8768342 ]], dtype=float32),\n",
       " array([[0.5092239 , 0.49077615],\n",
       "        [0.60728794, 0.3927121 ],\n",
       "        [0.16986866, 0.8301313 ],\n",
       "        ...,\n",
       "        [0.2854696 , 0.7145304 ],\n",
       "        [0.20876725, 0.79123276],\n",
       "        [0.24563938, 0.7543606 ]], dtype=float32),\n",
       " array([[0.53762466, 0.46237534],\n",
       "        [0.3876752 , 0.61232483],\n",
       "        [0.31962258, 0.6803774 ],\n",
       "        ...,\n",
       "        [0.1786738 , 0.8213262 ],\n",
       "        [0.13316381, 0.8668362 ],\n",
       "        [0.25848332, 0.74151665]], dtype=float32),\n",
       " array([[0.6718085 , 0.32819152],\n",
       "        [0.5533874 , 0.44661257],\n",
       "        [0.4907666 , 0.5092334 ],\n",
       "        ...,\n",
       "        [0.33372712, 0.66627294],\n",
       "        [0.27552   , 0.72448003],\n",
       "        [0.27862334, 0.72137666]], dtype=float32),\n",
       " array([[0.6895289 , 0.3104711 ],\n",
       "        [0.532257  , 0.46774295],\n",
       "        [0.35844734, 0.6415527 ],\n",
       "        ...,\n",
       "        [0.41690388, 0.5830961 ],\n",
       "        [0.22477764, 0.77522236],\n",
       "        [0.33066702, 0.669333  ]], dtype=float32),\n",
       " array([[0.781638  , 0.218362  ],\n",
       "        [0.35055503, 0.649445  ],\n",
       "        [0.2350894 , 0.76491064],\n",
       "        ...,\n",
       "        [0.27061033, 0.72938967],\n",
       "        [0.38543686, 0.61456317],\n",
       "        [0.39992878, 0.6000712 ]], dtype=float32),\n",
       " array([[0.6388767 , 0.3611233 ],\n",
       "        [0.50825036, 0.49174964],\n",
       "        [0.1569146 , 0.8430854 ],\n",
       "        ...,\n",
       "        [0.42381823, 0.57618177],\n",
       "        [0.26027748, 0.73972255],\n",
       "        [0.47262856, 0.52737147]], dtype=float32),\n",
       " array([[0.7226777 , 0.2773223 ],\n",
       "        [0.5956339 , 0.40436608],\n",
       "        [0.27807134, 0.72192866],\n",
       "        ...,\n",
       "        [0.33660552, 0.6633945 ],\n",
       "        [0.20430657, 0.7956934 ],\n",
       "        [0.37866393, 0.62133604]], dtype=float32)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [i for i in boosted_classifier.staged_predict_proba(X_test)]\n",
    "len(a[0])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7682847896440129,\n",
       " 0.6220064724919094,\n",
       " 0.7592233009708738,\n",
       " 0.6517799352750809,\n",
       " 0.7391585760517799,\n",
       " 0.6660194174757281,\n",
       " 0.7249190938511327,\n",
       " 0.6724919093851133,\n",
       " 0.7171521035598706,\n",
       " 0.6964401294498382]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[accuracy_score(y_test,i) for i in boosted_classifier.staged_predict(X_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosted_classifier.estimator_weights_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13636364, 0.18618371, 0.77088202, 0.80480714, 0.13529329])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosted_classifier.estimator_errors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.MyKerasClassifier at 0x7f46dd507910>,\n",
       " <__main__.MyKerasClassifier at 0x7f4773ba2760>,\n",
       " <__main__.MyKerasClassifier at 0x7f4758831640>,\n",
       " <__main__.MyKerasClassifier at 0x7f475b6ee2b0>,\n",
       " <__main__.MyKerasClassifier at 0x7f473e39f100>]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosted_classifier.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosted_classifier.estimator_weights_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19136202, 0.19596451, 0.16152457, 0.14712343, 0.16450197])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosted_classifier.estimator_errors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

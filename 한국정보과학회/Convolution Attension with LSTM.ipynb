{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7318b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tmp = np.load('WISDM.npz', allow_pickle=True)\n",
    "X = tmp['X']\n",
    "X = np.squeeze(X, axis = 1)\n",
    "y_one_hot = tmp['y']\n",
    "folds = tmp['folds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aee0d87e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1313b2fefa9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_physical_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mgpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c50b1fa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "(6144,) (1536,)\n",
      "WARNING:tensorflow:Layer lstm_84 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_85 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_86 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_87 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rnn_inputs (InputLayer)     [(64, 10, 4068, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (64, 10, 1, 10)           40690     \n",
      "                                                                 \n",
      " lambda_28 (Lambda)          (64, 10, 10)              0         \n",
      "                                                                 \n",
      " lstm_84 (LSTM)              (64, 10, 128)             71168     \n",
      "                                                                 \n",
      " lstm_85 (LSTM)              (64, 10, 64)              49408     \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (64, 10, 64)              0         \n",
      "                                                                 \n",
      " lstm_86 (LSTM)              (64, 10, 64)              33024     \n",
      "                                                                 \n",
      " lstm_87 (LSTM)              (64, 10, 32)              12416     \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (64, 10, 32)              0         \n",
      "                                                                 \n",
      " self_attention_18 (SelfAtte  ((64, 320),              1344      \n",
      " ntion)                       (64, 10, 10))                      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (64, 1)                   321       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 208,371\n",
      "Trainable params: 208,371\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      "72/72 [==============================] - 6s 42ms/step - loss: 0.6741 - accuracy: 0.6009 - val_loss: 0.6629 - val_accuracy: 0.6263\n",
      "Epoch 2/300\n",
      "72/72 [==============================] - 3s 35ms/step - loss: 0.6718 - accuracy: 0.6076 - val_loss: 0.6645 - val_accuracy: 0.6263\n",
      "Epoch 3/300\n",
      "72/72 [==============================] - 3s 36ms/step - loss: 0.6397 - accuracy: 0.6313 - val_loss: 0.5819 - val_accuracy: 0.7161\n",
      "Epoch 4/300\n",
      "72/72 [==============================] - 3s 37ms/step - loss: 0.5274 - accuracy: 0.7472 - val_loss: 0.5110 - val_accuracy: 0.7454\n",
      "Epoch 5/300\n",
      "72/72 [==============================] - 3s 35ms/step - loss: 0.4453 - accuracy: 0.8060 - val_loss: 0.5054 - val_accuracy: 0.7624\n",
      "Epoch 6/300\n",
      "72/72 [==============================] - 3s 35ms/step - loss: 0.4033 - accuracy: 0.8320 - val_loss: 0.5238 - val_accuracy: 0.7572\n",
      "Epoch 7/300\n",
      "72/72 [==============================] - 3s 37ms/step - loss: 0.3633 - accuracy: 0.8518 - val_loss: 0.5660 - val_accuracy: 0.7559\n",
      "Epoch 8/300\n",
      "72/72 [==============================] - 3s 35ms/step - loss: 0.3394 - accuracy: 0.8655 - val_loss: 0.5719 - val_accuracy: 0.7643\n",
      "Epoch 9/300\n",
      "72/72 [==============================] - 3s 35ms/step - loss: 0.3162 - accuracy: 0.8774 - val_loss: 0.6141 - val_accuracy: 0.7422\n",
      "Epoch 10/300\n",
      "72/72 [==============================] - 3s 35ms/step - loss: 0.2894 - accuracy: 0.8952 - val_loss: 0.5887 - val_accuracy: 0.7533\n",
      "Epoch 11/300\n",
      "72/72 [==============================] - 3s 35ms/step - loss: 0.2780 - accuracy: 0.8969 - val_loss: 0.6336 - val_accuracy: 0.7520\n",
      "Epoch 12/300\n",
      "72/72 [==============================] - 3s 35ms/step - loss: 0.2572 - accuracy: 0.9104 - val_loss: 0.6469 - val_accuracy: 0.7500\n",
      "Epoch 13/300\n",
      "72/72 [==============================] - 3s 35ms/step - loss: 0.2471 - accuracy: 0.9188 - val_loss: 0.6973 - val_accuracy: 0.7370\n",
      "Epoch 14/300\n",
      "72/72 [==============================] - 3s 35ms/step - loss: 0.2445 - accuracy: 0.9156 - val_loss: 0.6680 - val_accuracy: 0.7474\n",
      "Epoch 15/300\n",
      "72/72 [==============================] - 3s 36ms/step - loss: 0.2226 - accuracy: 0.9295 - val_loss: 0.7275 - val_accuracy: 0.7376\n",
      "******Evaluating TEST set*********\n",
      "[0.7467447916666666]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "import scipy.stats as st\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, GRU, SimpleRNN, Dropout, Conv2D, Lambda, Input, Bidirectional, Flatten\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "from layers import Attention, SelfAttention\n",
    "import keras\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "    try:\n",
    "        for i in range(len(gpus)):\n",
    "            tf.config.experimental.set_memory_growth(gpus[i], True)\n",
    "    except RuntimeError as e:\n",
    "        # 프로그램 시작시에 메모리 증가가 설정되어야만 합니다\n",
    "        print(e)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "def model(x_train, num_labels, LSTM_units, num_conv_filters, batch_size, F, D):\n",
    "    \"\"\"\n",
    "    The proposed model with CNN layer, LSTM RNN layer and self attention layers.\n",
    "    Inputs:\n",
    "    - x_train: required for creating input shape for RNN layer in Keras\n",
    "    - num_labels: number of output classes (int)\n",
    "    - LSTM_units: number of RNN units (int)\n",
    "    - num_conv_filters: number of CNN filters (int)\n",
    "    - batch_size: number of samples to be processed in each batch\n",
    "    - F: the attention length (int)\n",
    "    - D: the length of the output (int) \n",
    "    Returns\n",
    "    - model: A Keras model\n",
    "    \"\"\"\n",
    "    cnn_inputs = Input(shape=(x_train.shape[1], x_train.shape[2], 1), batch_size=batch_size, name='rnn_inputs')\n",
    "    cnn_layer = Conv2D(num_conv_filters, kernel_size = (1, x_train.shape[2]), strides=(1, 1), padding='valid', data_format=\"channels_last\")\n",
    "    cnn_out = cnn_layer(cnn_inputs)\n",
    "\n",
    "    sq_layer = Lambda(lambda x: K.squeeze(x, axis = 2))\n",
    "    sq_layer_out = sq_layer(cnn_out)\n",
    "\n",
    "    rnn_layer = LSTM(units=128, activation='hard_sigmoid', return_sequences=True)(sq_layer_out)\n",
    "    rnn_layer = LSTM(units=64, activation='hard_sigmoid', return_sequences=True)(rnn_layer)\n",
    "    rnn_layer = Dropout(0.2)(rnn_layer)\n",
    "    rnn_layer = LSTM(units=64, activation='hard_sigmoid', return_sequences=True)(rnn_layer)\n",
    "    rnn_layer = LSTM(units=32, activation='hard_sigmoid', return_sequences=True)(rnn_layer)\n",
    "    rnn_layer_output = Dropout(0.2)(rnn_layer)\n",
    "    \n",
    "    encoder_output, attention_weights = SelfAttention(size=F, num_hops=D, use_penalization=False, batch_size = batch_size)(rnn_layer_output)\n",
    "    dense_layer = Dense(num_labels, activation = 'sigmoid')\n",
    "    dense_layer_output = dense_layer(encoder_output)\n",
    "\n",
    "    model = Model(inputs=cnn_inputs, outputs=dense_layer_output)\n",
    "    print (model.summary())\n",
    "\n",
    "    return model\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]= \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '-1'\n",
    "\n",
    "EPOCH = 300\n",
    "BATCH_SIZE = 64\n",
    "LSTM_UNITS = 32\n",
    "CNN_FILTERS = 10\n",
    "NUM_LSTM_LAYERS = 1\n",
    "LEARNING_RATE = 1e-4\n",
    "PATIENCE = 10\n",
    "SEED = 0\n",
    "F = 32\n",
    "D = 10\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(os.path.join(SAVE_DIR)):\n",
    "    os.mkdir(os.path.join(SAVE_DIR))\n",
    "\n",
    "SEED = 0 \n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "x = np.load('/project/LSH/x_(7727,10,4068).npy')\n",
    "y = np.load('/project/LSH/y_(7727,1).npy')\n",
    "\n",
    "idx = list(range(len(x)))\n",
    "random.shuffle(idx)\n",
    "\n",
    "NUM_LABELS = 1\n",
    "avg_acc = []\n",
    "avg_recall = []\n",
    "avg_f1 = []\n",
    "early_stopping_epoch_list = []\n",
    "\n",
    "i = round(x.shape[0]*0.8)\n",
    "X_train, y_train = x[idx[:i],:,:], y[idx[:i]]\n",
    "X_test, y_test = x[idx[i:],:,:], y[idx[i:]]\n",
    "\n",
    "X_train_ = np.expand_dims(X_train, axis = 3)\n",
    "X_test_ = np.expand_dims(X_test, axis = 3)\n",
    "\n",
    "train_trailing_samples =  X_train_.shape[0]%BATCH_SIZE\n",
    "test_trailing_samples =  X_test_.shape[0]%BATCH_SIZE\n",
    "\n",
    "\n",
    "if train_trailing_samples!= 0:\n",
    "    X_train_ = X_train_[0:-train_trailing_samples]\n",
    "    y_train = y_train[0:-train_trailing_samples]\n",
    "if test_trailing_samples!= 0:\n",
    "    X_test_ = X_test_[0:-test_trailing_samples]\n",
    "    y_test = y_test[0:-test_trailing_samples]\n",
    "\n",
    "print (y_train.shape, y_test.shape)   \n",
    "\n",
    "rnn_model = model(x_train = X_train_, num_labels = NUM_LABELS, LSTM_units = LSTM_UNITS, \\\n",
    "    num_conv_filters = CNN_FILTERS, batch_size = BATCH_SIZE, F = F, D= D)\n",
    "\n",
    "model_filename = './models/convLSTM.h5'\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=True), \n",
    "             ModelCheckpoint(filepath=model_filename, monitor = 'val_accuracy', save_weights_only=True, save_best_only=True),]#, LearningRateScheduler()]\n",
    "\n",
    "opt = optimizers.Adam(clipnorm=1.)\n",
    "\n",
    "rnn_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = rnn_model.fit(X_train_, y_train, epochs=EPOCH, batch_size=BATCH_SIZE, verbose=1, callbacks=callbacks, validation_split=0.25)\n",
    "\n",
    "\n",
    "# Evaluate model and predict data on TEST \n",
    "print(\"******Evaluating TEST set*********\")\n",
    "rnn_model.load_weights(model_filename)\n",
    "\n",
    "y_test_predict = rnn_model.predict(X_test_, batch_size = BATCH_SIZE)\n",
    "y_test_predict = np.array(y_test_predict)\n",
    "y_test_predict[y_test_predict>0.5]=1\n",
    "y_test_predict[y_test_predict<=0.5]=0\n",
    "\n",
    "# all_trainable_count = int(np.sum([K.count_params(p) for p in set(rnn_model.trainable_weights)]))\n",
    "\n",
    "# MAE = metrics.mean_absolute_error(y_test, y_test_predict, sample_weight=None, multioutput='uniform_average')\n",
    "\n",
    "acc_fold = accuracy_score(y_test, y_test_predict)\n",
    "avg_acc.append(acc_fold)\n",
    "\n",
    "# recall_fold = recall_score(y_test, y_test_predict)\n",
    "# avg_recall.append(recall_fold)\n",
    "\n",
    "# f1_fold  = f1_score(y_test, y_test_predict)\n",
    "# avg_f1.append(f1_fold)\n",
    "\n",
    "\n",
    "print(avg_acc)\n",
    "\n",
    "\n",
    "# print('Accuracy[{:.4f}] Recall[{:.4f}] F1[{:.4f}] at fold[{}]'.format(acc_fold, recall_fold, f1_fold, i))\n",
    "# print('______________________________________________________')\n",
    "# K.clear_session()\n",
    "\n",
    "# ic_acc = st.t.interval(0.9, len(avg_acc) - 1, loc=np.mean(avg_acc), scale=st.sem(avg_acc))\n",
    "# ic_recall = st.t.interval(0.9, len(avg_recall) - 1, loc=np.mean(avg_recall), scale=st.sem(avg_recall))\n",
    "# ic_f1 = st.t.interval(0.9, len(avg_f1) - 1, loc = np.mean(avg_f1), scale=st.sem(avg_f1))\n",
    "\n",
    "# print('Mean Accuracy[{:.4f}] IC [{:.4f}, {:.4f}]'.format(np.mean(avg_acc), ic_acc[0], ic_acc[1]))\n",
    "# print('Mean Recall[{:.4f}] IC [{:.4f}, {:.4f}]'.format(np.mean(avg_recall), ic_recall[0], ic_recall[1]))\n",
    "# print('Mean F1[{:.4f}] IC [{:.4f}, {:.4f}]'.format(np.mean(avg_f1), ic_f1[0], ic_f1[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e23811",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

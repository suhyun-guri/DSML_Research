{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bb79b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "    try:\n",
    "        for i in range(len(gpus)):\n",
    "            tf.config.experimental.set_memory_growth(gpus[i], True)\n",
    "    except RuntimeError as e:\n",
    "        # 프로그램 시작시에 메모리 증가가 설정되어야만 합니다\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bde59951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436406b6",
   "metadata": {},
   "source": [
    "# Data Load and  Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0357c3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6182, 10, 4068), (6182,), (1545, 10, 4068), (1545,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random  \n",
    "seed_num = 42\n",
    "random.seed(seed_num)\n",
    "\n",
    "x = np.load('/project/LSH/x_(7727,10,4068).npy')\n",
    "y = np.load('/project/LSH/y_(7727,1).npy')\n",
    "\n",
    "idx = list(range(len(x)))\n",
    "random.shuffle(idx)\n",
    "\n",
    "i = round(x.shape[0]*0.8)\n",
    "X_train, y_train = x[idx[:i],:,:], y[idx[:i]]\n",
    "X_test, y_test = x[idx[i:],:,:], y[idx[i:]]\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526b2b0a",
   "metadata": {},
   "source": [
    "# Revised KerasClassifier\n",
    "- (1차) 코드 참고 : https://github.com/veniversum/keras/blob/9a401eb2e184fda7238a6259c1b8b02c645e4e9c/keras/wrappers/scikit_learn.py\n",
    "- (2차) AdaBoost algorithm 참고 : https://www.analyticsvidhya.com/blog/2021/09/adaboost-algorithm-a-complete-guide-for-beginners/\n",
    "  - 이 부분은 hard coding함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f802e9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "293a5e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Wrapper for using the Scikit-Learn API with Keras models.\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import copy\n",
    "import types\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from tensorflow import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils.generic_utils import has_arg\n",
    "from keras.models import Sequential\n",
    "# from keras.layers import BaseWrapper\n",
    "import random\n",
    "\n",
    "class BaseWrapper(object):\n",
    "    def __init__(self, build_fn=None, **sk_params):\n",
    "        self.build_fn = build_fn\n",
    "        self.sk_params = sk_params\n",
    "        self.check_params(sk_params)\n",
    "\n",
    "    def check_params(self, params):\n",
    "        \"\"\"Checks for user typos in `params`.\n",
    "\n",
    "        # Arguments\n",
    "            params: dictionary; the parameters to be checked\n",
    "\n",
    "        # Raises\n",
    "            ValueError: if any member of `params` is not a valid argument.\n",
    "        \"\"\"\n",
    "        legal_params_fns = [Sequential.fit, Sequential.predict,\n",
    "                            Sequential.predict_classes, Sequential.evaluate]\n",
    "        if self.build_fn is None:\n",
    "            legal_params_fns.append(self.__call__)\n",
    "        elif (not isinstance(self.build_fn, types.FunctionType) and\n",
    "              not isinstance(self.build_fn, types.MethodType)):\n",
    "            legal_params_fns.append(self.build_fn.__call__)\n",
    "        else:\n",
    "            legal_params_fns.append(self.build_fn)\n",
    "\n",
    "        for params_name in params:\n",
    "            for fn in legal_params_fns:\n",
    "                if has_arg(fn, params_name):\n",
    "                    break\n",
    "            else:\n",
    "                if params_name != 'nb_epoch':\n",
    "                    raise ValueError(\n",
    "                        '{} is not a legal parameter'.format(params_name))\n",
    "\n",
    "    def get_params(self, **params):\n",
    "        \"\"\"Gets parameters for this estimator.\n",
    "\n",
    "        # Arguments\n",
    "            **params: ignored (exists for API compatibility).\n",
    "\n",
    "        # Returns\n",
    "            Dictionary of parameter names mapped to their values.\n",
    "        \"\"\"\n",
    "        res = copy.deepcopy(self.sk_params)\n",
    "        res.update({'build_fn': self.build_fn})\n",
    "        return res\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        \"\"\"Sets the parameters of this estimator.\n",
    "\n",
    "        # Arguments\n",
    "            **params: Dictionary of parameter names mapped to their values.\n",
    "\n",
    "        # Returns\n",
    "            self\n",
    "        \"\"\"\n",
    "        self.check_params(params)\n",
    "        self.sk_params.update(params)\n",
    "        return self\n",
    "\n",
    "    def fit(self, x, y, **kwargs):\n",
    "        \"\"\"Constructs a new model with `build_fn` & fit the model to `(x, y)`.\n",
    "\n",
    "        # Arguments\n",
    "            x : array-like, shape `(n_samples, n_features)`\n",
    "                Training samples where `n_samples` is the number of samples\n",
    "                and `n_features` is the number of features.\n",
    "            y : array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n",
    "                True labels for `x`.\n",
    "            **kwargs: dictionary arguments\n",
    "                Legal arguments are the arguments of `Sequential.fit`\n",
    "\n",
    "        # Returns\n",
    "            history : object\n",
    "                details about the training history at each epoch.\n",
    "        \"\"\"\n",
    "        if self.build_fn is None:\n",
    "            self.model = self.__call__(**self.filter_sk_params(self.__call__))\n",
    "        elif (not isinstance(self.build_fn, types.FunctionType) and\n",
    "              not isinstance(self.build_fn, types.MethodType)):\n",
    "            self.model = self.build_fn(\n",
    "                **self.filter_sk_params(self.build_fn.__call__))\n",
    "        else:\n",
    "            self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
    "\n",
    "        loss_name = self.model.loss\n",
    "        if hasattr(loss_name, '__name__'):\n",
    "            loss_name = loss_name.__name__\n",
    "        if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:\n",
    "            y = to_categorical(y)\n",
    "\n",
    "        fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n",
    "        fit_args.update(kwargs)\n",
    "\n",
    "        history = self.model.fit(x, y, **fit_args)\n",
    "\n",
    "        return history\n",
    "\n",
    "    def filter_sk_params(self, fn, override=None):\n",
    "        \"\"\"Filters `sk_params` and returns those in `fn`'s arguments.\n",
    "\n",
    "        # Arguments\n",
    "            fn : arbitrary function\n",
    "            override: dictionary, values to override `sk_params`\n",
    "\n",
    "        # Returns\n",
    "            res : dictionary containing variables\n",
    "                in both `sk_params` and `fn`'s arguments.\n",
    "        \"\"\"\n",
    "        override = override or {}\n",
    "        res = {}\n",
    "        for name, value in self.sk_params.items():\n",
    "            if has_arg(fn, name):\n",
    "                res.update({name: value})\n",
    "        res.update(override)\n",
    "        return res\n",
    "\n",
    "\n",
    "class KerasClassifier(BaseWrapper):\n",
    "    \"\"\"Implementation of the scikit-learn classifier API for Keras.\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, x, y, sample_weight=None, **kwargs):\n",
    "        \"\"\"Constructs a new model with `build_fn` & fit the model to `(x, y)`.\n",
    "\n",
    "        # Arguments\n",
    "            x : array-like, shape `(n_samples, n_features)`\n",
    "                Training samples where `n_samples` is the number of samples\n",
    "                and `n_features` is the number of features.\n",
    "            y : array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n",
    "                True labels for `x`.\n",
    "            **kwargs: dictionary arguments\n",
    "                Legal arguments are the arguments of `Sequential.fit`\n",
    "\n",
    "        # Returns\n",
    "            history : object\n",
    "                details about the training history at each epoch.\n",
    "\n",
    "        # Raises\n",
    "            ValueError: In case of invalid shape for `y` argument.\n",
    "        \"\"\"\n",
    "        y = np.array(y)\n",
    "        if len(y.shape) == 2 and y.shape[1] > 1:\n",
    "            self.classes_ = np.arange(y.shape[1])\n",
    "        elif (len(y.shape) == 2 and y.shape[1] == 1) or len(y.shape) == 1:\n",
    "            self.classes_ = np.unique(y)\n",
    "            y = np.searchsorted(self.classes_, y)\n",
    "        else:\n",
    "            raise ValueError('Invalid shape for y: ' + str(y.shape))\n",
    "        self.n_classes_ = len(self.classes_)\n",
    "        if sample_weight is not None:\n",
    "            #-----수정부분-----\n",
    "            weights = list(map(lambda x:x/sum(sample_weight), sample_weight))\n",
    "            random_range = [(sum(weights[:i]), sum(weights[:i])+weights[i]) if i!=0 else (0, weights[i]) for i in range(len(weights))]\n",
    "            random_nums = [random.uniform(0,1) for _ in range(len(weights))]\n",
    "            idx_list = []\n",
    "            for i in random_nums:\n",
    "                for j in random_range:\n",
    "                    if j[0] < i <= j[1]:\n",
    "                        idx_list.append(random_range.index(j))\n",
    "                        break\n",
    "            new_x = x[idx_list, :, :]\n",
    "            new_y = y[idx_list]\n",
    "            print(len(set(idx_list)))\n",
    "            #----------------\n",
    "            kwargs['sample_weight'] = sample_weight\n",
    "        return super(KerasClassifier, self).fit(new_x, new_y, **kwargs)\n",
    "#             kwargs['sample_weight'] = sample_weight\n",
    "#         return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
    "\n",
    "    def predict(self, x, **kwargs):\n",
    "        \"\"\"Returns the class predictions for the given test data.\n",
    "\n",
    "        # Arguments\n",
    "            x: array-like, shape `(n_samples, n_features)`\n",
    "                Test samples where `n_samples` is the number of samples\n",
    "                and `n_features` is the number of features.\n",
    "            **kwargs: dictionary arguments\n",
    "                Legal arguments are the arguments\n",
    "                of `Sequential.predict_classes`.\n",
    "\n",
    "        # Returns\n",
    "            preds: array-like, shape `(n_samples,)`\n",
    "                Class predictions.\n",
    "        \"\"\"\n",
    "        kwargs = self.filter_sk_params(Sequential.predict_classes, kwargs)\n",
    "        classes = self.model.predict_classes(x, **kwargs)\n",
    "        return self.classes_[classes]\n",
    "\n",
    "    def predict_proba(self, x, **kwargs):\n",
    "        \"\"\"Returns class probability estimates for the given test data.\n",
    "\n",
    "        # Arguments\n",
    "            x: array-like, shape `(n_samples, n_features)`\n",
    "                Test samples where `n_samples` is the number of samples\n",
    "                and `n_features` is the number of features.\n",
    "            **kwargs: dictionary arguments\n",
    "                Legal arguments are the arguments\n",
    "                of `Sequential.predict_classes`.\n",
    "\n",
    "        # Returns\n",
    "            proba: array-like, shape `(n_samples, n_outputs)`\n",
    "                Class probability estimates.\n",
    "                In the case of binary classification,\n",
    "                to match the scikit-learn API,\n",
    "                will return an array of shape `(n_samples, 2)`\n",
    "                (instead of `(n_sample, 1)` as in Keras).\n",
    "        \"\"\"\n",
    "        kwargs = self.filter_sk_params(Sequential.predict_proba, kwargs)\n",
    "        probs = self.model.predict_proba(x, **kwargs)\n",
    "\n",
    "        # check if binary classification\n",
    "        if probs.shape[1] == 1:\n",
    "            # first column is probability of class 0 and second is of class 1\n",
    "            probs = np.hstack([1 - probs, probs])\n",
    "        return probs\n",
    "\n",
    "    def score(self, x, y, **kwargs):\n",
    "        \"\"\"Returns the mean accuracy on the given test data and labels.\n",
    "\n",
    "        # Arguments\n",
    "            x: array-like, shape `(n_samples, n_features)`\n",
    "                Test samples where `n_samples` is the number of samples\n",
    "                and `n_features` is the number of features.\n",
    "            y: array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n",
    "                True labels for `x`.\n",
    "            **kwargs: dictionary arguments\n",
    "                Legal arguments are the arguments of `Sequential.evaluate`.\n",
    "\n",
    "        # Returns\n",
    "            score: float\n",
    "                Mean accuracy of predictions on `x` wrt. `y`.\n",
    "\n",
    "        # Raises\n",
    "            ValueError: If the underlying model isn't configured to\n",
    "                compute accuracy. You should pass `metrics=[\"accuracy\"]` to\n",
    "                the `.compile()` method of the model.\n",
    "        \"\"\"\n",
    "        y = np.searchsorted(self.classes_, y)\n",
    "        kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n",
    "\n",
    "        loss_name = self.model.loss\n",
    "        if hasattr(loss_name, '__name__'):\n",
    "            loss_name = loss_name.__name__\n",
    "        if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:\n",
    "            y = to_categorical(y)\n",
    "\n",
    "        outputs = self.model.evaluate(x, y, **kwargs)\n",
    "        if not isinstance(outputs, list):\n",
    "            outputs = [outputs]\n",
    "        for name, output in zip(self.model.metrics_names, outputs):\n",
    "            if name == 'acc':\n",
    "                return output\n",
    "        raise ValueError('The model is not configured to compute accuracy. '\n",
    "                         'You should pass `metrics=[\"accuracy\"]` to '\n",
    "                         'the `model.compile()` method.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78723caf",
   "metadata": {},
   "source": [
    "# Apply AdaboostClassifier\n",
    "## adaboost1, get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5783db33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n",
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "seed_num = 42\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Dropout, LSTM, InputLayer\n",
    "from sklearn.ensemble import VotingClassifier, AdaBoostClassifier\n",
    "\n",
    "from sklearn import metrics \n",
    "from tensorflow import keras\n",
    "# from keras.wrappers.scikit_learn import KerasClassifier\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    lstm = Sequential()\n",
    "    lstm.add(InputLayer(input_shape=(x.shape[1],x.shape[2])))\n",
    "    lstm.add(LSTM(units=128, activation='hard_sigmoid', return_sequences=True))\n",
    "    lstm.add(LSTM(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "    lstm.add(Dropout(0.2))\n",
    "    lstm.add(LSTM(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "    lstm.add(LSTM(units=32, activation='hard_sigmoid', return_sequences=False))\n",
    "    lstm.add(Dropout(0.2))\n",
    "    lstm.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    lstm.compile(optimizer= keras.optimizers.Adam(learning_rate = 0.001), \n",
    "                          loss = \"binary_crossentropy\", metrics=['acc'])\n",
    "    return lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a211fa",
   "metadata": {},
   "source": [
    "### single LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "901925f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "78/78 [==============================] - 10s 75ms/step - loss: 0.6781 - acc: 0.6002 - val_loss: 0.6641 - val_acc: 0.6112\n",
      "Epoch 2/100\n",
      "78/78 [==============================] - 5s 69ms/step - loss: 0.6013 - acc: 0.6762 - val_loss: 0.5172 - val_acc: 0.7599\n",
      "Epoch 3/100\n",
      "78/78 [==============================] - 5s 69ms/step - loss: 0.4615 - acc: 0.7990 - val_loss: 0.5098 - val_acc: 0.7526\n",
      "Epoch 4/100\n",
      "78/78 [==============================] - 5s 69ms/step - loss: 0.3927 - acc: 0.8364 - val_loss: 0.5613 - val_acc: 0.7348\n",
      "Epoch 5/100\n",
      "78/78 [==============================] - 5s 70ms/step - loss: 0.3561 - acc: 0.8572 - val_loss: 0.5403 - val_acc: 0.7534\n",
      "Epoch 6/100\n",
      "78/78 [==============================] - 5s 69ms/step - loss: 0.3216 - acc: 0.8770 - val_loss: 0.5544 - val_acc: 0.7470\n",
      "Epoch 7/100\n",
      "78/78 [==============================] - 5s 68ms/step - loss: 0.2899 - acc: 0.8948 - val_loss: 0.5911 - val_acc: 0.7518\n",
      "Epoch 8/100\n",
      "78/78 [==============================] - 6s 71ms/step - loss: 0.2483 - acc: 0.9187 - val_loss: 0.6375 - val_acc: 0.7502\n",
      "Epoch 9/100\n",
      "78/78 [==============================] - 5s 70ms/step - loss: 0.2290 - acc: 0.9256 - val_loss: 0.7174 - val_acc: 0.7365\n",
      "Epoch 10/100\n",
      "78/78 [==============================] - 5s 69ms/step - loss: 0.2127 - acc: 0.9296 - val_loss: 0.7129 - val_acc: 0.7437\n",
      "Epoch 11/100\n",
      "78/78 [==============================] - 5s 70ms/step - loss: 0.1767 - acc: 0.9474 - val_loss: 0.7847 - val_acc: 0.7421\n",
      "Epoch 12/100\n",
      "78/78 [==============================] - 5s 69ms/step - loss: 0.1700 - acc: 0.9488 - val_loss: 0.8095 - val_acc: 0.7219\n",
      "Epoch 00012: early stopping\n",
      " accuracy : 0.7423948220064724, precision : 0.8185096153846154, recall : 0.7338362068965517, f1 : 0.7738636363636364, roc_auc : 0.7445518149555692\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_acc', patience=10, verbose=1, restore_best_weights=False)\n",
    "\n",
    "model = get_model()\n",
    "model.fit(X_train,y_train, validation_split = 0.2, epochs=100, batch_size=64, callbacks=[early_stop])\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "preds[preds>0.5] = 1\n",
    "preds[preds<=0.5] = 0\n",
    "\n",
    "precision = precision_score(y_test, preds)\n",
    "recall = recall_score(y_test, preds)\n",
    "f1 = f1_score(y_test, preds)\n",
    "roc_auc = roc_auc_score(y_test, preds)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "\n",
    "print(f' accuracy : {acc}, precision : {precision}, recall : {recall}, f1 : {f1}, roc_auc : {roc_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d581da91",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1c8b24f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_96 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_97 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_98 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_99 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# adaboost\n",
    "lstm_Predictors = KerasClassifier(build_fn=lambda:lstm, epochs=100, batch_size=256)\n",
    "lstm = get_model()\n",
    "# lstm_Predictors = KerasClassifier(build_fn=lambda:get_model(), epochs=10, batch_size=256)\n",
    "lstm_Predictors._estimator_type=\"classifier\"\n",
    "final_model = AdaBoostClassifier(lstm_Predictors, n_estimators=2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "72a393b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00016176, 0.00016176, 0.00016176, ..., 0.00016176, 0.00016176,\n",
       "       0.00016176])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(X_train.shape[0])/X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9c80c227",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 5s 67ms/step - loss: 1.0870e-04 - acc: 0.6042\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0901e-04 - acc: 0.6110\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.0890e-04 - acc: 0.6069\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0859e-04 - acc: 0.6081\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.0867e-04 - acc: 0.6118\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0826e-04 - acc: 0.6121\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0854e-04 - acc: 0.6124\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0858e-04 - acc: 0.6126\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0847e-04 - acc: 0.6103\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0861e-04 - acc: 0.6118\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.0849e-04 - acc: 0.6119\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0822e-04 - acc: 0.6129\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0837e-04 - acc: 0.6124\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.0841e-04 - acc: 0.6124\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.0862e-04 - acc: 0.6121\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.0839e-04 - acc: 0.6129\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0848e-04 - acc: 0.6124\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.0833e-04 - acc: 0.6134\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0839e-04 - acc: 0.6131\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0835e-04 - acc: 0.6136: 1s - loss: 1\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0833e-04 - acc: 0.6127\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.0828e-04 - acc: 0.6127\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0829e-04 - acc: 0.6132: 0s - loss: 1.0829e-04 - acc: 0\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.0845e-04 - acc: 0.6131\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0825e-04 - acc: 0.6131\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.0826e-04 - acc: 0.6129\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0853e-04 - acc: 0.6131\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.0818e-04 - acc: 0.6129: 0s - loss: 1.0895e-04 \n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0824e-04 - acc: 0.6131\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0828e-04 - acc: 0.6131\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0840e-04 - acc: 0.6131\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0811e-04 - acc: 0.6131\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0817e-04 - acc: 0.6131\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0793e-04 - acc: 0.6131\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0816e-04 - acc: 0.6131\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.0834e-04 - acc: 0.6131\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0816e-04 - acc: 0.6131\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.0798e-04 - acc: 0.6131\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0814e-04 - acc: 0.6131\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0824e-04 - acc: 0.6131\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0827e-04 - acc: 0.6131\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0823e-04 - acc: 0.6131\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0807e-04 - acc: 0.6131\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0823e-04 - acc: 0.6131\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.0815e-04 - acc: 0.6131\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0808e-04 - acc: 0.6131\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0827e-04 - acc: 0.6131\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0818e-04 - acc: 0.6131\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0793e-04 - acc: 0.6131\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.0808e-04 - acc: 0.6131\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0799e-04 - acc: 0.6131\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.0814e-04 - acc: 0.6131\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.0810e-04 - acc: 0.6131\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0814e-04 - acc: 0.6131\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0805e-04 - acc: 0.6131\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0814e-04 - acc: 0.6131\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0797e-04 - acc: 0.6131\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.0810e-04 - acc: 0.6131\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0815e-04 - acc: 0.6131\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0796e-04 - acc: 0.6131\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.0805e-04 - acc: 0.6131\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0800e-04 - acc: 0.6131\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.0798e-04 - acc: 0.6131\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0808e-04 - acc: 0.6131\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0798e-04 - acc: 0.6131\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0789e-04 - acc: 0.6131\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.0812e-04 - acc: 0.6131\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0812e-04 - acc: 0.6131\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.0810e-04 - acc: 0.6131\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.0802e-04 - acc: 0.6131\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.0814e-04 - acc: 0.6131\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.0807e-04 - acc: 0.6131\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0805e-04 - acc: 0.6131\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0808e-04 - acc: 0.6131\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.0806e-04 - acc: 0.6131\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.0807e-04 - acc: 0.6131\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0799e-04 - acc: 0.6131\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.0807e-04 - acc: 0.6131\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0794e-04 - acc: 0.6131\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0806e-04 - acc: 0.6131\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0797e-04 - acc: 0.6131\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0809e-04 - acc: 0.6131\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0807e-04 - acc: 0.6131\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0804e-04 - acc: 0.6131\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0799e-04 - acc: 0.6131\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0803e-04 - acc: 0.6131\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.0815e-04 - acc: 0.6131\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0797e-04 - acc: 0.6131\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.0806e-04 - acc: 0.6131\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.0796e-04 - acc: 0.6131\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.0807e-04 - acc: 0.6131\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0795e-04 - acc: 0.6131\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.0805e-04 - acc: 0.6131\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0803e-04 - acc: 0.6131\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.0801e-04 - acc: 0.6131\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.0810e-04 - acc: 0.6131\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.0812e-04 - acc: 0.6131\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.0808e-04 - acc: 0.6131\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.0798e-04 - acc: 0.6131\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.0795e-04 - acc: 0.6131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guri99/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:430: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1471e-04 - acc: 0.6131\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1218e-04 - acc: 0.5332\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1218e-04 - acc: 0.4490\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.1219e-04 - acc: 0.4544\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1215e-04 - acc: 0.5128: 1s - loss: 1.1220\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.1212e-04 - acc: 0.5281\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1211e-04 - acc: 0.4872\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.1215e-04 - acc: 0.4675\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1217e-04 - acc: 0.4421\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.1217e-04 - acc: 0.4461: 1s - loss: 1.11 - ETA: 0s - loss: 1.1226e-04 - acc: 0.4\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1219e-04 - acc: 0.4686: 0s - loss: 1.1185e-04\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1225e-04 - acc: 0.4537\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1214e-04 - acc: 0.4806\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1217e-04 - acc: 0.4719\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.1210e-04 - acc: 0.4774\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1216e-04 - acc: 0.4916\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.1209e-04 - acc: 0.4478\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1222e-04 - acc: 0.4160\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1213e-04 - acc: 0.4900\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1218e-04 - acc: 0.5175\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.1217e-04 - acc: 0.4932\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.1217e-04 - acc: 0.4888\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.1222e-04 - acc: 0.4439\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.1212e-04 - acc: 0.4914\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1218e-04 - acc: 0.5063\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1216e-04 - acc: 0.4725\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1212e-04 - acc: 0.4736\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1211e-04 - acc: 0.4850\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.1213e-04 - acc: 0.4835\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1208e-04 - acc: 0.4560\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1217e-04 - acc: 0.4544\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1210e-04 - acc: 0.4840\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.1211e-04 - acc: 0.4801\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.1218e-04 - acc: 0.4676\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1210e-04 - acc: 0.5199\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.1213e-04 - acc: 0.4772\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1215e-04 - acc: 0.4528\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1220e-04 - acc: 0.4820\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1212e-04 - acc: 0.4596\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1219e-04 - acc: 0.4442\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1219e-04 - acc: 0.4282\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1215e-04 - acc: 0.4232: 0s - loss: 1.1207e-0\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1216e-04 - acc: 0.4225\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1211e-04 - acc: 0.4908\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1215e-04 - acc: 0.4605\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1215e-04 - acc: 0.4625\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.1219e-04 - acc: 0.4296\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1217e-04 - acc: 0.4618\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1223e-04 - acc: 0.4877\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1213e-04 - acc: 0.4568\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1218e-04 - acc: 0.4720\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.1216e-04 - acc: 0.4277\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1212e-04 - acc: 0.4665\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.1216e-04 - acc: 0.4541\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1211e-04 - acc: 0.4141\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.1216e-04 - acc: 0.4380\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.1211e-04 - acc: 0.4588\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.1214e-04 - acc: 0.4756\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1216e-04 - acc: 0.5236\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.1211e-04 - acc: 0.4757\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1213e-04 - acc: 0.5144\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1212e-04 - acc: 0.4628\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1216e-04 - acc: 0.4581\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1214e-04 - acc: 0.5034\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1212e-04 - acc: 0.4864\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.1213e-04 - acc: 0.4549\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1215e-04 - acc: 0.4710\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1212e-04 - acc: 0.4829\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.1217e-04 - acc: 0.4905\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1210e-04 - acc: 0.4832\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1216e-04 - acc: 0.4597\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1212e-04 - acc: 0.4615\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1209e-04 - acc: 0.5202\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1210e-04 - acc: 0.5201\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1209e-04 - acc: 0.5385\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1217e-04 - acc: 0.4241\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1217e-04 - acc: 0.4769\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1214e-04 - acc: 0.5278\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.1216e-04 - acc: 0.4612\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.1210e-04 - acc: 0.4786\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1213e-04 - acc: 0.5011\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.1217e-04 - acc: 0.4880\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1219e-04 - acc: 0.4609: 0s - loss: 1.1237e-04 - acc: 0.\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1210e-04 - acc: 0.5215\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1210e-04 - acc: 0.5273\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1214e-04 - acc: 0.4447\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.1219e-04 - acc: 0.4788\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.1209e-04 - acc: 0.5422: 0s - loss: 1.1208e-04 - acc: \n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1217e-04 - acc: 0.4803\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1220e-04 - acc: 0.4531\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1214e-04 - acc: 0.4550\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.1218e-04 - acc: 0.4888\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1215e-04 - acc: 0.4479\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1220e-04 - acc: 0.4560\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1214e-04 - acc: 0.4667\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 2s 66ms/step - loss: 1.1217e-04 - acc: 0.4151\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.1207e-04 - acc: 0.4314\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.1212e-04 - acc: 0.4364\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 2s 66ms/step - loss: 1.1211e-04 - acc: 0.4636\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.1216e-04 - acc: 0.5005\n",
      "CPU times: user 14min 39s, sys: 17min 53s, total: 32min 32s\n",
      "Wall time: 5min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with tf.device('/device:GPU:0'):\n",
    "#     final_model.fit(X_train,y_train, sample_weight=np.ones(X_train.shape[0])/X_train.shape[0])\n",
    "    history = final_model.fit(X_train,y_train, sample_weight=np.ones(X_train.shape[0])/X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "971efe0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guri99/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:430: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " accuracy : 0.6006472491909385, precision : 0.6006472491909385, recall : 1.0, f1 : 0.7505054589567327, roc_auc : 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "preds = final_model.predict(X_test)\n",
    "\n",
    "precision = precision_score(y_test, preds)\n",
    "recall = recall_score(y_test, preds)\n",
    "f1 = f1_score(y_test, preds)\n",
    "roc_auc = roc_auc_score(y_test, preds)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "\n",
    "print(f' accuracy : {acc}, precision : {precision}, recall : {recall}, f1 : {f1}, roc_auc : {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624a3c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e83d2bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guri99/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:430: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.7521035598705501\n"
     ]
    }
   ],
   "source": [
    "preds = final_model.predict(X_test)\n",
    "# preds[preds>0.5] = 1\n",
    "# preds[preds<=0.5] = 0\n",
    "from sklearn import metrics\n",
    "print('정확도 :', metrics.accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a8c4630",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guri99/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:430: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcb28af",
   "metadata": {},
   "source": [
    "## adaboost 2\n",
    "- 참고한 github\n",
    "- https://github.com/limitless083/timeseries-forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65139810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def calc_error(y, y_):\n",
    "    return np.sqrt((y - y_) ** 2)\n",
    "\n",
    "\n",
    "class AdaBoost:\n",
    "    def __init__(self, trainX, trainY):\n",
    "        self.trainX = trainX\n",
    "        self.trainY = trainY\n",
    "        self.N = len(self.trainX)\n",
    "        self.weights = np.ones(self.N) / self.N\n",
    "        self.alphas = []\n",
    "        self.models = []\n",
    "\n",
    "    def set_rule(self, model):\n",
    "        predict = model.predict(self.trainX)\n",
    "        errors = []\n",
    "        for i in range(self.N):\n",
    "            errors.append(self.weights[i] * calc_error(self.trainY[i], predict[i, 0]))\n",
    "        e = np.sum(errors)\n",
    "        alpha = 0.5 * np.log((1 - e) / e)\n",
    "        print('e=%.4f a=%.4f' % (e, alpha))\n",
    "        w = np.zeros(self.N)\n",
    "        for i in range(self.N):\n",
    "            w[i] = self.weights[i] * np.exp(alpha * errors[i] / e)\n",
    "        self.weights = w / w.sum()\n",
    "        self.models.append(model)\n",
    "        self.alphas.append(alpha)\n",
    "\n",
    "    def predict(self, x_set):\n",
    "        n_models = len(self.models)\n",
    "        alpha_sum = np.sum(self.alphas)\n",
    "        final_predict = np.zeros(1)\n",
    "        for i in range(n_models):\n",
    "            predict = self.models[i].predict(x_set)\n",
    "            final_predict = final_predict + predict[:, 0] * self.alphas[i]\n",
    "        final_predict = final_predict / alpha_sum\n",
    "\n",
    "        return final_predict.reshape(len(x_set), 1)\n",
    "\n",
    "    def evaluate(self):\n",
    "        n_models = len(self.models)\n",
    "        alpha_sum = np.sum(self.alphas)\n",
    "        final_predict = np.zeros(len(self.trainX))\n",
    "        for i in range(n_models):\n",
    "            predict = self.models[i].predict(self.trainX)\n",
    "            final_predict = final_predict + predict[:, 0] * self.alphas[i]\n",
    "        final_predict = final_predict / alpha_sum\n",
    "        errors = []\n",
    "        for i in range(self.N):\n",
    "            errors.append(calc_error(self.trainY[i], final_predict[i]))\n",
    "        return np.sum(errors)\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78447586",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "40/40 - 5s - loss: 1.0949e-04 - acc: 0.5925\n",
      "Epoch 2/20\n",
      "40/40 - 3s - loss: 1.0935e-04 - acc: 0.5979\n",
      "Epoch 3/20\n",
      "40/40 - 3s - loss: 1.0992e-04 - acc: 0.5959\n",
      "Epoch 4/20\n",
      "40/40 - 3s - loss: 1.0989e-04 - acc: 0.6000\n",
      "Epoch 5/20\n",
      "40/40 - 3s - loss: 1.0933e-04 - acc: 0.5951\n",
      "Epoch 6/20\n",
      "40/40 - 3s - loss: 1.0938e-04 - acc: 0.5995\n",
      "Epoch 7/20\n",
      "40/40 - 3s - loss: 1.0936e-04 - acc: 0.6014\n",
      "Epoch 8/20\n",
      "40/40 - 3s - loss: 1.0958e-04 - acc: 0.6000\n",
      "Epoch 9/20\n",
      "40/40 - 3s - loss: 1.0910e-04 - acc: 0.6011\n",
      "Epoch 10/20\n",
      "40/40 - 3s - loss: 1.0926e-04 - acc: 0.6029\n",
      "Epoch 11/20\n",
      "40/40 - 3s - loss: 1.0906e-04 - acc: 0.6026\n",
      "Epoch 12/20\n",
      "40/40 - 3s - loss: 1.0922e-04 - acc: 0.6064\n",
      "Epoch 13/20\n",
      "40/40 - 3s - loss: 1.0903e-04 - acc: 0.6032\n",
      "Epoch 14/20\n",
      "40/40 - 3s - loss: 1.0909e-04 - acc: 0.6042\n",
      "Epoch 15/20\n",
      "40/40 - 3s - loss: 1.0904e-04 - acc: 0.6035\n",
      "Epoch 16/20\n",
      "40/40 - 3s - loss: 1.0910e-04 - acc: 0.6042\n",
      "Epoch 17/20\n",
      "40/40 - 3s - loss: 1.0886e-04 - acc: 0.6058\n",
      "Epoch 18/20\n",
      "40/40 - 3s - loss: 1.0883e-04 - acc: 0.6045\n",
      "Epoch 19/20\n",
      "40/40 - 3s - loss: 1.0904e-04 - acc: 0.6038\n",
      "Epoch 20/20\n",
      "40/40 - 3s - loss: 1.0888e-04 - acc: 0.6060\n",
      "e=0.4778 a=0.0444\n",
      "final error:  2953.856681569422\n"
     ]
    }
   ],
   "source": [
    "adaboost = AdaBoost(X_train, y_train)\n",
    "for i in range(1):\n",
    "    sample_weights = adaboost.get_weights()\n",
    "    model = get_model(seed_num)\n",
    "    model.fit(X_train, y_train, epochs=20, batch_size=156, verbose=2, sample_weight=sample_weights)\n",
    "    adaboost.set_rule(model)\n",
    "print(\"final error: \", adaboost.evaluate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3f8c687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6284789644012945"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred[pred>0.5] = 1; pred[pred<=0.5] = 0\n",
    "metrics.accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c57f61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f562a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23a8518a",
   "metadata": {},
   "source": [
    "## adaboost 3\n",
    "- 참고한 자료\n",
    "- https://stackoverflow.com/questions/64558810/how-to-use-a-keras-model-inside-of-sklearns-adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df3f0555",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyKerasClassifier(KerasClassifier):\n",
    "    def fit(self, x, y, sample_weight=None, **kwargs):\n",
    "        y = np.array(y)\n",
    "        if len(y.shape) == 2 and y.shape[1] > 1:\n",
    "            self.classes_ = np.arange(y.shape[1])\n",
    "        elif (len(y.shape) == 2 and y.shape[1] == 1) or len(y.shape) == 1:\n",
    "            self.classes_ = np.unique(y)\n",
    "            y = np.searchsorted(self.classes_, y)\n",
    "        else:\n",
    "            raise ValueError('Invalid shape for y: ' + str(y.shape))\n",
    "        self.n_classes_ = len(self.classes_)\n",
    "        if sample_weight is not None:\n",
    "            kwargs['sample_weight'] = sample_weight\n",
    "            print(type(sample_weight))\n",
    "        return super(MyKerasClassifier, self).fit(x, y, **kwargs)\n",
    "    def predict(self, x, **kwargs):\n",
    "        kwargs = self.filter_sk_params(Sequential.predict_classes, kwargs)\n",
    "        classes = self.model.predict_classes(x, **kwargs)\n",
    "        return self.classes_[classes].flatten()\n",
    "        #return super(KerasClassifier, self).fit(x, y, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a8fa9fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Epoch 1/20\n",
      "40/40 - 16s - loss: 1.0959e-04 - acc: 0.5932\n",
      "Epoch 2/20\n",
      "40/40 - 3s - loss: 1.0909e-04 - acc: 0.6030\n",
      "Epoch 3/20\n",
      "40/40 - 3s - loss: 1.0925e-04 - acc: 0.5992\n",
      "Epoch 4/20\n",
      "40/40 - 3s - loss: 1.0919e-04 - acc: 0.6030\n",
      "Epoch 5/20\n",
      "40/40 - 3s - loss: 1.0931e-04 - acc: 0.5982\n",
      "Epoch 6/20\n",
      "40/40 - 3s - loss: 1.0895e-04 - acc: 0.6050\n",
      "Epoch 7/20\n",
      "40/40 - 3s - loss: 1.0938e-04 - acc: 0.6053\n",
      "Epoch 8/20\n",
      "40/40 - 3s - loss: 1.0933e-04 - acc: 0.6006\n",
      "Epoch 9/20\n",
      "40/40 - 3s - loss: 1.0891e-04 - acc: 0.6050\n",
      "Epoch 10/20\n",
      "40/40 - 3s - loss: 1.0880e-04 - acc: 0.6056\n",
      "Epoch 11/20\n",
      "40/40 - 3s - loss: 1.0915e-04 - acc: 0.6038\n",
      "Epoch 12/20\n",
      "40/40 - 3s - loss: 1.0866e-04 - acc: 0.6060\n",
      "Epoch 13/20\n",
      "40/40 - 3s - loss: 1.0878e-04 - acc: 0.6051\n",
      "Epoch 14/20\n",
      "40/40 - 3s - loss: 1.0874e-04 - acc: 0.6066\n",
      "Epoch 15/20\n",
      "40/40 - 3s - loss: 1.0881e-04 - acc: 0.6058\n",
      "Epoch 16/20\n",
      "40/40 - 3s - loss: 1.0876e-04 - acc: 0.6056\n",
      "Epoch 17/20\n",
      "40/40 - 3s - loss: 1.0860e-04 - acc: 0.6061\n",
      "Epoch 18/20\n",
      "40/40 - 3s - loss: 1.0867e-04 - acc: 0.6058\n",
      "Epoch 19/20\n",
      "40/40 - 3s - loss: 1.0877e-04 - acc: 0.6064\n",
      "Epoch 20/20\n",
      "40/40 - 3s - loss: 1.0859e-04 - acc: 0.6061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 - 2s\n",
      "<class 'numpy.ndarray'>\n",
      "Epoch 1/20\n",
      "40/40 - 6s - loss: 1.1402e-04 - acc: 0.5325\n",
      "Epoch 2/20\n",
      "40/40 - 3s - loss: 1.1279e-04 - acc: 0.5209\n",
      "Epoch 3/20\n",
      "40/40 - 3s - loss: 1.1291e-04 - acc: 0.4982\n",
      "Epoch 4/20\n",
      "40/40 - 3s - loss: 1.1285e-04 - acc: 0.5045\n",
      "Epoch 5/20\n",
      "40/40 - 3s - loss: 1.1300e-04 - acc: 0.4995\n",
      "Epoch 6/20\n",
      "40/40 - 3s - loss: 1.1267e-04 - acc: 0.5055\n",
      "Epoch 7/20\n",
      "40/40 - 3s - loss: 1.1306e-04 - acc: 0.5152\n",
      "Epoch 8/20\n",
      "40/40 - 3s - loss: 1.1295e-04 - acc: 0.4934\n",
      "Epoch 9/20\n",
      "40/40 - 3s - loss: 1.1261e-04 - acc: 0.4913\n",
      "Epoch 10/20\n",
      "40/40 - 3s - loss: 1.1251e-04 - acc: 0.5333\n",
      "Epoch 11/20\n",
      "40/40 - 3s - loss: 1.1283e-04 - acc: 0.4948\n",
      "Epoch 12/20\n",
      "40/40 - 3s - loss: 1.1232e-04 - acc: 0.5210\n",
      "Epoch 13/20\n",
      "40/40 - 3s - loss: 1.1250e-04 - acc: 0.5160\n",
      "Epoch 14/20\n",
      "40/40 - 3s - loss: 1.1236e-04 - acc: 0.5134\n",
      "Epoch 15/20\n",
      "40/40 - 3s - loss: 1.1250e-04 - acc: 0.5070\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d45ffe294336>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mboosted_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mboosted_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0miboost\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;31m# Boosting step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             sample_weight, estimator_weight, estimator_error = self._boost(\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \"\"\"\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SAMME.R'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-f4a4bc5199e2>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMyKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_sk_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-12bca8c9feae>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-12bca8c9feae>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "base_estimator = MyKerasClassifier(build_fn=lambda:get_model(seed_num), epochs=20, batch_size=156, verbose=2)\n",
    "boosted_classifier = AdaBoostClassifier(base_estimator=base_estimator,n_estimators=10,random_state=42)\n",
    "\n",
    "boosted_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee15040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "boosted_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b92b47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bd344f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb5e31c4",
   "metadata": {},
   "source": [
    "# Apply VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abb66947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f0c1133f520>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload_model = tf.keras.models.load_model('/project/guri/Restart/models/14-0.7646.hdf5')\n",
    "reload_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df643139",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('model1', <__main__.KerasClassifier object at 0x7f0adc371a60>), ('model2', <__main__.KerasClassifier object at 0x7f0ad0273f70>), ('model3', <__main__.KerasClassifier object at 0x7f0ad0273c40>), ('model4', <__main__.KerasClassifier object at 0x7f0ad0273b20>)]\n"
     ]
    }
   ],
   "source": [
    "# voting\n",
    "# GRU_Predictors = KerasClassifier(build_fn=lambda:lstm, epochs=20, batch_size=256)\n",
    "# lstm_Predictors = KerasClassifier(build_fn=lambda:get_model(seed_num), epochs=20, batch_size=256)\n",
    "#LSTM 쌓기\n",
    "estimator = []\n",
    "for i in range(1,5):\n",
    "    LSTM_Predictors = KerasClassifier(build_fn=lambda:reload_model, epochs=20, batch_size=256)\n",
    "    LSTM_Predictors._estimator_type=\"classifier\"\n",
    "    estimator.append((f'model{i}', LSTM_Predictors))\n",
    "print(estimator) \n",
    "voting_model = VotingClassifier(estimators=estimator, voting = 'soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5bf7c94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 3s 110ms/step - loss: 0.1686 - acc: 0.9562\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 3s 105ms/step - loss: 0.1612 - acc: 0.9581\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 3s 105ms/step - loss: 0.1529 - acc: 0.9615\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 3s 107ms/step - loss: 0.1470 - acc: 0.9634\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 3s 104ms/step - loss: 0.1444 - acc: 0.9631\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.1453 - acc: 0.9634\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.1374 - acc: 0.9652\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 3s 105ms/step - loss: 0.1549 - acc: 0.9573\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.1386 - acc: 0.9657\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.1421 - acc: 0.9639\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 3s 104ms/step - loss: 0.1349 - acc: 0.9664\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 3s 109ms/step - loss: 0.1293 - acc: 0.9680\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 3s 104ms/step - loss: 0.1272 - acc: 0.9681\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 3s 104ms/step - loss: 0.1274 - acc: 0.9699\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 3s 108ms/step - loss: 0.1238 - acc: 0.9701\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 3s 103ms/step - loss: 0.1194 - acc: 0.9723\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 3s 104ms/step - loss: 0.1205 - acc: 0.9710\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 3s 103ms/step - loss: 0.1167 - acc: 0.9728\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 3s 102ms/step - loss: 0.1194 - acc: 0.9733\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 3s 104ms/step - loss: 0.1146 - acc: 0.9738\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 3s 107ms/step - loss: 0.1136 - acc: 0.9738\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 3s 104ms/step - loss: 0.1114 - acc: 0.9743\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 3s 108ms/step - loss: 0.1117 - acc: 0.9741\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 3s 104ms/step - loss: 0.1135 - acc: 0.9735\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 3s 103ms/step - loss: 0.1173 - acc: 0.9712\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.1104 - acc: 0.9743\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 3s 107ms/step - loss: 0.1053 - acc: 0.9774\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.1112 - acc: 0.9719\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.1068 - acc: 0.9751\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.1069 - acc: 0.9757\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 3s 107ms/step - loss: 0.1040 - acc: 0.9765\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 3s 105ms/step - loss: 0.1025 - acc: 0.9775\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.1016 - acc: 0.9772\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 3s 107ms/step - loss: 0.1066 - acc: 0.9746\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 3s 104ms/step - loss: 0.1068 - acc: 0.9754\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 3s 103ms/step - loss: 0.1031 - acc: 0.9775\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 3s 101ms/step - loss: 0.1018 - acc: 0.9769\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 3s 100ms/step - loss: 0.1038 - acc: 0.9759\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 3s 103ms/step - loss: 0.1037 - acc: 0.9762\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 3s 101ms/step - loss: 0.1000 - acc: 0.9783\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 3s 104ms/step - loss: 0.1026 - acc: 0.9761\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.1012 - acc: 0.9769\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 3s 103ms/step - loss: 0.1032 - acc: 0.9761\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 3s 101ms/step - loss: 0.0991 - acc: 0.9778\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 3s 105ms/step - loss: 0.0995 - acc: 0.9780\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 3s 103ms/step - loss: 0.1031 - acc: 0.9751\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.0976 - acc: 0.9770\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 3s 103ms/step - loss: 0.0946 - acc: 0.9791\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 3s 105ms/step - loss: 0.0904 - acc: 0.9808\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 3s 107ms/step - loss: 0.0959 - acc: 0.9788\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 3s 105ms/step - loss: 0.0950 - acc: 0.9778\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.0944 - acc: 0.9798\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.0937 - acc: 0.9799\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 3s 105ms/step - loss: 0.0961 - acc: 0.9783\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.0926 - acc: 0.9803\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 3s 102ms/step - loss: 0.0906 - acc: 0.9801\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 3s 102ms/step - loss: 0.0909 - acc: 0.9803\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 3s 103ms/step - loss: 0.0895 - acc: 0.9817\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 99ms/step - loss: 0.0939 - acc: 0.9790\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 3s 102ms/step - loss: 0.0978 - acc: 0.9764\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 3s 105ms/step - loss: 0.0913 - acc: 0.9798\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 3s 103ms/step - loss: 0.0899 - acc: 0.9809\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.0923 - acc: 0.9796\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 3s 104ms/step - loss: 0.0902 - acc: 0.9801\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 3s 102ms/step - loss: 0.0919 - acc: 0.9791\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 3s 107ms/step - loss: 0.0898 - acc: 0.9814\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 3s 104ms/step - loss: 0.0952 - acc: 0.9777\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 3s 105ms/step - loss: 0.0886 - acc: 0.9816\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 3s 105ms/step - loss: 0.0913 - acc: 0.9791\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 3s 103ms/step - loss: 0.0913 - acc: 0.9790\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 3s 108ms/step - loss: 0.0894 - acc: 0.9804\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.0879 - acc: 0.9817\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 3s 105ms/step - loss: 0.0890 - acc: 0.9801\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 3s 109ms/step - loss: 0.0896 - acc: 0.9801\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 3s 105ms/step - loss: 0.0892 - acc: 0.9801\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 3s 103ms/step - loss: 0.0868 - acc: 0.9825\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 3s 104ms/step - loss: 0.0857 - acc: 0.9820\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 3s 101ms/step - loss: 0.0874 - acc: 0.9819\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 3s 104ms/step - loss: 0.0845 - acc: 0.9817\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 99ms/step - loss: 0.0883 - acc: 0.9817\n",
      "CPU times: user 1h 58min 47s, sys: 27min 37s, total: 2h 26min 24s\n",
      "Wall time: 3min 33s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('model1',\n",
       "                              <__main__.KerasClassifier object at 0x7f0adc371a60>),\n",
       "                             ('model2',\n",
       "                              <__main__.KerasClassifier object at 0x7f0ad0273f70>),\n",
       "                             ('model3',\n",
       "                              <__main__.KerasClassifier object at 0x7f0ad0273c40>),\n",
       "                             ('model4',\n",
       "                              <__main__.KerasClassifier object at 0x7f0ad0273b20>)],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "voting_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c504e750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guri99/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:430: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.7941747572815534\n"
     ]
    }
   ],
   "source": [
    "preds = voting_model.predict(X_test)\n",
    "from sklearn import metrics\n",
    "print('정확도 :', metrics.accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ace675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18c65ae4",
   "metadata": {},
   "source": [
    "# Adaboost-GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5433d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_num = 48\n",
    "def get_gru_model(seed_num):\n",
    "    tf.random.set_seed(seed_num)\n",
    "\n",
    "    gru = Sequential()\n",
    "    gru.add(InputLayer(input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "    gru.add(GRU(units=128, activation='hard_sigmoid', return_sequences=True))\n",
    "    gru.add(GRU(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "    gru.add(Dropout(0.2))\n",
    "    gru.add(GRU(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "    gru.add(GRU(units=32, activation='hard_sigmoid', return_sequences=False))\n",
    "    gru.add(Dropout(0.2))\n",
    "    gru.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    gru.compile(optimizer= \"adam\", loss = \"binary_crossentropy\", metrics=['acc'])\n",
    "    return gru\n",
    "\n",
    "# adaboost\n",
    "# GRU_Predictors = KerasClassifier(build_fn=lambda:gru, epochs=20, batch_size=256)\n",
    "gru_Predictors = KerasClassifier(build_fn=lambda:get_gru_model(seed_num), epochs=20, batch_size=256)\n",
    "gru_model = AdaBoostClassifier(gru_Predictors, n_estimators=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "57883fc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 73ms/step - loss: 1.1196e-04 - acc: 0.5808\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1028e-04 - acc: 0.5911\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1036e-04 - acc: 0.5858\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1049e-04 - acc: 0.5904\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1094e-04 - acc: 0.5820\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.0939e-04 - acc: 0.5893\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.0990e-04 - acc: 0.5938\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1004e-04 - acc: 0.5930\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1012e-04 - acc: 0.5943\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.0929e-04 - acc: 0.6065\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.0902e-04 - acc: 0.6070\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.0977e-04 - acc: 0.5926\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 1.0889e-04 - acc: 0.6091\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.0931e-04 - acc: 0.6003\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.0972e-04 - acc: 0.6009\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.0909e-04 - acc: 0.6022\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.0884e-04 - acc: 0.6055\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.0945e-04 - acc: 0.5999\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.0890e-04 - acc: 0.6064\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.0817e-04 - acc: 0.6131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 74ms/step - loss: 1.1916e-04 - acc: 0.5625\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1438e-04 - acc: 0.4882\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1424e-04 - acc: 0.5040\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1437e-04 - acc: 0.5045\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1482e-04 - acc: 0.4828\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1316e-04 - acc: 0.5082\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1378e-04 - acc: 0.5064\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1391e-04 - acc: 0.4710\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1379e-04 - acc: 0.4917\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1325e-04 - acc: 0.5208\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 1.1289e-04 - acc: 0.5037\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1338e-04 - acc: 0.4832\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1283e-04 - acc: 0.5207\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1302e-04 - acc: 0.4976\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1335e-04 - acc: 0.5153\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1280e-04 - acc: 0.4985\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1259e-04 - acc: 0.5105\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1313e-04 - acc: 0.5102\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 1.1262e-04 - acc: 0.5204\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1198e-04 - acc: 0.4967\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 74ms/step - loss: 1.1918e-04 - acc: 0.5622\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1438e-04 - acc: 0.4876\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1425e-04 - acc: 0.5036\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1437e-04 - acc: 0.5032\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1483e-04 - acc: 0.4823\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1316e-04 - acc: 0.5073\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1379e-04 - acc: 0.5065\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1392e-04 - acc: 0.4683\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1379e-04 - acc: 0.4902\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1325e-04 - acc: 0.5185\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1289e-04 - acc: 0.5004\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1339e-04 - acc: 0.4845\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1284e-04 - acc: 0.5205\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1302e-04 - acc: 0.4956\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1335e-04 - acc: 0.5144\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1280e-04 - acc: 0.4956\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1259e-04 - acc: 0.5076\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1313e-04 - acc: 0.5079\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 1.1262e-04 - acc: 0.5189\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1199e-04 - acc: 0.4939\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 73ms/step - loss: 1.1918e-04 - acc: 0.5622\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1438e-04 - acc: 0.4876\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1425e-04 - acc: 0.5036\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1437e-04 - acc: 0.5032\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1483e-04 - acc: 0.4823\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1316e-04 - acc: 0.5073\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1379e-04 - acc: 0.5065\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1392e-04 - acc: 0.4683\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1379e-04 - acc: 0.4902\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1325e-04 - acc: 0.5185\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1289e-04 - acc: 0.5004\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1339e-04 - acc: 0.4845\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1284e-04 - acc: 0.5205\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1302e-04 - acc: 0.4956\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1335e-04 - acc: 0.5144\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1280e-04 - acc: 0.4956\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1259e-04 - acc: 0.5075\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1313e-04 - acc: 0.5079\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1262e-04 - acc: 0.5189\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1199e-04 - acc: 0.4939\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 6s 75ms/step - loss: 1.1918e-04 - acc: 0.5622\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1438e-04 - acc: 0.4876\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1425e-04 - acc: 0.5036\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1437e-04 - acc: 0.5032\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1483e-04 - acc: 0.4823\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1316e-04 - acc: 0.5073\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1379e-04 - acc: 0.5065\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1392e-04 - acc: 0.4683\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1379e-04 - acc: 0.4902\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1325e-04 - acc: 0.5185\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1289e-04 - acc: 0.5004\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1339e-04 - acc: 0.4845\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1284e-04 - acc: 0.5205\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1302e-04 - acc: 0.4956\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1335e-04 - acc: 0.5144\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1280e-04 - acc: 0.4956\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1259e-04 - acc: 0.5075\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1313e-04 - acc: 0.5079\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1262e-04 - acc: 0.5189\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 1.1199e-04 - acc: 0.4939\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 73ms/step - loss: 1.1918e-04 - acc: 0.5622\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1438e-04 - acc: 0.4876\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1425e-04 - acc: 0.5036\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1437e-04 - acc: 0.5032\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1483e-04 - acc: 0.4823\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1316e-04 - acc: 0.5073\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1379e-04 - acc: 0.5065\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1392e-04 - acc: 0.4683\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1380e-04 - acc: 0.4902\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1325e-04 - acc: 0.5185\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1289e-04 - acc: 0.5004\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1339e-04 - acc: 0.4845\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1284e-04 - acc: 0.5205\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1302e-04 - acc: 0.4956\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1335e-04 - acc: 0.5144\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1280e-04 - acc: 0.4956\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1259e-04 - acc: 0.5075\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1313e-04 - acc: 0.5079\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1262e-04 - acc: 0.5189\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1199e-04 - acc: 0.4939\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 72ms/step - loss: 1.1918e-04 - acc: 0.5622\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1438e-04 - acc: 0.4876\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1425e-04 - acc: 0.5036\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1437e-04 - acc: 0.5032\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1483e-04 - acc: 0.4823\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1316e-04 - acc: 0.5073\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1379e-04 - acc: 0.5065\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1392e-04 - acc: 0.4683\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1380e-04 - acc: 0.4902\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1325e-04 - acc: 0.5185\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1289e-04 - acc: 0.5004\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1339e-04 - acc: 0.4845\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 1.1284e-04 - acc: 0.5205\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1302e-04 - acc: 0.4956\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1335e-04 - acc: 0.5144\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1280e-04 - acc: 0.4956\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1259e-04 - acc: 0.5076\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1313e-04 - acc: 0.5079\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 1.1262e-04 - acc: 0.5190\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1199e-04 - acc: 0.4939\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 73ms/step - loss: 1.1918e-04 - acc: 0.5622\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1438e-04 - acc: 0.4876\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1425e-04 - acc: 0.5036\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1437e-04 - acc: 0.5032\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1483e-04 - acc: 0.4823\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1316e-04 - acc: 0.5073\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1379e-04 - acc: 0.5065\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1392e-04 - acc: 0.4683\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1380e-04 - acc: 0.4902\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1325e-04 - acc: 0.5185\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1289e-04 - acc: 0.5004\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1339e-04 - acc: 0.4845\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1284e-04 - acc: 0.5205\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1302e-04 - acc: 0.4956\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1335e-04 - acc: 0.5144\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1280e-04 - acc: 0.4956\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1259e-04 - acc: 0.5076\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1313e-04 - acc: 0.5079\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 1.1262e-04 - acc: 0.5190\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 1.1199e-04 - acc: 0.4939\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 73ms/step - loss: 1.1918e-04 - acc: 0.5622\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1438e-04 - acc: 0.4876\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1425e-04 - acc: 0.5036\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1437e-04 - acc: 0.5032\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1483e-04 - acc: 0.4823\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1316e-04 - acc: 0.5073\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1379e-04 - acc: 0.5065\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1392e-04 - acc: 0.4683\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 1.1380e-04 - acc: 0.4902\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1325e-04 - acc: 0.5185\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1289e-04 - acc: 0.5004\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1339e-04 - acc: 0.4845\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1284e-04 - acc: 0.5205\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 1.1302e-04 - acc: 0.4956\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1335e-04 - acc: 0.5144\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1280e-04 - acc: 0.4956\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1259e-04 - acc: 0.5076\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1313e-04 - acc: 0.5079\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 1.1262e-04 - acc: 0.5190\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 1.1199e-04 - acc: 0.4939\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 74ms/step - loss: 1.1918e-04 - acc: 0.5622\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1438e-04 - acc: 0.4876\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1425e-04 - acc: 0.5036\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1437e-04 - acc: 0.5032\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1483e-04 - acc: 0.4823\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1316e-04 - acc: 0.5073\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1379e-04 - acc: 0.5065\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1392e-04 - acc: 0.4683\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1380e-04 - acc: 0.4902\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1325e-04 - acc: 0.5185\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1289e-04 - acc: 0.5004\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1339e-04 - acc: 0.4845\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1284e-04 - acc: 0.5205\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1302e-04 - acc: 0.4956\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1335e-04 - acc: 0.5144\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1280e-04 - acc: 0.4956\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1259e-04 - acc: 0.5076\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1313e-04 - acc: 0.5079\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1262e-04 - acc: 0.5190\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 1.1199e-04 - acc: 0.4939\n",
      "CPU times: user 4h 40min 2s, sys: 42min 40s, total: 5h 22min 43s\n",
      "Wall time: 7min 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=<__main__.KerasClassifier object at 0x7f3a133592b0>,\n",
       "                   n_estimators=10, random_state=42)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "gru_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc1c042d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.6284789644012945\n"
     ]
    }
   ],
   "source": [
    "preds = gru_model.predict(X_test)\n",
    "preds[preds>0.5] = 1\n",
    "preds[preds<=0.5] = 0\n",
    "from sklearn import metrics\n",
    "print('정확도 :', metrics.accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2788da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2a2aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bdf705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41fcf2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b42b7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ef9fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd423d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25606137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "164.97px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

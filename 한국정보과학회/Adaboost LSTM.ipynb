{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bb79b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "    try:\n",
    "        for i in range(len(gpus)):\n",
    "            tf.config.experimental.set_memory_growth(gpus[i], True)\n",
    "    except RuntimeError as e:\n",
    "        # 프로그램 시작시에 메모리 증가가 설정되어야만 합니다\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bde59951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436406b6",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173c3946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0de28f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0357c3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6182, 10, 4068), (6182,), (1545, 10, 4068), (1545,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random  \n",
    "seed_num = 42\n",
    "random.seed(seed_num)\n",
    "\n",
    "x = np.load('/project/LSH/x_(7727,10,4068).npy')\n",
    "y = np.load('/project/LSH/y_(7727,1).npy')\n",
    "\n",
    "idx = list(range(len(x)))\n",
    "random.shuffle(idx)\n",
    "\n",
    "i = round(x.shape[0]*0.8)\n",
    "X_train, y_train = x[idx[:i],:,:], y[idx[:i]]\n",
    "X_test, y_test = x[idx[i:],:,:], y[idx[i:]]\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526b2b0a",
   "metadata": {},
   "source": [
    "# Revised KerasClassifier\n",
    "- https://github.com/veniversum/keras/blob/9a401eb2e184fda7238a6259c1b8b02c645e4e9c/keras/wrappers/scikit_learn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f802e9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "293a5e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Wrapper for using the Scikit-Learn API with Keras models.\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import copy\n",
    "import types\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from tensorflow import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils.generic_utils import has_arg\n",
    "from keras.models import Sequential\n",
    "# from keras.layers import BaseWrapper\n",
    "\n",
    "class BaseWrapper(object):\n",
    "    \"\"\"Base class for the Keras scikit-learn wrapper.\n",
    "\n",
    "    Warning: This class should not be used directly.\n",
    "    Use descendant classes instead.\n",
    "\n",
    "    # Arguments\n",
    "        build_fn: callable function or class instance\n",
    "        **sk_params: model parameters & fitting parameters\n",
    "\n",
    "    The `build_fn` should construct, compile and return a Keras model, which\n",
    "    will then be used to fit/predict. One of the following\n",
    "    three values could be passed to `build_fn`:\n",
    "    1. A function\n",
    "    2. An instance of a class that implements the `__call__` method\n",
    "    3. None. This means you implement a class that inherits from either\n",
    "    `KerasClassifier` or `KerasRegressor`. The `__call__` method of the\n",
    "    present class will then be treated as the default `build_fn`.\n",
    "\n",
    "    `sk_params` takes both model parameters and fitting parameters. Legal model\n",
    "    parameters are the arguments of `build_fn`. Note that like all other\n",
    "    estimators in scikit-learn, `build_fn` should provide default values for\n",
    "    its arguments, so that you could create the estimator without passing any\n",
    "    values to `sk_params`.\n",
    "\n",
    "    `sk_params` could also accept parameters for calling `fit`, `predict`,\n",
    "    `predict_proba`, and `score` methods (e.g., `epochs`, `batch_size`).\n",
    "    fitting (predicting) parameters are selected in the following order:\n",
    "\n",
    "    1. Values passed to the dictionary arguments of\n",
    "    `fit`, `predict`, `predict_proba`, and `score` methods\n",
    "    2. Values passed to `sk_params`\n",
    "    3. The default values of the `keras.models.Sequential`\n",
    "    `fit`, `predict`, `predict_proba` and `score` methods\n",
    "\n",
    "    When using scikit-learn's `grid_search` API, legal tunable parameters are\n",
    "    those you could pass to `sk_params`, including fitting parameters.\n",
    "    In other words, you could use `grid_search` to search for the best\n",
    "    `batch_size` or `epochs` as well as the model parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, build_fn=None, **sk_params):\n",
    "        self.build_fn = build_fn\n",
    "        self.sk_params = sk_params\n",
    "        self.check_params(sk_params)\n",
    "\n",
    "    def check_params(self, params):\n",
    "        \"\"\"Checks for user typos in `params`.\n",
    "\n",
    "        # Arguments\n",
    "            params: dictionary; the parameters to be checked\n",
    "\n",
    "        # Raises\n",
    "            ValueError: if any member of `params` is not a valid argument.\n",
    "        \"\"\"\n",
    "        legal_params_fns = [Sequential.fit, Sequential.predict,\n",
    "                            Sequential.predict_classes, Sequential.evaluate]\n",
    "        if self.build_fn is None:\n",
    "            legal_params_fns.append(self.__call__)\n",
    "        elif (not isinstance(self.build_fn, types.FunctionType) and\n",
    "              not isinstance(self.build_fn, types.MethodType)):\n",
    "            legal_params_fns.append(self.build_fn.__call__)\n",
    "        else:\n",
    "            legal_params_fns.append(self.build_fn)\n",
    "\n",
    "        for params_name in params:\n",
    "            for fn in legal_params_fns:\n",
    "                if has_arg(fn, params_name):\n",
    "                    break\n",
    "            else:\n",
    "                if params_name != 'nb_epoch':\n",
    "                    raise ValueError(\n",
    "                        '{} is not a legal parameter'.format(params_name))\n",
    "\n",
    "    def get_params(self, **params):\n",
    "        \"\"\"Gets parameters for this estimator.\n",
    "\n",
    "        # Arguments\n",
    "            **params: ignored (exists for API compatibility).\n",
    "\n",
    "        # Returns\n",
    "            Dictionary of parameter names mapped to their values.\n",
    "        \"\"\"\n",
    "        res = copy.deepcopy(self.sk_params)\n",
    "        res.update({'build_fn': self.build_fn})\n",
    "        return res\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        \"\"\"Sets the parameters of this estimator.\n",
    "\n",
    "        # Arguments\n",
    "            **params: Dictionary of parameter names mapped to their values.\n",
    "\n",
    "        # Returns\n",
    "            self\n",
    "        \"\"\"\n",
    "        self.check_params(params)\n",
    "        self.sk_params.update(params)\n",
    "        return self\n",
    "\n",
    "    def fit(self, x, y, **kwargs):\n",
    "        \"\"\"Constructs a new model with `build_fn` & fit the model to `(x, y)`.\n",
    "\n",
    "        # Arguments\n",
    "            x : array-like, shape `(n_samples, n_features)`\n",
    "                Training samples where `n_samples` is the number of samples\n",
    "                and `n_features` is the number of features.\n",
    "            y : array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n",
    "                True labels for `x`.\n",
    "            **kwargs: dictionary arguments\n",
    "                Legal arguments are the arguments of `Sequential.fit`\n",
    "\n",
    "        # Returns\n",
    "            history : object\n",
    "                details about the training history at each epoch.\n",
    "        \"\"\"\n",
    "        if self.build_fn is None:\n",
    "            self.model = self.__call__(**self.filter_sk_params(self.__call__))\n",
    "        elif (not isinstance(self.build_fn, types.FunctionType) and\n",
    "              not isinstance(self.build_fn, types.MethodType)):\n",
    "            self.model = self.build_fn(\n",
    "                **self.filter_sk_params(self.build_fn.__call__))\n",
    "        else:\n",
    "            self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
    "\n",
    "        loss_name = self.model.loss\n",
    "        if hasattr(loss_name, '__name__'):\n",
    "            loss_name = loss_name.__name__\n",
    "        if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:\n",
    "            y = to_categorical(y)\n",
    "\n",
    "        fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n",
    "        fit_args.update(kwargs)\n",
    "\n",
    "        history = self.model.fit(x, y, **fit_args)\n",
    "\n",
    "        return history\n",
    "\n",
    "    def filter_sk_params(self, fn, override=None):\n",
    "        \"\"\"Filters `sk_params` and returns those in `fn`'s arguments.\n",
    "\n",
    "        # Arguments\n",
    "            fn : arbitrary function\n",
    "            override: dictionary, values to override `sk_params`\n",
    "\n",
    "        # Returns\n",
    "            res : dictionary containing variables\n",
    "                in both `sk_params` and `fn`'s arguments.\n",
    "        \"\"\"\n",
    "        override = override or {}\n",
    "        res = {}\n",
    "        for name, value in self.sk_params.items():\n",
    "            if has_arg(fn, name):\n",
    "                res.update({name: value})\n",
    "        res.update(override)\n",
    "        return res\n",
    "\n",
    "\n",
    "class KerasClassifier(BaseWrapper):\n",
    "    \"\"\"Implementation of the scikit-learn classifier API for Keras.\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, x, y, sample_weight=None, **kwargs):\n",
    "        \"\"\"Constructs a new model with `build_fn` & fit the model to `(x, y)`.\n",
    "\n",
    "        # Arguments\n",
    "            x : array-like, shape `(n_samples, n_features)`\n",
    "                Training samples where `n_samples` is the number of samples\n",
    "                and `n_features` is the number of features.\n",
    "            y : array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n",
    "                True labels for `x`.\n",
    "            **kwargs: dictionary arguments\n",
    "                Legal arguments are the arguments of `Sequential.fit`\n",
    "\n",
    "        # Returns\n",
    "            history : object\n",
    "                details about the training history at each epoch.\n",
    "\n",
    "        # Raises\n",
    "            ValueError: In case of invalid shape for `y` argument.\n",
    "        \"\"\"\n",
    "        y = np.array(y)\n",
    "        if len(y.shape) == 2 and y.shape[1] > 1:\n",
    "            self.classes_ = np.arange(y.shape[1])\n",
    "        elif (len(y.shape) == 2 and y.shape[1] == 1) or len(y.shape) == 1:\n",
    "            self.classes_ = np.unique(y)\n",
    "            y = np.searchsorted(self.classes_, y)\n",
    "        else:\n",
    "            raise ValueError('Invalid shape for y: ' + str(y.shape))\n",
    "        self.n_classes_ = len(self.classes_)\n",
    "        if sample_weight is not None:\n",
    "            \n",
    "            \n",
    "            kwargs['sample_weight'] = sample_weight\n",
    "        return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
    "\n",
    "    def predict(self, x, **kwargs):\n",
    "        \"\"\"Returns the class predictions for the given test data.\n",
    "\n",
    "        # Arguments\n",
    "            x: array-like, shape `(n_samples, n_features)`\n",
    "                Test samples where `n_samples` is the number of samples\n",
    "                and `n_features` is the number of features.\n",
    "            **kwargs: dictionary arguments\n",
    "                Legal arguments are the arguments\n",
    "                of `Sequential.predict_classes`.\n",
    "\n",
    "        # Returns\n",
    "            preds: array-like, shape `(n_samples,)`\n",
    "                Class predictions.\n",
    "        \"\"\"\n",
    "        kwargs = self.filter_sk_params(Sequential.predict_classes, kwargs)\n",
    "        classes = self.model.predict_classes(x, **kwargs)\n",
    "        return self.classes_[classes]\n",
    "\n",
    "    def predict_proba(self, x, **kwargs):\n",
    "        \"\"\"Returns class probability estimates for the given test data.\n",
    "\n",
    "        # Arguments\n",
    "            x: array-like, shape `(n_samples, n_features)`\n",
    "                Test samples where `n_samples` is the number of samples\n",
    "                and `n_features` is the number of features.\n",
    "            **kwargs: dictionary arguments\n",
    "                Legal arguments are the arguments\n",
    "                of `Sequential.predict_classes`.\n",
    "\n",
    "        # Returns\n",
    "            proba: array-like, shape `(n_samples, n_outputs)`\n",
    "                Class probability estimates.\n",
    "                In the case of binary classification,\n",
    "                to match the scikit-learn API,\n",
    "                will return an array of shape `(n_samples, 2)`\n",
    "                (instead of `(n_sample, 1)` as in Keras).\n",
    "        \"\"\"\n",
    "        kwargs = self.filter_sk_params(Sequential.predict_proba, kwargs)\n",
    "        probs = self.model.predict_proba(x, **kwargs)\n",
    "\n",
    "        # check if binary classification\n",
    "        if probs.shape[1] == 1:\n",
    "            # first column is probability of class 0 and second is of class 1\n",
    "            probs = np.hstack([1 - probs, probs])\n",
    "        return probs\n",
    "\n",
    "    def score(self, x, y, **kwargs):\n",
    "        \"\"\"Returns the mean accuracy on the given test data and labels.\n",
    "\n",
    "        # Arguments\n",
    "            x: array-like, shape `(n_samples, n_features)`\n",
    "                Test samples where `n_samples` is the number of samples\n",
    "                and `n_features` is the number of features.\n",
    "            y: array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n",
    "                True labels for `x`.\n",
    "            **kwargs: dictionary arguments\n",
    "                Legal arguments are the arguments of `Sequential.evaluate`.\n",
    "\n",
    "        # Returns\n",
    "            score: float\n",
    "                Mean accuracy of predictions on `x` wrt. `y`.\n",
    "\n",
    "        # Raises\n",
    "            ValueError: If the underlying model isn't configured to\n",
    "                compute accuracy. You should pass `metrics=[\"accuracy\"]` to\n",
    "                the `.compile()` method of the model.\n",
    "        \"\"\"\n",
    "        y = np.searchsorted(self.classes_, y)\n",
    "        kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n",
    "\n",
    "        loss_name = self.model.loss\n",
    "        if hasattr(loss_name, '__name__'):\n",
    "            loss_name = loss_name.__name__\n",
    "        if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:\n",
    "            y = to_categorical(y)\n",
    "\n",
    "        outputs = self.model.evaluate(x, y, **kwargs)\n",
    "        if not isinstance(outputs, list):\n",
    "            outputs = [outputs]\n",
    "        for name, output in zip(self.model.metrics_names, outputs):\n",
    "            if name == 'acc':\n",
    "                return output\n",
    "        raise ValueError('The model is not configured to compute accuracy. '\n",
    "                         'You should pass `metrics=[\"accuracy\"]` to '\n",
    "                         'the `model.compile()` method.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78723caf",
   "metadata": {},
   "source": [
    "# Apply AdaboostClassifier\n",
    "## adaboost1, get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5783db33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n",
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "seed_num = 42\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Dropout, LSTM, InputLayer\n",
    "from sklearn.ensemble import VotingClassifier, AdaBoostClassifier\n",
    "\n",
    "from sklearn import metrics \n",
    "from tensorflow import keras\n",
    "# from keras.wrappers.scikit_learn import KerasClassifier\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    lstm = Sequential()\n",
    "    lstm.add(InputLayer(input_shape=(x.shape[1],x.shape[2])))\n",
    "    lstm.add(LSTM(units=128, activation='hard_sigmoid', return_sequences=True))\n",
    "    lstm.add(LSTM(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "    lstm.add(Dropout(0.2))\n",
    "    lstm.add(LSTM(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "    lstm.add(LSTM(units=32, activation='hard_sigmoid', return_sequences=False))\n",
    "    lstm.add(Dropout(0.2))\n",
    "    lstm.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    lstm.compile(optimizer= keras.optimizers.Adam(learning_rate = 0.001), \n",
    "                          loss = \"binary_crossentropy\", metrics=['acc'])\n",
    "    return lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "901925f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "78/78 [==============================] - 10s 75ms/step - loss: 0.6781 - acc: 0.6002 - val_loss: 0.6641 - val_acc: 0.6112\n",
      "Epoch 2/100\n",
      "78/78 [==============================] - 5s 69ms/step - loss: 0.6013 - acc: 0.6762 - val_loss: 0.5172 - val_acc: 0.7599\n",
      "Epoch 3/100\n",
      "78/78 [==============================] - 5s 69ms/step - loss: 0.4615 - acc: 0.7990 - val_loss: 0.5098 - val_acc: 0.7526\n",
      "Epoch 4/100\n",
      "78/78 [==============================] - 5s 69ms/step - loss: 0.3927 - acc: 0.8364 - val_loss: 0.5613 - val_acc: 0.7348\n",
      "Epoch 5/100\n",
      "78/78 [==============================] - 5s 70ms/step - loss: 0.3561 - acc: 0.8572 - val_loss: 0.5403 - val_acc: 0.7534\n",
      "Epoch 6/100\n",
      "78/78 [==============================] - 5s 69ms/step - loss: 0.3216 - acc: 0.8770 - val_loss: 0.5544 - val_acc: 0.7470\n",
      "Epoch 7/100\n",
      "78/78 [==============================] - 5s 68ms/step - loss: 0.2899 - acc: 0.8948 - val_loss: 0.5911 - val_acc: 0.7518\n",
      "Epoch 8/100\n",
      "78/78 [==============================] - 6s 71ms/step - loss: 0.2483 - acc: 0.9187 - val_loss: 0.6375 - val_acc: 0.7502\n",
      "Epoch 9/100\n",
      "78/78 [==============================] - 5s 70ms/step - loss: 0.2290 - acc: 0.9256 - val_loss: 0.7174 - val_acc: 0.7365\n",
      "Epoch 10/100\n",
      "78/78 [==============================] - 5s 69ms/step - loss: 0.2127 - acc: 0.9296 - val_loss: 0.7129 - val_acc: 0.7437\n",
      "Epoch 11/100\n",
      "78/78 [==============================] - 5s 70ms/step - loss: 0.1767 - acc: 0.9474 - val_loss: 0.7847 - val_acc: 0.7421\n",
      "Epoch 12/100\n",
      "78/78 [==============================] - 5s 69ms/step - loss: 0.1700 - acc: 0.9488 - val_loss: 0.8095 - val_acc: 0.7219\n",
      "Epoch 00012: early stopping\n",
      " accuracy : 0.7423948220064724, precision : 0.8185096153846154, recall : 0.7338362068965517, f1 : 0.7738636363636364, roc_auc : 0.7445518149555692\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_acc', patience=10, verbose=1, restore_best_weights=False)\n",
    "\n",
    "model = get_model()\n",
    "model.fit(X_train,y_train, validation_split = 0.2, epochs=100, batch_size=64, callbacks=[early_stop])\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "preds[preds>0.5] = 1\n",
    "preds[preds<=0.5] = 0\n",
    "\n",
    "precision = precision_score(y_test, preds)\n",
    "recall = recall_score(y_test, preds)\n",
    "f1 = f1_score(y_test, preds)\n",
    "roc_auc = roc_auc_score(y_test, preds)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "\n",
    "print(f' accuracy : {acc}, precision : {precision}, recall : {recall}, f1 : {f1}, roc_auc : {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c8b24f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaboost\n",
    "# GRU_Predictors = KerasClassifier(build_fn=lambda:lstm, epochs=20, batch_size=256)\n",
    "lstm_Predictors = KerasClassifier(build_fn=lambda:get_model(), epochs=100, batch_size=64)\n",
    "lstm_Predictors._estimator_type=\"classifier\"\n",
    "final_model = AdaBoostClassifier(lstm_Predictors, n_estimators=5, random_state=42, learning_rate=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c80c227",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "97/97 [==============================] - 10s 63ms/step - loss: 1.0893e-04 - acc: 0.6079\n",
      "Epoch 2/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0904e-04 - acc: 0.6076\n",
      "Epoch 3/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0861e-04 - acc: 0.6105\n",
      "Epoch 4/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0840e-04 - acc: 0.6119\n",
      "Epoch 5/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0850e-04 - acc: 0.6124\n",
      "Epoch 6/100\n",
      "97/97 [==============================] - 6s 62ms/step - loss: 1.0856e-04 - acc: 0.6132\n",
      "Epoch 7/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0829e-04 - acc: 0.6124\n",
      "Epoch 8/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0835e-04 - acc: 0.6127\n",
      "Epoch 9/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0835e-04 - acc: 0.6129\n",
      "Epoch 10/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0827e-04 - acc: 0.6124\n",
      "Epoch 11/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0849e-04 - acc: 0.6132\n",
      "Epoch 12/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0820e-04 - acc: 0.6127\n",
      "Epoch 13/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0816e-04 - acc: 0.6131\n",
      "Epoch 14/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0816e-04 - acc: 0.6131\n",
      "Epoch 15/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0825e-04 - acc: 0.6132\n",
      "Epoch 16/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0817e-04 - acc: 0.6131\n",
      "Epoch 17/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0810e-04 - acc: 0.6131\n",
      "Epoch 18/100\n",
      "97/97 [==============================] - 6s 61ms/step - loss: 1.0805e-04 - acc: 0.6131\n",
      "Epoch 19/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0806e-04 - acc: 0.6131\n",
      "Epoch 20/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0814e-04 - acc: 0.6131\n",
      "Epoch 21/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0820e-04 - acc: 0.6131\n",
      "Epoch 22/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0808e-04 - acc: 0.6131\n",
      "Epoch 23/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0819e-04 - acc: 0.6131\n",
      "Epoch 24/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0824e-04 - acc: 0.6131\n",
      "Epoch 25/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0810e-04 - acc: 0.6131\n",
      "Epoch 26/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0810e-04 - acc: 0.6131\n",
      "Epoch 27/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0806e-04 - acc: 0.6131\n",
      "Epoch 28/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0809e-04 - acc: 0.6131\n",
      "Epoch 29/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0807e-04 - acc: 0.6131\n",
      "Epoch 30/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0801e-04 - acc: 0.6131\n",
      "Epoch 31/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0806e-04 - acc: 0.6131\n",
      "Epoch 32/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0807e-04 - acc: 0.6131\n",
      "Epoch 33/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0803e-04 - acc: 0.6131\n",
      "Epoch 34/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0798e-04 - acc: 0.6131\n",
      "Epoch 35/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0800e-04 - acc: 0.6131\n",
      "Epoch 36/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0807e-04 - acc: 0.6131\n",
      "Epoch 37/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0806e-04 - acc: 0.6131\n",
      "Epoch 38/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.0796e-04 - acc: 0.6131\n",
      "Epoch 39/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0811e-04 - acc: 0.6131\n",
      "Epoch 40/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0803e-04 - acc: 0.6131\n",
      "Epoch 41/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0796e-04 - acc: 0.6131\n",
      "Epoch 42/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0807e-04 - acc: 0.6131\n",
      "Epoch 43/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0805e-04 - acc: 0.6131\n",
      "Epoch 44/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0797e-04 - acc: 0.6131\n",
      "Epoch 45/100\n",
      "97/97 [==============================] - 6s 62ms/step - loss: 1.0793e-04 - acc: 0.6131\n",
      "Epoch 46/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0797e-04 - acc: 0.6131\n",
      "Epoch 47/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0820e-04 - acc: 0.6131\n",
      "Epoch 48/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0800e-04 - acc: 0.6131\n",
      "Epoch 49/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0795e-04 - acc: 0.6131\n",
      "Epoch 50/100\n",
      "97/97 [==============================] - 6s 62ms/step - loss: 1.0799e-04 - acc: 0.6131\n",
      "Epoch 51/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0795e-04 - acc: 0.6131\n",
      "Epoch 52/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0804e-04 - acc: 0.6131\n",
      "Epoch 53/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0800e-04 - acc: 0.6131\n",
      "Epoch 54/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0802e-04 - acc: 0.6131\n",
      "Epoch 55/100\n",
      "97/97 [==============================] - 6s 62ms/step - loss: 1.0795e-04 - acc: 0.6131\n",
      "Epoch 56/100\n",
      "97/97 [==============================] - 7s 66ms/step - loss: 1.0813e-04 - acc: 0.6131\n",
      "Epoch 57/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0792e-04 - acc: 0.6131\n",
      "Epoch 58/100\n",
      "97/97 [==============================] - 6s 67ms/step - loss: 1.0800e-04 - acc: 0.6131\n",
      "Epoch 59/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0797e-04 - acc: 0.6131\n",
      "Epoch 60/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0800e-04 - acc: 0.6131\n",
      "Epoch 61/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0801e-04 - acc: 0.6131\n",
      "Epoch 62/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0795e-04 - acc: 0.6131\n",
      "Epoch 63/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0797e-04 - acc: 0.6131\n",
      "Epoch 64/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.0800e-04 - acc: 0.6131\n",
      "Epoch 65/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0796e-04 - acc: 0.6131\n",
      "Epoch 66/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.0800e-04 - acc: 0.6131\n",
      "Epoch 67/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.0799e-04 - acc: 0.6131\n",
      "Epoch 68/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.0791e-04 - acc: 0.6131\n",
      "Epoch 69/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0790e-04 - acc: 0.6131\n",
      "Epoch 70/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0790e-04 - acc: 0.6131\n",
      "Epoch 71/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.0794e-04 - acc: 0.6131\n",
      "Epoch 72/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0787e-04 - acc: 0.6131\n",
      "Epoch 73/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.0778e-04 - acc: 0.6131\n",
      "Epoch 74/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0782e-04 - acc: 0.6131\n",
      "Epoch 75/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0760e-04 - acc: 0.6131\n",
      "Epoch 76/100\n",
      "97/97 [==============================] - 6s 67ms/step - loss: 1.0750e-04 - acc: 0.6131\n",
      "Epoch 77/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0713e-04 - acc: 0.6131\n",
      "Epoch 78/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.0623e-04 - acc: 0.6131\n",
      "Epoch 79/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0334e-04 - acc: 0.6131\n",
      "Epoch 80/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 9.5938e-05 - acc: 0.6262\n",
      "Epoch 81/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 8.9702e-05 - acc: 0.7109\n",
      "Epoch 82/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 8.3249e-05 - acc: 0.7485\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 6s 66ms/step - loss: 8.1240e-05 - acc: 0.7567\n",
      "Epoch 84/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 7.7148e-05 - acc: 0.7794\n",
      "Epoch 85/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 7.3780e-05 - acc: 0.7934\n",
      "Epoch 86/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 7.0598e-05 - acc: 0.8004\n",
      "Epoch 87/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 6.9377e-05 - acc: 0.8064\n",
      "Epoch 88/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 6.6198e-05 - acc: 0.8213\n",
      "Epoch 89/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 6.2910e-05 - acc: 0.8323\n",
      "Epoch 90/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 6.2228e-05 - acc: 0.8331\n",
      "Epoch 91/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 6.0333e-05 - acc: 0.8444\n",
      "Epoch 92/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 5.9340e-05 - acc: 0.8475\n",
      "Epoch 93/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 5.7681e-05 - acc: 0.8505\n",
      "Epoch 94/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 5.4578e-05 - acc: 0.8636\n",
      "Epoch 95/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 5.3608e-05 - acc: 0.8670\n",
      "Epoch 96/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 5.1134e-05 - acc: 0.8782\n",
      "Epoch 97/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 5.1263e-05 - acc: 0.8784\n",
      "Epoch 98/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 4.9267e-05 - acc: 0.8808\n",
      "Epoch 99/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 4.5991e-05 - acc: 0.8937\n",
      "Epoch 100/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 4.5277e-05 - acc: 0.8949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guri99/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:430: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_80 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_80 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_81 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_81 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_82 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_82 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_83 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_83 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "97/97 [==============================] - 9s 64ms/step - loss: 1.0948e-04 - acc: 0.4078\n",
      "Epoch 2/100\n",
      "97/97 [==============================] - 6s 62ms/step - loss: 1.0791e-04 - acc: 0.3902\n",
      "Epoch 3/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0718e-04 - acc: 0.3879\n",
      "Epoch 4/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0726e-04 - acc: 0.3879\n",
      "Epoch 5/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0613e-04 - acc: 0.3866\n",
      "Epoch 6/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0670e-04 - acc: 0.3889\n",
      "Epoch 7/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.0665e-04 - acc: 0.3864\n",
      "Epoch 8/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.0661e-04 - acc: 0.3871\n",
      "Epoch 9/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0587e-04 - acc: 0.3877\n",
      "Epoch 10/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0617e-04 - acc: 0.3873\n",
      "Epoch 11/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0676e-04 - acc: 0.3873\n",
      "Epoch 12/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0667e-04 - acc: 0.3873\n",
      "Epoch 13/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0650e-04 - acc: 0.3871\n",
      "Epoch 14/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0638e-04 - acc: 0.3868\n",
      "Epoch 15/100\n",
      "97/97 [==============================] - 7s 68ms/step - loss: 1.0655e-04 - acc: 0.3869\n",
      "Epoch 16/100\n",
      "97/97 [==============================] - 6s 67ms/step - loss: 1.0679e-04 - acc: 0.3868\n",
      "Epoch 17/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0636e-04 - acc: 0.3869\n",
      "Epoch 18/100\n",
      "97/97 [==============================] - 6s 67ms/step - loss: 1.0695e-04 - acc: 0.3869\n",
      "Epoch 19/100\n",
      "97/97 [==============================] - 6s 67ms/step - loss: 1.0604e-04 - acc: 0.3869\n",
      "Epoch 20/100\n",
      "97/97 [==============================] - 6s 67ms/step - loss: 1.0636e-04 - acc: 0.3869\n",
      "Epoch 21/100\n",
      "97/97 [==============================] - 7s 67ms/step - loss: 1.0646e-04 - acc: 0.3869\n",
      "Epoch 22/100\n",
      "97/97 [==============================] - 6s 67ms/step - loss: 1.0607e-04 - acc: 0.3869\n",
      "Epoch 23/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0659e-04 - acc: 0.3869\n",
      "Epoch 24/100\n",
      "97/97 [==============================] - 7s 67ms/step - loss: 1.0593e-04 - acc: 0.3869\n",
      "Epoch 25/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.0640e-04 - acc: 0.3869\n",
      "Epoch 26/100\n",
      "97/97 [==============================] - 7s 68ms/step - loss: 1.0599e-04 - acc: 0.3869\n",
      "Epoch 27/100\n",
      "97/97 [==============================] - 6s 67ms/step - loss: 1.0637e-04 - acc: 0.3869\n",
      "Epoch 28/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0613e-04 - acc: 0.3869\n",
      "Epoch 29/100\n",
      "97/97 [==============================] - 6s 67ms/step - loss: 1.0609e-04 - acc: 0.3869\n",
      "Epoch 30/100\n",
      "97/97 [==============================] - 7s 67ms/step - loss: 1.0657e-04 - acc: 0.3869\n",
      "Epoch 31/100\n",
      "97/97 [==============================] - 6s 67ms/step - loss: 1.0624e-04 - acc: 0.3869\n",
      "Epoch 32/100\n",
      "97/97 [==============================] - 6s 67ms/step - loss: 1.0626e-04 - acc: 0.3869\n",
      "Epoch 33/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.0610e-04 - acc: 0.3869\n",
      "Epoch 34/100\n",
      "97/97 [==============================] - 6s 67ms/step - loss: 1.0630e-04 - acc: 0.3869\n",
      "Epoch 35/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0630e-04 - acc: 0.3869\n",
      "Epoch 36/100\n",
      "97/97 [==============================] - 7s 67ms/step - loss: 1.0606e-04 - acc: 0.3869\n",
      "Epoch 37/100\n",
      "97/97 [==============================] - 6s 67ms/step - loss: 1.0624e-04 - acc: 0.3869\n",
      "Epoch 38/100\n",
      "97/97 [==============================] - 7s 67ms/step - loss: 1.0624e-04 - acc: 0.3869\n",
      "Epoch 39/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0627e-04 - acc: 0.3869\n",
      "Epoch 40/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0615e-04 - acc: 0.3869\n",
      "Epoch 41/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0635e-04 - acc: 0.3869\n",
      "Epoch 42/100\n",
      "97/97 [==============================] - 6s 67ms/step - loss: 1.0615e-04 - acc: 0.3869\n",
      "Epoch 43/100\n",
      "97/97 [==============================] - 6s 67ms/step - loss: 1.0613e-04 - acc: 0.3869\n",
      "Epoch 44/100\n",
      "97/97 [==============================] - 7s 67ms/step - loss: 1.0629e-04 - acc: 0.3869\n",
      "Epoch 45/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0622e-04 - acc: 0.3869\n",
      "Epoch 46/100\n",
      "97/97 [==============================] - 6s 67ms/step - loss: 1.0627e-04 - acc: 0.3869\n",
      "Epoch 47/100\n",
      "97/97 [==============================] - 7s 67ms/step - loss: 1.0604e-04 - acc: 0.3869\n",
      "Epoch 48/100\n",
      "97/97 [==============================] - 7s 67ms/step - loss: 1.0629e-04 - acc: 0.3869\n",
      "Epoch 49/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0636e-04 - acc: 0.3869\n",
      "Epoch 50/100\n",
      "97/97 [==============================] - 7s 68ms/step - loss: 1.0617e-04 - acc: 0.3869\n",
      "Epoch 51/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0614e-04 - acc: 0.3869\n",
      "Epoch 52/100\n",
      "97/97 [==============================] - 6s 67ms/step - loss: 1.0596e-04 - acc: 0.3869\n",
      "Epoch 53/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0646e-04 - acc: 0.3869\n",
      "Epoch 54/100\n",
      "97/97 [==============================] - 7s 67ms/step - loss: 1.0631e-04 - acc: 0.3869\n",
      "Epoch 55/100\n",
      "97/97 [==============================] - 6s 67ms/step - loss: 1.0640e-04 - acc: 0.3869\n",
      "Epoch 56/100\n",
      "97/97 [==============================] - 6s 67ms/step - loss: 1.0606e-04 - acc: 0.3869\n",
      "Epoch 57/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.0593e-04 - acc: 0.3869\n",
      "Epoch 58/100\n",
      "97/97 [==============================] - 7s 67ms/step - loss: 1.0590e-04 - acc: 0.3869\n",
      "Epoch 59/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0623e-04 - acc: 0.3869\n",
      "Epoch 60/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0610e-04 - acc: 0.3869\n",
      "Epoch 61/100\n",
      "97/97 [==============================] - 7s 67ms/step - loss: 1.0599e-04 - acc: 0.3869\n",
      "Epoch 62/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0604e-04 - acc: 0.3869\n",
      "Epoch 63/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0621e-04 - acc: 0.3869\n",
      "Epoch 64/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.0622e-04 - acc: 0.3869\n",
      "Epoch 65/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0611e-04 - acc: 0.3869\n",
      "Epoch 66/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0616e-04 - acc: 0.3869\n",
      "Epoch 67/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0612e-04 - acc: 0.3869\n",
      "Epoch 68/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0586e-04 - acc: 0.3869\n",
      "Epoch 69/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0631e-04 - acc: 0.3869\n",
      "Epoch 70/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0593e-04 - acc: 0.3869\n",
      "Epoch 71/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0650e-04 - acc: 0.3869\n",
      "Epoch 72/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0597e-04 - acc: 0.3869\n",
      "Epoch 73/100\n",
      "97/97 [==============================] - 6s 61ms/step - loss: 1.0603e-04 - acc: 0.3869\n",
      "Epoch 74/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0601e-04 - acc: 0.3869\n",
      "Epoch 75/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0554e-04 - acc: 0.3869\n",
      "Epoch 76/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0613e-04 - acc: 0.3869\n",
      "Epoch 77/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0639e-04 - acc: 0.3869\n",
      "Epoch 78/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0611e-04 - acc: 0.3869\n",
      "Epoch 79/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0618e-04 - acc: 0.3869\n",
      "Epoch 80/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.0611e-04 - acc: 0.3869\n",
      "Epoch 81/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0632e-04 - acc: 0.3869\n",
      "Epoch 82/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0599e-04 - acc: 0.3869\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0595e-04 - acc: 0.3869\n",
      "Epoch 84/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0597e-04 - acc: 0.3869\n",
      "Epoch 85/100\n",
      "97/97 [==============================] - 6s 63ms/step - loss: 1.0625e-04 - acc: 0.3869\n",
      "Epoch 86/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0627e-04 - acc: 0.3869\n",
      "Epoch 87/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0605e-04 - acc: 0.3869\n",
      "Epoch 88/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0608e-04 - acc: 0.3869\n",
      "Epoch 89/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0609e-04 - acc: 0.3869\n",
      "Epoch 90/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.0605e-04 - acc: 0.3869\n",
      "Epoch 91/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0604e-04 - acc: 0.3869\n",
      "Epoch 92/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0615e-04 - acc: 0.3869\n",
      "Epoch 93/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.0607e-04 - acc: 0.3869\n",
      "Epoch 94/100\n",
      "97/97 [==============================] - 6s 67ms/step - loss: 1.0621e-04 - acc: 0.3869\n",
      "Epoch 95/100\n",
      "97/97 [==============================] - 6s 67ms/step - loss: 1.0596e-04 - acc: 0.3869\n",
      "Epoch 96/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.0610e-04 - acc: 0.3869\n",
      "Epoch 97/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0607e-04 - acc: 0.3869\n",
      "Epoch 98/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.0593e-04 - acc: 0.3869\n",
      "Epoch 99/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.0626e-04 - acc: 0.3869\n",
      "Epoch 100/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.0605e-04 - acc: 0.3869\n",
      "WARNING:tensorflow:Layer lstm_84 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_84 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_85 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_85 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_86 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_86 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_87 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_87 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "97/97 [==============================] - 9s 66ms/step - loss: 1.1326e-04 - acc: 0.5573\n",
      "Epoch 2/100\n",
      "97/97 [==============================] - 7s 68ms/step - loss: 1.1362e-04 - acc: 0.5401\n",
      "Epoch 3/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1316e-04 - acc: 0.5453\n",
      "Epoch 4/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1313e-04 - acc: 0.5513\n",
      "Epoch 5/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1287e-04 - acc: 0.5485\n",
      "Epoch 6/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1398e-04 - acc: 0.5427\n",
      "Epoch 7/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1323e-04 - acc: 0.5597\n",
      "Epoch 8/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.1270e-04 - acc: 0.5759\n",
      "Epoch 9/100\n",
      "97/97 [==============================] - 7s 67ms/step - loss: 1.1202e-04 - acc: 0.5406\n",
      "Epoch 10/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1324e-04 - acc: 0.5561\n",
      "Epoch 11/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1250e-04 - acc: 0.5852\n",
      "Epoch 12/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1213e-04 - acc: 0.5521\n",
      "Epoch 13/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1230e-04 - acc: 0.5975\n",
      "Epoch 14/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1266e-04 - acc: 0.5521\n",
      "Epoch 15/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.1204e-04 - acc: 0.5747\n",
      "Epoch 16/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.1206e-04 - acc: 0.5489\n",
      "Epoch 17/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1249e-04 - acc: 0.5987\n",
      "Epoch 18/100\n",
      "97/97 [==============================] - 6s 67ms/step - loss: 1.1196e-04 - acc: 0.5467\n",
      "Epoch 19/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1236e-04 - acc: 0.5946\n",
      "Epoch 20/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1202e-04 - acc: 0.5948:\n",
      "Epoch 21/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1236e-04 - acc: 0.5848\n",
      "Epoch 22/100\n",
      "97/97 [==============================] - 6s 67ms/step - loss: 1.1211e-04 - acc: 0.5886\n",
      "Epoch 23/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1226e-04 - acc: 0.6005\n",
      "Epoch 24/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.1237e-04 - acc: 0.5620\n",
      "Epoch 25/100\n",
      "97/97 [==============================] - 7s 68ms/step - loss: 1.1205e-04 - acc: 0.5911\n",
      "Epoch 26/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1182e-04 - acc: 0.6006\n",
      "Epoch 27/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1210e-04 - acc: 0.6017\n",
      "Epoch 28/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1227e-04 - acc: 0.5882\n",
      "Epoch 29/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1201e-04 - acc: 0.5972\n",
      "Epoch 30/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1210e-04 - acc: 0.6047\n",
      "Epoch 31/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1167e-04 - acc: 0.6106\n",
      "Epoch 32/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1247e-04 - acc: 0.5501\n",
      "Epoch 33/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.1239e-04 - acc: 0.6087\n",
      "Epoch 34/100\n",
      "97/97 [==============================] - 7s 68ms/step - loss: 1.1217e-04 - acc: 0.6105\n",
      "Epoch 35/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1228e-04 - acc: 0.6089\n",
      "Epoch 36/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1164e-04 - acc: 0.6124\n",
      "Epoch 37/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1201e-04 - acc: 0.6123\n",
      "Epoch 38/100\n",
      "97/97 [==============================] - 6s 67ms/step - loss: 1.1194e-04 - acc: 0.6119\n",
      "Epoch 39/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1211e-04 - acc: 0.6121\n",
      "Epoch 40/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1194e-04 - acc: 0.6119\n",
      "Epoch 41/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1193e-04 - acc: 0.6116\n",
      "Epoch 42/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1190e-04 - acc: 0.6126\n",
      "Epoch 43/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1216e-04 - acc: 0.5964\n",
      "Epoch 44/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1202e-04 - acc: 0.6127\n",
      "Epoch 45/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1183e-04 - acc: 0.6129\n",
      "Epoch 46/100\n",
      "97/97 [==============================] - 7s 67ms/step - loss: 1.1198e-04 - acc: 0.6131\n",
      "Epoch 47/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.1192e-04 - acc: 0.6131\n",
      "Epoch 48/100\n",
      "97/97 [==============================] - 7s 68ms/step - loss: 1.1189e-04 - acc: 0.6132\n",
      "Epoch 49/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1175e-04 - acc: 0.6131\n",
      "Epoch 50/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1181e-04 - acc: 0.6131\n",
      "Epoch 51/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1202e-04 - acc: 0.6131\n",
      "Epoch 52/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1192e-04 - acc: 0.6129\n",
      "Epoch 53/100\n",
      "97/97 [==============================] - 6s 67ms/step - loss: 1.1192e-04 - acc: 0.6131\n",
      "Epoch 54/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1184e-04 - acc: 0.6131\n",
      "Epoch 55/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1196e-04 - acc: 0.6121\n",
      "Epoch 56/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.1184e-04 - acc: 0.6131\n",
      "Epoch 57/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.1200e-04 - acc: 0.6131\n",
      "Epoch 58/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1183e-04 - acc: 0.6131\n",
      "Epoch 59/100\n",
      "97/97 [==============================] - 7s 67ms/step - loss: 1.1185e-04 - acc: 0.6131\n",
      "Epoch 60/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1188e-04 - acc: 0.6131\n",
      "Epoch 61/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.1180e-04 - acc: 0.6131\n",
      "Epoch 62/100\n",
      "97/97 [==============================] - 7s 67ms/step - loss: 1.1192e-04 - acc: 0.6131\n",
      "Epoch 63/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1188e-04 - acc: 0.6131\n",
      "Epoch 64/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1173e-04 - acc: 0.6131\n",
      "Epoch 65/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1190e-04 - acc: 0.6131\n",
      "Epoch 66/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.1180e-04 - acc: 0.6131\n",
      "Epoch 67/100\n",
      "97/97 [==============================] - 7s 67ms/step - loss: 1.1179e-04 - acc: 0.6131\n",
      "Epoch 68/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1182e-04 - acc: 0.6131\n",
      "Epoch 69/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1182e-04 - acc: 0.6131\n",
      "Epoch 70/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1179e-04 - acc: 0.6131\n",
      "Epoch 71/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.1187e-04 - acc: 0.6131\n",
      "Epoch 72/100\n",
      "97/97 [==============================] - 7s 68ms/step - loss: 1.1186e-04 - acc: 0.6131\n",
      "Epoch 73/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1181e-04 - acc: 0.6131\n",
      "Epoch 74/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1188e-04 - acc: 0.6131\n",
      "Epoch 75/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1181e-04 - acc: 0.6131\n",
      "Epoch 76/100\n",
      "97/97 [==============================] - 6s 66ms/step - loss: 1.1191e-04 - acc: 0.6131\n",
      "Epoch 77/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.1181e-04 - acc: 0.6131\n",
      "Epoch 78/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.1178e-04 - acc: 0.6131\n",
      "Epoch 79/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.1188e-04 - acc: 0.6131\n",
      "Epoch 80/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.1175e-04 - acc: 0.6131\n",
      "Epoch 81/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.1181e-04 - acc: 0.6131\n",
      "Epoch 82/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.1179e-04 - acc: 0.6131\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 6s 65ms/step - loss: 1.1180e-04 - acc: 0.6131\n",
      "Epoch 84/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.1181e-04 - acc: 0.6131\n",
      "Epoch 85/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.1179e-04 - acc: 0.6131\n",
      "Epoch 86/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.1185e-04 - acc: 0.6131\n",
      "Epoch 87/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.1186e-04 - acc: 0.6131\n",
      "Epoch 88/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.1180e-04 - acc: 0.6131\n",
      "Epoch 89/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.1181e-04 - acc: 0.6131\n",
      "Epoch 90/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.1189e-04 - acc: 0.6131\n",
      "Epoch 91/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.1180e-04 - acc: 0.6131\n",
      "Epoch 92/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.1181e-04 - acc: 0.6131\n",
      "Epoch 93/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.1185e-04 - acc: 0.6131\n",
      "Epoch 94/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.1185e-04 - acc: 0.6131\n",
      "Epoch 95/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.1176e-04 - acc: 0.6131\n",
      "Epoch 96/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.1180e-04 - acc: 0.6131\n",
      "Epoch 97/100\n",
      "97/97 [==============================] - 6s 65ms/step - loss: 1.1181e-04 - acc: 0.6131\n",
      "Epoch 98/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.1179e-04 - acc: 0.6131\n",
      "Epoch 99/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.1182e-04 - acc: 0.6131\n",
      "Epoch 100/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.1184e-04 - acc: 0.6131\n",
      "WARNING:tensorflow:Layer lstm_88 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_88 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_89 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_89 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_90 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_90 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_91 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_91 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "97/97 [==============================] - 10s 64ms/step - loss: 1.1646e-04 - acc: 0.4390\n",
      "Epoch 2/100\n",
      "97/97 [==============================] - 6s 64ms/step - loss: 1.1393e-04 - acc: 0.4859\n",
      "Epoch 3/100\n",
      " 7/97 [=>............................] - ETA: 5s - loss: 1.1582e-04 - acc: 0.5067"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0miboost\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;31m# Boosting step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             sample_weight, estimator_weight, estimator_error = self._boost(\n\u001b[0m\u001b[1;32m    146\u001b[0m                 \u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \"\"\"\n\u001b[1;32m    547\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"SAMME.R\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-16483d51d48d>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-16483d51d48d>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with tf.device('/device:GPU:0'):\n",
    "    final_model.fit(X_train,y_train, sample_weight=np.ones(X_train.shape[0])/X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "971efe0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guri99/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:430: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-8967ef417ef1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \"\"\"\n\u001b[0;32m--> 679\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"SAMME.R\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0;31m# The weights are all 1. for SAMME.R\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m             pred = sum(\n\u001b[0m\u001b[1;32m    748\u001b[0m                 \u001b[0m_samme_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m             )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0;31m# The weights are all 1. for SAMME.R\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m             pred = sum(\n\u001b[0;32m--> 748\u001b[0;31m                 \u001b[0m_samme_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m             )\n\u001b[1;32m    750\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# self.algorithm == \"SAMME\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_samme_proba\u001b[0;34m(estimator, n_classes, X)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \"\"\"\n\u001b[0;32m--> 300\u001b[0;31m     \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;31m# Displace zero probabilities so the log is defined.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-16483d51d48d>\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \"\"\"\n\u001b[1;32m    250\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_sk_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;31m# check if binary classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    431\u001b[0m                   \u001b[0;34m'will be removed after 2021-01-01. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m                   'Please use `model.predict()` instead.')\n\u001b[0;32m--> 433\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m       logging.warning('Network returning invalid probability values. '\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1694\u001b[0m                         '. Consider setting it to AutoShardPolicy.DATA.')\n\u001b[1;32m   1695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1696\u001b[0;31m       data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[1;32m   1697\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1698\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1362\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verify_data_adapter_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1155\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m                **kwargs):\n\u001b[1;32m    246\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[1;32m    249\u001b[0m         sample_weights, sample_weight_modes)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   1044\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_numpy_and_scipy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_convert_numpy_and_scipy\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor_v2_with_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0m_is_scipy_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m   \"\"\"\n\u001b[0;32m-> 1430\u001b[0;31m   return convert_to_tensor_v2(\n\u001b[0m\u001b[1;32m   1431\u001b[0m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[1;32m   1432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1434\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m   \u001b[0;34m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1436\u001b[0;31m   return convert_to_tensor(\n\u001b[0m\u001b[1;32m   1437\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m       \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m   \"\"\"\n\u001b[0;32m--> 264\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    265\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "preds = final_model.predict(X_test)\n",
    "\n",
    "precision = precision_score(y_test, preds)\n",
    "recall = recall_score(y_test, preds)\n",
    "f1 = f1_score(y_test, preds)\n",
    "roc_auc = roc_auc_score(y_test, preds)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "\n",
    "print(f' accuracy : {acc}, precision : {precision}, recall : {recall}, f1 : {f1}, roc_auc : {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689b5288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624a3c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e83d2bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guri99/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:430: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.7521035598705501\n"
     ]
    }
   ],
   "source": [
    "preds = final_model.predict(X_test)\n",
    "# preds[preds>0.5] = 1\n",
    "# preds[preds<=0.5] = 0\n",
    "from sklearn import metrics\n",
    "print('정확도 :', metrics.accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a8c4630",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guri99/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:430: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcb28af",
   "metadata": {},
   "source": [
    "## adaboost 2\n",
    "- 참고한 github\n",
    "- https://github.com/limitless083/timeseries-forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65139810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def calc_error(y, y_):\n",
    "    return np.sqrt((y - y_) ** 2)\n",
    "\n",
    "\n",
    "class AdaBoost:\n",
    "    def __init__(self, trainX, trainY):\n",
    "        self.trainX = trainX\n",
    "        self.trainY = trainY\n",
    "        self.N = len(self.trainX)\n",
    "        self.weights = np.ones(self.N) / self.N\n",
    "        self.alphas = []\n",
    "        self.models = []\n",
    "\n",
    "    def set_rule(self, model):\n",
    "        predict = model.predict(self.trainX)\n",
    "        errors = []\n",
    "        for i in range(self.N):\n",
    "            errors.append(self.weights[i] * calc_error(self.trainY[i], predict[i, 0]))\n",
    "        e = np.sum(errors)\n",
    "        alpha = 0.5 * np.log((1 - e) / e)\n",
    "        print('e=%.4f a=%.4f' % (e, alpha))\n",
    "        w = np.zeros(self.N)\n",
    "        for i in range(self.N):\n",
    "            w[i] = self.weights[i] * np.exp(alpha * errors[i] / e)\n",
    "        self.weights = w / w.sum()\n",
    "        self.models.append(model)\n",
    "        self.alphas.append(alpha)\n",
    "\n",
    "    def predict(self, x_set):\n",
    "        n_models = len(self.models)\n",
    "        alpha_sum = np.sum(self.alphas)\n",
    "        final_predict = np.zeros(1)\n",
    "        for i in range(n_models):\n",
    "            predict = self.models[i].predict(x_set)\n",
    "            final_predict = final_predict + predict[:, 0] * self.alphas[i]\n",
    "        final_predict = final_predict / alpha_sum\n",
    "\n",
    "        return final_predict.reshape(len(x_set), 1)\n",
    "\n",
    "    def evaluate(self):\n",
    "        n_models = len(self.models)\n",
    "        alpha_sum = np.sum(self.alphas)\n",
    "        final_predict = np.zeros(len(self.trainX))\n",
    "        for i in range(n_models):\n",
    "            predict = self.models[i].predict(self.trainX)\n",
    "            final_predict = final_predict + predict[:, 0] * self.alphas[i]\n",
    "        final_predict = final_predict / alpha_sum\n",
    "        errors = []\n",
    "        for i in range(self.N):\n",
    "            errors.append(calc_error(self.trainY[i], final_predict[i]))\n",
    "        return np.sum(errors)\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78447586",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "40/40 - 5s - loss: 1.0949e-04 - acc: 0.5925\n",
      "Epoch 2/20\n",
      "40/40 - 3s - loss: 1.0935e-04 - acc: 0.5979\n",
      "Epoch 3/20\n",
      "40/40 - 3s - loss: 1.0992e-04 - acc: 0.5959\n",
      "Epoch 4/20\n",
      "40/40 - 3s - loss: 1.0989e-04 - acc: 0.6000\n",
      "Epoch 5/20\n",
      "40/40 - 3s - loss: 1.0933e-04 - acc: 0.5951\n",
      "Epoch 6/20\n",
      "40/40 - 3s - loss: 1.0938e-04 - acc: 0.5995\n",
      "Epoch 7/20\n",
      "40/40 - 3s - loss: 1.0936e-04 - acc: 0.6014\n",
      "Epoch 8/20\n",
      "40/40 - 3s - loss: 1.0958e-04 - acc: 0.6000\n",
      "Epoch 9/20\n",
      "40/40 - 3s - loss: 1.0910e-04 - acc: 0.6011\n",
      "Epoch 10/20\n",
      "40/40 - 3s - loss: 1.0926e-04 - acc: 0.6029\n",
      "Epoch 11/20\n",
      "40/40 - 3s - loss: 1.0906e-04 - acc: 0.6026\n",
      "Epoch 12/20\n",
      "40/40 - 3s - loss: 1.0922e-04 - acc: 0.6064\n",
      "Epoch 13/20\n",
      "40/40 - 3s - loss: 1.0903e-04 - acc: 0.6032\n",
      "Epoch 14/20\n",
      "40/40 - 3s - loss: 1.0909e-04 - acc: 0.6042\n",
      "Epoch 15/20\n",
      "40/40 - 3s - loss: 1.0904e-04 - acc: 0.6035\n",
      "Epoch 16/20\n",
      "40/40 - 3s - loss: 1.0910e-04 - acc: 0.6042\n",
      "Epoch 17/20\n",
      "40/40 - 3s - loss: 1.0886e-04 - acc: 0.6058\n",
      "Epoch 18/20\n",
      "40/40 - 3s - loss: 1.0883e-04 - acc: 0.6045\n",
      "Epoch 19/20\n",
      "40/40 - 3s - loss: 1.0904e-04 - acc: 0.6038\n",
      "Epoch 20/20\n",
      "40/40 - 3s - loss: 1.0888e-04 - acc: 0.6060\n",
      "e=0.4778 a=0.0444\n",
      "final error:  2953.856681569422\n"
     ]
    }
   ],
   "source": [
    "adaboost = AdaBoost(X_train, y_train)\n",
    "for i in range(1):\n",
    "    sample_weights = adaboost.get_weights()\n",
    "    model = get_model(seed_num)\n",
    "    model.fit(X_train, y_train, epochs=20, batch_size=156, verbose=2, sample_weight=sample_weights)\n",
    "    adaboost.set_rule(model)\n",
    "print(\"final error: \", adaboost.evaluate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3f8c687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6284789644012945"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred[pred>0.5] = 1; pred[pred<=0.5] = 0\n",
    "metrics.accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c57f61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f562a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23a8518a",
   "metadata": {},
   "source": [
    "## adaboost 3\n",
    "- 참고한 자료\n",
    "- https://stackoverflow.com/questions/64558810/how-to-use-a-keras-model-inside-of-sklearns-adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df3f0555",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyKerasClassifier(KerasClassifier):\n",
    "    def fit(self, x, y, sample_weight=None, **kwargs):\n",
    "        y = np.array(y)\n",
    "        if len(y.shape) == 2 and y.shape[1] > 1:\n",
    "            self.classes_ = np.arange(y.shape[1])\n",
    "        elif (len(y.shape) == 2 and y.shape[1] == 1) or len(y.shape) == 1:\n",
    "            self.classes_ = np.unique(y)\n",
    "            y = np.searchsorted(self.classes_, y)\n",
    "        else:\n",
    "            raise ValueError('Invalid shape for y: ' + str(y.shape))\n",
    "        self.n_classes_ = len(self.classes_)\n",
    "        if sample_weight is not None:\n",
    "            kwargs['sample_weight'] = sample_weight\n",
    "            print(type(sample_weight))\n",
    "        return super(MyKerasClassifier, self).fit(x, y, **kwargs)\n",
    "    def predict(self, x, **kwargs):\n",
    "        kwargs = self.filter_sk_params(Sequential.predict_classes, kwargs)\n",
    "        classes = self.model.predict_classes(x, **kwargs)\n",
    "        return self.classes_[classes].flatten()\n",
    "        #return super(KerasClassifier, self).fit(x, y, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a8fa9fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Epoch 1/20\n",
      "40/40 - 16s - loss: 1.0959e-04 - acc: 0.5932\n",
      "Epoch 2/20\n",
      "40/40 - 3s - loss: 1.0909e-04 - acc: 0.6030\n",
      "Epoch 3/20\n",
      "40/40 - 3s - loss: 1.0925e-04 - acc: 0.5992\n",
      "Epoch 4/20\n",
      "40/40 - 3s - loss: 1.0919e-04 - acc: 0.6030\n",
      "Epoch 5/20\n",
      "40/40 - 3s - loss: 1.0931e-04 - acc: 0.5982\n",
      "Epoch 6/20\n",
      "40/40 - 3s - loss: 1.0895e-04 - acc: 0.6050\n",
      "Epoch 7/20\n",
      "40/40 - 3s - loss: 1.0938e-04 - acc: 0.6053\n",
      "Epoch 8/20\n",
      "40/40 - 3s - loss: 1.0933e-04 - acc: 0.6006\n",
      "Epoch 9/20\n",
      "40/40 - 3s - loss: 1.0891e-04 - acc: 0.6050\n",
      "Epoch 10/20\n",
      "40/40 - 3s - loss: 1.0880e-04 - acc: 0.6056\n",
      "Epoch 11/20\n",
      "40/40 - 3s - loss: 1.0915e-04 - acc: 0.6038\n",
      "Epoch 12/20\n",
      "40/40 - 3s - loss: 1.0866e-04 - acc: 0.6060\n",
      "Epoch 13/20\n",
      "40/40 - 3s - loss: 1.0878e-04 - acc: 0.6051\n",
      "Epoch 14/20\n",
      "40/40 - 3s - loss: 1.0874e-04 - acc: 0.6066\n",
      "Epoch 15/20\n",
      "40/40 - 3s - loss: 1.0881e-04 - acc: 0.6058\n",
      "Epoch 16/20\n",
      "40/40 - 3s - loss: 1.0876e-04 - acc: 0.6056\n",
      "Epoch 17/20\n",
      "40/40 - 3s - loss: 1.0860e-04 - acc: 0.6061\n",
      "Epoch 18/20\n",
      "40/40 - 3s - loss: 1.0867e-04 - acc: 0.6058\n",
      "Epoch 19/20\n",
      "40/40 - 3s - loss: 1.0877e-04 - acc: 0.6064\n",
      "Epoch 20/20\n",
      "40/40 - 3s - loss: 1.0859e-04 - acc: 0.6061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 - 2s\n",
      "<class 'numpy.ndarray'>\n",
      "Epoch 1/20\n",
      "40/40 - 6s - loss: 1.1402e-04 - acc: 0.5325\n",
      "Epoch 2/20\n",
      "40/40 - 3s - loss: 1.1279e-04 - acc: 0.5209\n",
      "Epoch 3/20\n",
      "40/40 - 3s - loss: 1.1291e-04 - acc: 0.4982\n",
      "Epoch 4/20\n",
      "40/40 - 3s - loss: 1.1285e-04 - acc: 0.5045\n",
      "Epoch 5/20\n",
      "40/40 - 3s - loss: 1.1300e-04 - acc: 0.4995\n",
      "Epoch 6/20\n",
      "40/40 - 3s - loss: 1.1267e-04 - acc: 0.5055\n",
      "Epoch 7/20\n",
      "40/40 - 3s - loss: 1.1306e-04 - acc: 0.5152\n",
      "Epoch 8/20\n",
      "40/40 - 3s - loss: 1.1295e-04 - acc: 0.4934\n",
      "Epoch 9/20\n",
      "40/40 - 3s - loss: 1.1261e-04 - acc: 0.4913\n",
      "Epoch 10/20\n",
      "40/40 - 3s - loss: 1.1251e-04 - acc: 0.5333\n",
      "Epoch 11/20\n",
      "40/40 - 3s - loss: 1.1283e-04 - acc: 0.4948\n",
      "Epoch 12/20\n",
      "40/40 - 3s - loss: 1.1232e-04 - acc: 0.5210\n",
      "Epoch 13/20\n",
      "40/40 - 3s - loss: 1.1250e-04 - acc: 0.5160\n",
      "Epoch 14/20\n",
      "40/40 - 3s - loss: 1.1236e-04 - acc: 0.5134\n",
      "Epoch 15/20\n",
      "40/40 - 3s - loss: 1.1250e-04 - acc: 0.5070\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d45ffe294336>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mboosted_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mboosted_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0miboost\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;31m# Boosting step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             sample_weight, estimator_weight, estimator_error = self._boost(\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \"\"\"\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SAMME.R'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-f4a4bc5199e2>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMyKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_sk_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-12bca8c9feae>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-12bca8c9feae>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "base_estimator = MyKerasClassifier(build_fn=lambda:get_model(seed_num), epochs=20, batch_size=156, verbose=2)\n",
    "boosted_classifier = AdaBoostClassifier(base_estimator=base_estimator,n_estimators=10,random_state=42)\n",
    "\n",
    "boosted_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee15040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "boosted_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b92b47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bd344f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb5e31c4",
   "metadata": {},
   "source": [
    "# Apply VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abb66947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f0c1133f520>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload_model = tf.keras.models.load_model('/project/guri/Restart/models/14-0.7646.hdf5')\n",
    "reload_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df643139",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('model1', <__main__.KerasClassifier object at 0x7f0adc371a60>), ('model2', <__main__.KerasClassifier object at 0x7f0ad0273f70>), ('model3', <__main__.KerasClassifier object at 0x7f0ad0273c40>), ('model4', <__main__.KerasClassifier object at 0x7f0ad0273b20>)]\n"
     ]
    }
   ],
   "source": [
    "# voting\n",
    "# GRU_Predictors = KerasClassifier(build_fn=lambda:lstm, epochs=20, batch_size=256)\n",
    "# lstm_Predictors = KerasClassifier(build_fn=lambda:get_model(seed_num), epochs=20, batch_size=256)\n",
    "#LSTM 쌓기\n",
    "estimator = []\n",
    "for i in range(1,5):\n",
    "    LSTM_Predictors = KerasClassifier(build_fn=lambda:reload_model, epochs=20, batch_size=256)\n",
    "    LSTM_Predictors._estimator_type=\"classifier\"\n",
    "    estimator.append((f'model{i}', LSTM_Predictors))\n",
    "print(estimator) \n",
    "voting_model = VotingClassifier(estimators=estimator, voting = 'soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5bf7c94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 3s 110ms/step - loss: 0.1686 - acc: 0.9562\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 3s 105ms/step - loss: 0.1612 - acc: 0.9581\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 3s 105ms/step - loss: 0.1529 - acc: 0.9615\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 3s 107ms/step - loss: 0.1470 - acc: 0.9634\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 3s 104ms/step - loss: 0.1444 - acc: 0.9631\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.1453 - acc: 0.9634\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.1374 - acc: 0.9652\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 3s 105ms/step - loss: 0.1549 - acc: 0.9573\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.1386 - acc: 0.9657\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.1421 - acc: 0.9639\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 3s 104ms/step - loss: 0.1349 - acc: 0.9664\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 3s 109ms/step - loss: 0.1293 - acc: 0.9680\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 3s 104ms/step - loss: 0.1272 - acc: 0.9681\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 3s 104ms/step - loss: 0.1274 - acc: 0.9699\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 3s 108ms/step - loss: 0.1238 - acc: 0.9701\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 3s 103ms/step - loss: 0.1194 - acc: 0.9723\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 3s 104ms/step - loss: 0.1205 - acc: 0.9710\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 3s 103ms/step - loss: 0.1167 - acc: 0.9728\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 3s 102ms/step - loss: 0.1194 - acc: 0.9733\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 3s 104ms/step - loss: 0.1146 - acc: 0.9738\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 3s 107ms/step - loss: 0.1136 - acc: 0.9738\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 3s 104ms/step - loss: 0.1114 - acc: 0.9743\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 3s 108ms/step - loss: 0.1117 - acc: 0.9741\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 3s 104ms/step - loss: 0.1135 - acc: 0.9735\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 3s 103ms/step - loss: 0.1173 - acc: 0.9712\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.1104 - acc: 0.9743\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 3s 107ms/step - loss: 0.1053 - acc: 0.9774\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.1112 - acc: 0.9719\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.1068 - acc: 0.9751\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.1069 - acc: 0.9757\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 3s 107ms/step - loss: 0.1040 - acc: 0.9765\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 3s 105ms/step - loss: 0.1025 - acc: 0.9775\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.1016 - acc: 0.9772\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 3s 107ms/step - loss: 0.1066 - acc: 0.9746\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 3s 104ms/step - loss: 0.1068 - acc: 0.9754\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 3s 103ms/step - loss: 0.1031 - acc: 0.9775\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 3s 101ms/step - loss: 0.1018 - acc: 0.9769\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 3s 100ms/step - loss: 0.1038 - acc: 0.9759\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 3s 103ms/step - loss: 0.1037 - acc: 0.9762\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 3s 101ms/step - loss: 0.1000 - acc: 0.9783\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 3s 104ms/step - loss: 0.1026 - acc: 0.9761\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.1012 - acc: 0.9769\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 3s 103ms/step - loss: 0.1032 - acc: 0.9761\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 3s 101ms/step - loss: 0.0991 - acc: 0.9778\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 3s 105ms/step - loss: 0.0995 - acc: 0.9780\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 3s 103ms/step - loss: 0.1031 - acc: 0.9751\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.0976 - acc: 0.9770\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 3s 103ms/step - loss: 0.0946 - acc: 0.9791\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 3s 105ms/step - loss: 0.0904 - acc: 0.9808\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 3s 107ms/step - loss: 0.0959 - acc: 0.9788\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 3s 105ms/step - loss: 0.0950 - acc: 0.9778\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.0944 - acc: 0.9798\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.0937 - acc: 0.9799\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 3s 105ms/step - loss: 0.0961 - acc: 0.9783\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.0926 - acc: 0.9803\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 3s 102ms/step - loss: 0.0906 - acc: 0.9801\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 3s 102ms/step - loss: 0.0909 - acc: 0.9803\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 3s 103ms/step - loss: 0.0895 - acc: 0.9817\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 99ms/step - loss: 0.0939 - acc: 0.9790\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 3s 102ms/step - loss: 0.0978 - acc: 0.9764\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 3s 105ms/step - loss: 0.0913 - acc: 0.9798\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 3s 103ms/step - loss: 0.0899 - acc: 0.9809\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.0923 - acc: 0.9796\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 3s 104ms/step - loss: 0.0902 - acc: 0.9801\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 3s 102ms/step - loss: 0.0919 - acc: 0.9791\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 3s 107ms/step - loss: 0.0898 - acc: 0.9814\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 3s 104ms/step - loss: 0.0952 - acc: 0.9777\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 3s 105ms/step - loss: 0.0886 - acc: 0.9816\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 3s 105ms/step - loss: 0.0913 - acc: 0.9791\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 3s 103ms/step - loss: 0.0913 - acc: 0.9790\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 3s 108ms/step - loss: 0.0894 - acc: 0.9804\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.0879 - acc: 0.9817\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 3s 105ms/step - loss: 0.0890 - acc: 0.9801\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 3s 109ms/step - loss: 0.0896 - acc: 0.9801\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 3s 105ms/step - loss: 0.0892 - acc: 0.9801\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 3s 103ms/step - loss: 0.0868 - acc: 0.9825\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 3s 104ms/step - loss: 0.0857 - acc: 0.9820\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 3s 101ms/step - loss: 0.0874 - acc: 0.9819\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 3s 104ms/step - loss: 0.0845 - acc: 0.9817\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 99ms/step - loss: 0.0883 - acc: 0.9817\n",
      "CPU times: user 1h 58min 47s, sys: 27min 37s, total: 2h 26min 24s\n",
      "Wall time: 3min 33s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('model1',\n",
       "                              <__main__.KerasClassifier object at 0x7f0adc371a60>),\n",
       "                             ('model2',\n",
       "                              <__main__.KerasClassifier object at 0x7f0ad0273f70>),\n",
       "                             ('model3',\n",
       "                              <__main__.KerasClassifier object at 0x7f0ad0273c40>),\n",
       "                             ('model4',\n",
       "                              <__main__.KerasClassifier object at 0x7f0ad0273b20>)],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "voting_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c504e750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guri99/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:430: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.7941747572815534\n"
     ]
    }
   ],
   "source": [
    "preds = voting_model.predict(X_test)\n",
    "from sklearn import metrics\n",
    "print('정확도 :', metrics.accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ace675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18c65ae4",
   "metadata": {},
   "source": [
    "# Adaboost-GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5433d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_num = 48\n",
    "def get_gru_model(seed_num):\n",
    "    tf.random.set_seed(seed_num)\n",
    "\n",
    "    gru = Sequential()\n",
    "    gru.add(InputLayer(input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "    gru.add(GRU(units=128, activation='hard_sigmoid', return_sequences=True))\n",
    "    gru.add(GRU(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "    gru.add(Dropout(0.2))\n",
    "    gru.add(GRU(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "    gru.add(GRU(units=32, activation='hard_sigmoid', return_sequences=False))\n",
    "    gru.add(Dropout(0.2))\n",
    "    gru.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    gru.compile(optimizer= \"adam\", loss = \"binary_crossentropy\", metrics=['acc'])\n",
    "    return gru\n",
    "\n",
    "# adaboost\n",
    "# GRU_Predictors = KerasClassifier(build_fn=lambda:gru, epochs=20, batch_size=256)\n",
    "gru_Predictors = KerasClassifier(build_fn=lambda:get_gru_model(seed_num), epochs=20, batch_size=256)\n",
    "gru_model = AdaBoostClassifier(gru_Predictors, n_estimators=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "57883fc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 73ms/step - loss: 1.1196e-04 - acc: 0.5808\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1028e-04 - acc: 0.5911\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1036e-04 - acc: 0.5858\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1049e-04 - acc: 0.5904\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1094e-04 - acc: 0.5820\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.0939e-04 - acc: 0.5893\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.0990e-04 - acc: 0.5938\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1004e-04 - acc: 0.5930\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1012e-04 - acc: 0.5943\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.0929e-04 - acc: 0.6065\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.0902e-04 - acc: 0.6070\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.0977e-04 - acc: 0.5926\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 1.0889e-04 - acc: 0.6091\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.0931e-04 - acc: 0.6003\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.0972e-04 - acc: 0.6009\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.0909e-04 - acc: 0.6022\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.0884e-04 - acc: 0.6055\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.0945e-04 - acc: 0.5999\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.0890e-04 - acc: 0.6064\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.0817e-04 - acc: 0.6131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 74ms/step - loss: 1.1916e-04 - acc: 0.5625\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1438e-04 - acc: 0.4882\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1424e-04 - acc: 0.5040\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1437e-04 - acc: 0.5045\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1482e-04 - acc: 0.4828\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1316e-04 - acc: 0.5082\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1378e-04 - acc: 0.5064\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1391e-04 - acc: 0.4710\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1379e-04 - acc: 0.4917\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1325e-04 - acc: 0.5208\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 1.1289e-04 - acc: 0.5037\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1338e-04 - acc: 0.4832\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1283e-04 - acc: 0.5207\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1302e-04 - acc: 0.4976\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1335e-04 - acc: 0.5153\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1280e-04 - acc: 0.4985\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1259e-04 - acc: 0.5105\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1313e-04 - acc: 0.5102\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 1.1262e-04 - acc: 0.5204\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1198e-04 - acc: 0.4967\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 74ms/step - loss: 1.1918e-04 - acc: 0.5622\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1438e-04 - acc: 0.4876\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1425e-04 - acc: 0.5036\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1437e-04 - acc: 0.5032\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1483e-04 - acc: 0.4823\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1316e-04 - acc: 0.5073\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1379e-04 - acc: 0.5065\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1392e-04 - acc: 0.4683\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1379e-04 - acc: 0.4902\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1325e-04 - acc: 0.5185\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1289e-04 - acc: 0.5004\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1339e-04 - acc: 0.4845\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1284e-04 - acc: 0.5205\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1302e-04 - acc: 0.4956\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1335e-04 - acc: 0.5144\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1280e-04 - acc: 0.4956\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1259e-04 - acc: 0.5076\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1313e-04 - acc: 0.5079\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 1.1262e-04 - acc: 0.5189\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1199e-04 - acc: 0.4939\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 73ms/step - loss: 1.1918e-04 - acc: 0.5622\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1438e-04 - acc: 0.4876\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1425e-04 - acc: 0.5036\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1437e-04 - acc: 0.5032\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1483e-04 - acc: 0.4823\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1316e-04 - acc: 0.5073\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1379e-04 - acc: 0.5065\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1392e-04 - acc: 0.4683\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1379e-04 - acc: 0.4902\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1325e-04 - acc: 0.5185\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1289e-04 - acc: 0.5004\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1339e-04 - acc: 0.4845\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1284e-04 - acc: 0.5205\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1302e-04 - acc: 0.4956\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1335e-04 - acc: 0.5144\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1280e-04 - acc: 0.4956\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1259e-04 - acc: 0.5075\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1313e-04 - acc: 0.5079\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1262e-04 - acc: 0.5189\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1199e-04 - acc: 0.4939\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 6s 75ms/step - loss: 1.1918e-04 - acc: 0.5622\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1438e-04 - acc: 0.4876\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1425e-04 - acc: 0.5036\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1437e-04 - acc: 0.5032\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1483e-04 - acc: 0.4823\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1316e-04 - acc: 0.5073\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1379e-04 - acc: 0.5065\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1392e-04 - acc: 0.4683\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1379e-04 - acc: 0.4902\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1325e-04 - acc: 0.5185\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1289e-04 - acc: 0.5004\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1339e-04 - acc: 0.4845\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1284e-04 - acc: 0.5205\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1302e-04 - acc: 0.4956\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1335e-04 - acc: 0.5144\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1280e-04 - acc: 0.4956\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1259e-04 - acc: 0.5075\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1313e-04 - acc: 0.5079\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1262e-04 - acc: 0.5189\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 1.1199e-04 - acc: 0.4939\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 73ms/step - loss: 1.1918e-04 - acc: 0.5622\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1438e-04 - acc: 0.4876\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1425e-04 - acc: 0.5036\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1437e-04 - acc: 0.5032\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1483e-04 - acc: 0.4823\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1316e-04 - acc: 0.5073\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1379e-04 - acc: 0.5065\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1392e-04 - acc: 0.4683\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1380e-04 - acc: 0.4902\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1325e-04 - acc: 0.5185\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1289e-04 - acc: 0.5004\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1339e-04 - acc: 0.4845\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1284e-04 - acc: 0.5205\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1302e-04 - acc: 0.4956\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1335e-04 - acc: 0.5144\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1280e-04 - acc: 0.4956\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1259e-04 - acc: 0.5075\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1313e-04 - acc: 0.5079\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1262e-04 - acc: 0.5189\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1199e-04 - acc: 0.4939\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 72ms/step - loss: 1.1918e-04 - acc: 0.5622\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1438e-04 - acc: 0.4876\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1425e-04 - acc: 0.5036\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1437e-04 - acc: 0.5032\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1483e-04 - acc: 0.4823\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1316e-04 - acc: 0.5073\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1379e-04 - acc: 0.5065\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1392e-04 - acc: 0.4683\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1380e-04 - acc: 0.4902\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1325e-04 - acc: 0.5185\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1289e-04 - acc: 0.5004\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1339e-04 - acc: 0.4845\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 1.1284e-04 - acc: 0.5205\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1302e-04 - acc: 0.4956\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1335e-04 - acc: 0.5144\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1280e-04 - acc: 0.4956\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1259e-04 - acc: 0.5076\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1313e-04 - acc: 0.5079\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 1.1262e-04 - acc: 0.5190\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1199e-04 - acc: 0.4939\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 73ms/step - loss: 1.1918e-04 - acc: 0.5622\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1438e-04 - acc: 0.4876\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1425e-04 - acc: 0.5036\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1437e-04 - acc: 0.5032\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1483e-04 - acc: 0.4823\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1316e-04 - acc: 0.5073\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1379e-04 - acc: 0.5065\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1392e-04 - acc: 0.4683\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1380e-04 - acc: 0.4902\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1325e-04 - acc: 0.5185\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1289e-04 - acc: 0.5004\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1339e-04 - acc: 0.4845\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1284e-04 - acc: 0.5205\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1302e-04 - acc: 0.4956\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1335e-04 - acc: 0.5144\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1280e-04 - acc: 0.4956\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1259e-04 - acc: 0.5076\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1313e-04 - acc: 0.5079\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 1.1262e-04 - acc: 0.5190\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 1.1199e-04 - acc: 0.4939\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 73ms/step - loss: 1.1918e-04 - acc: 0.5622\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1438e-04 - acc: 0.4876\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1425e-04 - acc: 0.5036\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1437e-04 - acc: 0.5032\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1483e-04 - acc: 0.4823\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1316e-04 - acc: 0.5073\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1379e-04 - acc: 0.5065\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1392e-04 - acc: 0.4683\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 1.1380e-04 - acc: 0.4902\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1325e-04 - acc: 0.5185\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1289e-04 - acc: 0.5004\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1339e-04 - acc: 0.4845\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1284e-04 - acc: 0.5205\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 1.1302e-04 - acc: 0.4956\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1335e-04 - acc: 0.5144\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1280e-04 - acc: 0.4956\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1259e-04 - acc: 0.5076\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1313e-04 - acc: 0.5079\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 1.1262e-04 - acc: 0.5190\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 1.1199e-04 - acc: 0.4939\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 74ms/step - loss: 1.1918e-04 - acc: 0.5622\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1438e-04 - acc: 0.4876\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1425e-04 - acc: 0.5036\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1437e-04 - acc: 0.5032\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1483e-04 - acc: 0.4823\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1316e-04 - acc: 0.5073\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1379e-04 - acc: 0.5065\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1392e-04 - acc: 0.4683\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1380e-04 - acc: 0.4902\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1325e-04 - acc: 0.5185\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1289e-04 - acc: 0.5004\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1339e-04 - acc: 0.4845\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1284e-04 - acc: 0.5205\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1302e-04 - acc: 0.4956\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1335e-04 - acc: 0.5144\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1280e-04 - acc: 0.4956\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1259e-04 - acc: 0.5076\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1313e-04 - acc: 0.5079\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1262e-04 - acc: 0.5190\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 1.1199e-04 - acc: 0.4939\n",
      "CPU times: user 4h 40min 2s, sys: 42min 40s, total: 5h 22min 43s\n",
      "Wall time: 7min 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=<__main__.KerasClassifier object at 0x7f3a133592b0>,\n",
       "                   n_estimators=10, random_state=42)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "gru_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc1c042d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.6284789644012945\n"
     ]
    }
   ],
   "source": [
    "preds = gru_model.predict(X_test)\n",
    "preds[preds>0.5] = 1\n",
    "preds[preds<=0.5] = 0\n",
    "from sklearn import metrics\n",
    "print('정확도 :', metrics.accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2788da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2a2aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bdf705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41fcf2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b42b7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ef9fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd423d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25606137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "164.97px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

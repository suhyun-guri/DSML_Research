{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8f20ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional\n",
    "from tensorflow.keras.layers import SimpleRNN, GRU\n",
    "from tensorflow.keras.layers import Dropout, InputLayer, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "#한글설정\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "font_dirs = ['/usr/share/fonts/truetype/nanum', ]\n",
    "font_files = fm.findSystemFonts(fontpaths=font_dirs)\n",
    "\n",
    "for font_file in font_files:\n",
    "    fm.fontManager.addfont(font_file)\n",
    "    \n",
    "# 한글 출력을 위해서 폰트 옵션을 설정합니다.\n",
    "# \"axes.unicode_minus\" : 마이너스가 깨질 것을 방지\n",
    "\n",
    "sns.set(font=\"NanumBarunGothic\",\n",
    "        rc={\"axes.unicode_minus\":False},\n",
    "        style='darkgrid')\n",
    "\n",
    "#GPU 사용 설정, -1이면 CPU 사용\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\"\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "    try:\n",
    "        for i in range(len(gpus)):\n",
    "            tf.config.experimental.set_memory_growth(gpus[i], True)\n",
    "    except RuntimeError as e:\n",
    "        # 프로그램 시작시에 메모리 증가가 설정되어야만 합니다\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d6b046",
   "metadata": {},
   "source": [
    "# 시계열, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11c9410d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "309ac6a5936c4655bf24bc8bb6c4b9ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 5s 153ms/step - loss: 0.8916 - acc: 0.3881 - val_loss: 0.7479 - val_acc: 0.3946\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.7040 - acc: 0.5165 - val_loss: 0.6718 - val_acc: 0.6054\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6762 - acc: 0.6106 - val_loss: 0.6815 - val_acc: 0.6054\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.6856 - acc: 0.6037 - val_loss: 0.6726 - val_acc: 0.6054\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.6750 - acc: 0.5994 - val_loss: 0.6706 - val_acc: 0.6054\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6744 - acc: 0.5996 - val_loss: 0.6708 - val_acc: 0.6054\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6745 - acc: 0.5914 - val_loss: 0.6704 - val_acc: 0.6054\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6725 - acc: 0.6080 - val_loss: 0.6705 - val_acc: 0.6054\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.6731 - acc: 0.5983 - val_loss: 0.6702 - val_acc: 0.6054\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6730 - acc: 0.6011 - val_loss: 0.6698 - val_acc: 0.6054\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.6735 - acc: 0.6019 - val_loss: 0.6694 - val_acc: 0.6054\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6707 - acc: 0.6095 - val_loss: 0.6686 - val_acc: 0.6054\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6717 - acc: 0.6084 - val_loss: 0.6669 - val_acc: 0.6054\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.6666 - acc: 0.6106 - val_loss: 0.6636 - val_acc: 0.6054\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6640 - acc: 0.6086 - val_loss: 0.6563 - val_acc: 0.6054\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.6502 - acc: 0.6160 - val_loss: 0.6417 - val_acc: 0.6054\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6233 - acc: 0.6347 - val_loss: 0.6188 - val_acc: 0.6054\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.5881 - acc: 0.6684 - val_loss: 0.5886 - val_acc: 0.7128\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.5415 - acc: 0.7515 - val_loss: 0.5708 - val_acc: 0.7147\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.4877 - acc: 0.8106 - val_loss: 0.5450 - val_acc: 0.7432\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.4556 - acc: 0.8192 - val_loss: 0.5687 - val_acc: 0.7329\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.4299 - acc: 0.8362 - val_loss: 0.5520 - val_acc: 0.7516\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.3891 - acc: 0.8583 - val_loss: 0.5521 - val_acc: 0.7561\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.3684 - acc: 0.8727 - val_loss: 0.5664 - val_acc: 0.7490\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.3474 - acc: 0.8813 - val_loss: 0.5752 - val_acc: 0.7439\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.3261 - acc: 0.8919 - val_loss: 0.5936 - val_acc: 0.7303\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.3120 - acc: 0.9005 - val_loss: 0.6085 - val_acc: 0.7342\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2944 - acc: 0.9068 - val_loss: 0.6212 - val_acc: 0.7393\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2860 - acc: 0.9107 - val_loss: 0.6380 - val_acc: 0.7348\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2687 - acc: 0.9206Restoring model weights from the end of the best epoch: 20.\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2687 - acc: 0.9206 - val_loss: 0.6446 - val_acc: 0.7387\n",
      "Epoch 00030: early stopping\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 5s 147ms/step - loss: 0.7227 - acc: 0.4714 - val_loss: 0.6673 - val_acc: 0.6132\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 0.6819 - acc: 0.6032 - val_loss: 0.6715 - val_acc: 0.6132\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6785 - acc: 0.6022 - val_loss: 0.6673 - val_acc: 0.6132\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6743 - acc: 0.5989 - val_loss: 0.6682 - val_acc: 0.6132\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6774 - acc: 0.5974 - val_loss: 0.6667 - val_acc: 0.6132\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6722 - acc: 0.6056 - val_loss: 0.6661 - val_acc: 0.6132\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.6740 - acc: 0.6065 - val_loss: 0.6648 - val_acc: 0.6132\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6737 - acc: 0.6039 - val_loss: 0.6626 - val_acc: 0.6132\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.6670 - acc: 0.6056 - val_loss: 0.6556 - val_acc: 0.6132\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6565 - acc: 0.6138 - val_loss: 0.6391 - val_acc: 0.6132\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 0.6353 - acc: 0.6224 - val_loss: 0.6090 - val_acc: 0.6132\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.5948 - acc: 0.6492 - val_loss: 0.5665 - val_acc: 0.7160\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.5349 - acc: 0.7398 - val_loss: 0.5322 - val_acc: 0.7555\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 0.4840 - acc: 0.7909 - val_loss: 0.5174 - val_acc: 0.7549\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.4492 - acc: 0.8114 - val_loss: 0.5237 - val_acc: 0.7600\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.4159 - acc: 0.8317 - val_loss: 0.5017 - val_acc: 0.7736\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.3867 - acc: 0.8531 - val_loss: 0.5064 - val_acc: 0.7736\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.3674 - acc: 0.8619 - val_loss: 0.5184 - val_acc: 0.7736\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.3468 - acc: 0.8764 - val_loss: 0.5489 - val_acc: 0.7678\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.3340 - acc: 0.8809 - val_loss: 0.5366 - val_acc: 0.7710\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.3157 - acc: 0.8908 - val_loss: 0.5517 - val_acc: 0.7762\n",
      "Epoch 22/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 88ms/step - loss: 0.3146 - acc: 0.8891 - val_loss: 0.5549 - val_acc: 0.7613\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.3117 - acc: 0.8895 - val_loss: 0.5514 - val_acc: 0.7755\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.2953 - acc: 0.8988 - val_loss: 0.5747 - val_acc: 0.7697\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.2907 - acc: 0.8988 - val_loss: 0.5859 - val_acc: 0.7665\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2661 - acc: 0.9115Restoring model weights from the end of the best epoch: 16.\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.2661 - acc: 0.9115 - val_loss: 0.5700 - val_acc: 0.7762\n",
      "Epoch 00026: early stopping\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 5s 147ms/step - loss: 0.6745 - acc: 0.6030 - val_loss: 0.6663 - val_acc: 0.6171\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 0.6741 - acc: 0.6060 - val_loss: 0.6653 - val_acc: 0.6171\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6753 - acc: 0.6035 - val_loss: 0.6657 - val_acc: 0.6171\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.6718 - acc: 0.6069 - val_loss: 0.6648 - val_acc: 0.6171\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.6720 - acc: 0.6084 - val_loss: 0.6637 - val_acc: 0.6171\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6679 - acc: 0.6091 - val_loss: 0.6575 - val_acc: 0.6171\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6605 - acc: 0.6097 - val_loss: 0.6388 - val_acc: 0.6171\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6293 - acc: 0.6283 - val_loss: 0.5941 - val_acc: 0.6856\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.5724 - acc: 0.7038 - val_loss: 0.5359 - val_acc: 0.7626\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.5136 - acc: 0.7627 - val_loss: 0.5037 - val_acc: 0.7684\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.4633 - acc: 0.7959 - val_loss: 0.4905 - val_acc: 0.7691\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.4232 - acc: 0.8205 - val_loss: 0.4828 - val_acc: 0.7704\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.3925 - acc: 0.8403 - val_loss: 0.4925 - val_acc: 0.7807\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.3669 - acc: 0.8550 - val_loss: 0.5066 - val_acc: 0.7723\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.3403 - acc: 0.8712 - val_loss: 0.5239 - val_acc: 0.7600\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.3298 - acc: 0.8740 - val_loss: 0.5510 - val_acc: 0.7697\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.3056 - acc: 0.8874 - val_loss: 0.5533 - val_acc: 0.7574\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2890 - acc: 0.8934 - val_loss: 0.5919 - val_acc: 0.7652\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.2809 - acc: 0.8973 - val_loss: 0.5817 - val_acc: 0.7568\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2677 - acc: 0.9040 - val_loss: 0.6197 - val_acc: 0.7658\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.2560 - acc: 0.9090 - val_loss: 0.6126 - val_acc: 0.7516\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2367 - acc: 0.9232Restoring model weights from the end of the best epoch: 12.\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2367 - acc: 0.9232 - val_loss: 0.6430 - val_acc: 0.7652\n",
      "Epoch 00022: early stopping\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 5s 148ms/step - loss: 0.6806 - acc: 0.5933 - val_loss: 0.6629 - val_acc: 0.6274\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6785 - acc: 0.5998 - val_loss: 0.6606 - val_acc: 0.6274\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 0.6762 - acc: 0.5985 - val_loss: 0.6622 - val_acc: 0.6274\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.6768 - acc: 0.5994 - val_loss: 0.6608 - val_acc: 0.6274\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.6727 - acc: 0.6028 - val_loss: 0.6597 - val_acc: 0.6274\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6709 - acc: 0.6022 - val_loss: 0.6559 - val_acc: 0.6274\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6622 - acc: 0.6060 - val_loss: 0.6390 - val_acc: 0.6274\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.6337 - acc: 0.6145 - val_loss: 0.6015 - val_acc: 0.6274\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.5748 - acc: 0.6986 - val_loss: 0.5560 - val_acc: 0.7277\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.5063 - acc: 0.7661 - val_loss: 0.5234 - val_acc: 0.7516\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.4519 - acc: 0.8022 - val_loss: 0.5053 - val_acc: 0.7717\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.4127 - acc: 0.8280 - val_loss: 0.5155 - val_acc: 0.7600\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.3765 - acc: 0.8475 - val_loss: 0.5203 - val_acc: 0.7723\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 0.3528 - acc: 0.8550 - val_loss: 0.5461 - val_acc: 0.7568\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.3315 - acc: 0.8714 - val_loss: 0.5543 - val_acc: 0.7639\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.3066 - acc: 0.8859 - val_loss: 0.5752 - val_acc: 0.7620\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.2838 - acc: 0.9010 - val_loss: 0.6029 - val_acc: 0.7620\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 0.2786 - acc: 0.8980 - val_loss: 0.6201 - val_acc: 0.7497\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.2593 - acc: 0.9126 - val_loss: 0.6308 - val_acc: 0.7542\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.2474 - acc: 0.9180 - val_loss: 0.6464 - val_acc: 0.7536\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2318 - acc: 0.9215Restoring model weights from the end of the best epoch: 11.\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.2318 - acc: 0.9215 - val_loss: 0.6733 - val_acc: 0.7426\n",
      "Epoch 00021: early stopping\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 5s 146ms/step - loss: 0.6883 - acc: 0.6201 - val_loss: 0.6816 - val_acc: 0.5796\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.6729 - acc: 0.6073 - val_loss: 0.6804 - val_acc: 0.5796\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.6676 - acc: 0.6186 - val_loss: 0.6860 - val_acc: 0.5796\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6704 - acc: 0.6211 - val_loss: 0.6861 - val_acc: 0.5796\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.6681 - acc: 0.6196 - val_loss: 0.6824 - val_acc: 0.5796\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6668 - acc: 0.6205 - val_loss: 0.6798 - val_acc: 0.5796\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.6630 - acc: 0.6209 - val_loss: 0.6777 - val_acc: 0.5796\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6586 - acc: 0.6207 - val_loss: 0.6696 - val_acc: 0.5796\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6466 - acc: 0.6205 - val_loss: 0.6515 - val_acc: 0.5796\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6219 - acc: 0.6265 - val_loss: 0.6180 - val_acc: 0.5796\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 0.5737 - acc: 0.7012 - val_loss: 0.5706 - val_acc: 0.7458\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.5052 - acc: 0.7752 - val_loss: 0.5371 - val_acc: 0.7451\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.4481 - acc: 0.8123 - val_loss: 0.5574 - val_acc: 0.7594\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.4116 - acc: 0.8347 - val_loss: 0.5219 - val_acc: 0.7607\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.3825 - acc: 0.8503 - val_loss: 0.5655 - val_acc: 0.7581\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 0.3654 - acc: 0.8572 - val_loss: 0.5489 - val_acc: 0.7652\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.3399 - acc: 0.8757 - val_loss: 0.5543 - val_acc: 0.7600\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.3161 - acc: 0.8904 - val_loss: 0.6096 - val_acc: 0.7523\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.2937 - acc: 0.8984 - val_loss: 0.5848 - val_acc: 0.7490\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.2761 - acc: 0.9107 - val_loss: 0.6459 - val_acc: 0.7523\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 0.2582 - acc: 0.9156 - val_loss: 0.6492 - val_acc: 0.7510\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.2373 - acc: 0.9282 - val_loss: 0.6680 - val_acc: 0.7393\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.2287 - acc: 0.9299 - val_loss: 0.6856 - val_acc: 0.7400\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2228 - acc: 0.9340Restoring model weights from the end of the best epoch: 14.\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.2228 - acc: 0.9340 - val_loss: 0.7218 - val_acc: 0.7400\n",
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 5s 148ms/step - loss: 0.6755 - acc: 0.5987 - val_loss: 0.6796 - val_acc: 0.5957\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.6713 - acc: 0.6104 - val_loss: 0.6747 - val_acc: 0.5957\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6725 - acc: 0.6056 - val_loss: 0.6752 - val_acc: 0.5957\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.6733 - acc: 0.6127 - val_loss: 0.6763 - val_acc: 0.5957\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.6676 - acc: 0.6145 - val_loss: 0.6739 - val_acc: 0.5957\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.6661 - acc: 0.6145 - val_loss: 0.6712 - val_acc: 0.5957\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6608 - acc: 0.6155 - val_loss: 0.6595 - val_acc: 0.5957\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.6400 - acc: 0.6186 - val_loss: 0.6317 - val_acc: 0.5957\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.5936 - acc: 0.6738 - val_loss: 0.5764 - val_acc: 0.7206\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.5206 - acc: 0.7612 - val_loss: 0.5335 - val_acc: 0.7296\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.4648 - acc: 0.7948 - val_loss: 0.5327 - val_acc: 0.7471\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.4200 - acc: 0.8248 - val_loss: 0.5258 - val_acc: 0.7523\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.3927 - acc: 0.8410 - val_loss: 0.5432 - val_acc: 0.7568\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.3584 - acc: 0.8656 - val_loss: 0.5574 - val_acc: 0.7652\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.3295 - acc: 0.8813 - val_loss: 0.5761 - val_acc: 0.7458\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 0.3119 - acc: 0.8893 - val_loss: 0.5862 - val_acc: 0.7451\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2935 - acc: 0.8997 - val_loss: 0.6012 - val_acc: 0.7458\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 0.2748 - acc: 0.9115 - val_loss: 0.6169 - val_acc: 0.7464\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2589 - acc: 0.9187 - val_loss: 0.6319 - val_acc: 0.7555\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2494 - acc: 0.9232 - val_loss: 0.6596 - val_acc: 0.7387\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.2449 - acc: 0.9221 - val_loss: 0.6599 - val_acc: 0.7477\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2229 - acc: 0.9370Restoring model weights from the end of the best epoch: 12.\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.2229 - acc: 0.9370 - val_loss: 0.6819 - val_acc: 0.7439\n",
      "Epoch 00022: early stopping\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 5s 144ms/step - loss: 0.6890 - acc: 0.5493 - val_loss: 0.6794 - val_acc: 0.5964\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.6750 - acc: 0.6117 - val_loss: 0.6775 - val_acc: 0.5964\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.6699 - acc: 0.6110 - val_loss: 0.6742 - val_acc: 0.5964\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.6696 - acc: 0.6121 - val_loss: 0.6741 - val_acc: 0.5964\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 0.6723 - acc: 0.6088 - val_loss: 0.6744 - val_acc: 0.5964\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.6692 - acc: 0.6121 - val_loss: 0.6731 - val_acc: 0.5964\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.6695 - acc: 0.6112 - val_loss: 0.6688 - val_acc: 0.5964\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.6619 - acc: 0.6151 - val_loss: 0.6583 - val_acc: 0.5964\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.6437 - acc: 0.6214 - val_loss: 0.6365 - val_acc: 0.5964\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6082 - acc: 0.6358 - val_loss: 0.5945 - val_acc: 0.6721\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.5489 - acc: 0.7366 - val_loss: 0.5454 - val_acc: 0.7406\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.4850 - acc: 0.7881 - val_loss: 0.5198 - val_acc: 0.7516\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.4394 - acc: 0.8151 - val_loss: 0.5177 - val_acc: 0.7523\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.4076 - acc: 0.8365 - val_loss: 0.5156 - val_acc: 0.7555\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.3851 - acc: 0.8477 - val_loss: 0.5321 - val_acc: 0.7607\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 0.3583 - acc: 0.8630 - val_loss: 0.5487 - val_acc: 0.7477\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.3426 - acc: 0.8710 - val_loss: 0.5522 - val_acc: 0.7620\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.3246 - acc: 0.8846 - val_loss: 0.5573 - val_acc: 0.7639\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.3205 - acc: 0.8839 - val_loss: 0.5611 - val_acc: 0.7613\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2911 - acc: 0.8980 - val_loss: 0.5764 - val_acc: 0.7600\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2727 - acc: 0.9087 - val_loss: 0.5874 - val_acc: 0.7574\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.2575 - acc: 0.9213 - val_loss: 0.6079 - val_acc: 0.7587\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.2398 - acc: 0.9266 - val_loss: 0.6309 - val_acc: 0.7607\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2306 - acc: 0.9316Restoring model weights from the end of the best epoch: 14.\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2306 - acc: 0.9316 - val_loss: 0.6495 - val_acc: 0.7523\n",
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 5s 144ms/step - loss: 0.7316 - acc: 0.4591 - val_loss: 0.6718 - val_acc: 0.6138\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.6803 - acc: 0.6030 - val_loss: 0.6724 - val_acc: 0.6138\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6784 - acc: 0.6082 - val_loss: 0.6668 - val_acc: 0.6138\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.6762 - acc: 0.5955 - val_loss: 0.6679 - val_acc: 0.6138\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.6740 - acc: 0.5937 - val_loss: 0.6665 - val_acc: 0.6138\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6737 - acc: 0.6043 - val_loss: 0.6658 - val_acc: 0.6138\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6705 - acc: 0.6093 - val_loss: 0.6649 - val_acc: 0.6138\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.6720 - acc: 0.6067 - val_loss: 0.6630 - val_acc: 0.6138\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6666 - acc: 0.6104 - val_loss: 0.6579 - val_acc: 0.6138\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.6586 - acc: 0.6112 - val_loss: 0.6457 - val_acc: 0.6138\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.6413 - acc: 0.6177 - val_loss: 0.6241 - val_acc: 0.6138\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6084 - acc: 0.6319 - val_loss: 0.5881 - val_acc: 0.6145\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.5586 - acc: 0.7154 - val_loss: 0.5616 - val_acc: 0.7322\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.4969 - acc: 0.7957 - val_loss: 0.5334 - val_acc: 0.7574\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.4520 - acc: 0.8203 - val_loss: 0.5319 - val_acc: 0.7393\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.4168 - acc: 0.8337 - val_loss: 0.5349 - val_acc: 0.7587\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.3872 - acc: 0.8539 - val_loss: 0.5391 - val_acc: 0.7516\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.3636 - acc: 0.8682 - val_loss: 0.5510 - val_acc: 0.7613\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.3468 - acc: 0.8803 - val_loss: 0.5566 - val_acc: 0.7561\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.3246 - acc: 0.8934 - val_loss: 0.5697 - val_acc: 0.7561\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.3067 - acc: 0.8977 - val_loss: 0.5860 - val_acc: 0.7542\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.2894 - acc: 0.9092 - val_loss: 0.6040 - val_acc: 0.7484\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.2750 - acc: 0.9176 - val_loss: 0.6189 - val_acc: 0.7581\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.2734 - acc: 0.9148 - val_loss: 0.6317 - val_acc: 0.7587\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2699 - acc: 0.9163Restoring model weights from the end of the best epoch: 15.\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.2699 - acc: 0.9163 - val_loss: 0.6492 - val_acc: 0.7600\n",
      "Epoch 00025: early stopping\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 5s 146ms/step - loss: 0.6830 - acc: 0.5899 - val_loss: 0.6664 - val_acc: 0.6229\n",
      "Epoch 2/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 88ms/step - loss: 0.6766 - acc: 0.5935 - val_loss: 0.6624 - val_acc: 0.6229\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6766 - acc: 0.6054 - val_loss: 0.6626 - val_acc: 0.6229\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.6763 - acc: 0.6006 - val_loss: 0.6631 - val_acc: 0.6229\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.6722 - acc: 0.6063 - val_loss: 0.6608 - val_acc: 0.6229\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.6686 - acc: 0.6086 - val_loss: 0.6532 - val_acc: 0.6229\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6565 - acc: 0.6069 - val_loss: 0.6332 - val_acc: 0.6229\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.6256 - acc: 0.6347 - val_loss: 0.5888 - val_acc: 0.7238\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.5705 - acc: 0.7204 - val_loss: 0.5355 - val_acc: 0.7374\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.5015 - acc: 0.7778 - val_loss: 0.5044 - val_acc: 0.7620\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.4620 - acc: 0.7983 - val_loss: 0.5211 - val_acc: 0.7419\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.4303 - acc: 0.8110 - val_loss: 0.4972 - val_acc: 0.7743\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 0.3939 - acc: 0.8401 - val_loss: 0.5071 - val_acc: 0.7710\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.3654 - acc: 0.8526 - val_loss: 0.5217 - val_acc: 0.7658\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.3494 - acc: 0.8654 - val_loss: 0.5287 - val_acc: 0.7568\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.3267 - acc: 0.8731 - val_loss: 0.5427 - val_acc: 0.7568\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.3075 - acc: 0.8852 - val_loss: 0.5682 - val_acc: 0.7607\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2844 - acc: 0.8982 - val_loss: 0.5647 - val_acc: 0.7555\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2744 - acc: 0.9055 - val_loss: 0.5752 - val_acc: 0.7574\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 0.2476 - acc: 0.9189 - val_loss: 0.6032 - val_acc: 0.7620\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2349 - acc: 0.9249 - val_loss: 0.6249 - val_acc: 0.7490\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2161 - acc: 0.9299Restoring model weights from the end of the best epoch: 12.\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.2161 - acc: 0.9299 - val_loss: 0.6392 - val_acc: 0.7549\n",
      "Epoch 00022: early stopping\n",
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 5s 172ms/step - loss: 0.6724 - acc: 0.6117 - val_loss: 0.6793 - val_acc: 0.5899\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6711 - acc: 0.6153 - val_loss: 0.6794 - val_acc: 0.5899\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6704 - acc: 0.6142 - val_loss: 0.6784 - val_acc: 0.5899\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 0.6660 - acc: 0.6168 - val_loss: 0.6783 - val_acc: 0.5899\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6666 - acc: 0.6175 - val_loss: 0.6780 - val_acc: 0.5899\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.6677 - acc: 0.6179 - val_loss: 0.6764 - val_acc: 0.5899\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.6639 - acc: 0.6164 - val_loss: 0.6700 - val_acc: 0.5899\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6510 - acc: 0.6181 - val_loss: 0.6462 - val_acc: 0.5899\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.6156 - acc: 0.6311 - val_loss: 0.5986 - val_acc: 0.7025\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.5478 - acc: 0.7396 - val_loss: 0.5451 - val_acc: 0.7316\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.4848 - acc: 0.7817 - val_loss: 0.5359 - val_acc: 0.7536\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.4306 - acc: 0.8188 - val_loss: 0.5136 - val_acc: 0.7717\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.3941 - acc: 0.8388 - val_loss: 0.5179 - val_acc: 0.7717\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.3662 - acc: 0.8539 - val_loss: 0.5326 - val_acc: 0.7626\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.3312 - acc: 0.8777 - val_loss: 0.5427 - val_acc: 0.7568\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.3137 - acc: 0.8867 - val_loss: 0.5555 - val_acc: 0.7607\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 137ms/step - loss: 0.2923 - acc: 0.8954 - val_loss: 0.5712 - val_acc: 0.7620\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2694 - acc: 0.9107 - val_loss: 0.6000 - val_acc: 0.7587\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.2522 - acc: 0.9200 - val_loss: 0.6339 - val_acc: 0.7542\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2402 - acc: 0.9232 - val_loss: 0.6453 - val_acc: 0.7529\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2266 - acc: 0.9299 - val_loss: 0.6565 - val_acc: 0.7471\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2198 - acc: 0.9305Restoring model weights from the end of the best epoch: 12.\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2198 - acc: 0.9305 - val_loss: 0.6691 - val_acc: 0.7464\n",
      "Epoch 00022: early stopping\n",
      "정확도 : 0.7626778783958603, Precision : 0.8146078717974209, Recall : 0.7922669491525424, F1 : 0.8028529765175854, roc_auc : 0.7542730094599921\n"
     ]
    }
   ],
   "source": [
    "# 2. LSTM model\n",
    "def get_model():\n",
    "    lstm = Sequential()\n",
    "    lstm.add(InputLayer(input_shape=(x.shape[1],x.shape[2])))\n",
    "    lstm.add(LSTM(units=128, activation='hard_sigmoid', return_sequences=True))\n",
    "    lstm.add(LSTM(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "    lstm.add(Dropout(0.2))\n",
    "    lstm.add(LSTM(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "    lstm.add(LSTM(units=32, activation='hard_sigmoid', return_sequences=False))\n",
    "    lstm.add(Dropout(0.2))\n",
    "    lstm.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    lstm.compile(optimizer= keras.optimizers.Adam(learning_rate = 0.001), \n",
    "                 loss = \"binary_crossentropy\", metrics=['acc'])\n",
    "    return lstm\n",
    "\n",
    "\n",
    "path = '/project/LSH/'\n",
    "with tf.device('/device:GPU:0'):\n",
    "    # 1. Data load\n",
    "    x = np.load(path + 'x_(7727,10,4068).npy')\n",
    "    y = np.load(path + 'y_(7727,1).npy')\n",
    "\n",
    "    acc_list, precision_list, recall_list, f1_list, auc_list = [], [], [], [], []\n",
    "    sss = StratifiedShuffleSplit(n_splits=10, test_size = 0.2, random_state = 42)\n",
    "\n",
    "    # 4. Crossvalidation\n",
    "    for seed, (train_index, test_index) in tqdm(enumerate(sss.split(x, y))):\n",
    "        X_train, y_train = x[train_index,:,:], y[train_index]\n",
    "        X_test, y_test = x[test_index,:,:], y[test_index]\n",
    "        \n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
    "\n",
    "        model = get_model()\n",
    "        model.fit(X_train, y_train, epochs=300, batch_size=516, validation_split=0.25, callbacks=[early_stop])\n",
    "\n",
    "        y_pred_test = model.predict(X_test)\n",
    "\n",
    "        y_pred_test[y_pred_test>0.5]=1\n",
    "        y_pred_test[y_pred_test<=0.5]=0\n",
    "        precision = precision_score(y_test, y_pred_test)\n",
    "        recall = recall_score(y_test, y_pred_test)\n",
    "        f1 = f1_score(y_test, y_pred_test)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_test)\n",
    "        acc = accuracy_score(y_test, y_pred_test)\n",
    "        \n",
    "        acc_list.append(acc)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(f1)\n",
    "        auc_list.append(roc_auc)\n",
    "        \n",
    "    print(f'정확도 : {np.mean(acc_list)}, Precision : {np.mean(precision_list)}, Recall : {np.mean(recall_list)}, F1 : {np.mean(f1_list)}, roc_auc : {np.mean(auc_list)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42988f82",
   "metadata": {},
   "source": [
    "정확도 : 0.7626778783958603, Precision : 0.8146078717974209, Recall : 0.7922669491525424, F1 : 0.8028529765175854, roc_auc : 0.7542730094599921\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd41479d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fd6d670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = get_model()\n",
    "tf.keras.utils.plot_model(lstm, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d4aafd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_44 (LSTM)              (None, 10, 128)           2148864   \n",
      "                                                                 \n",
      " lstm_45 (LSTM)              (None, 10, 64)            49408     \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 10, 64)            0         \n",
      "                                                                 \n",
      " lstm_46 (LSTM)              (None, 10, 64)            33024     \n",
      "                                                                 \n",
      " lstm_47 (LSTM)              (None, 32)                12416     \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,243,745\n",
      "Trainable params: 2,243,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e36d8688",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lstm과 구조 동일하게\n",
    "def rnn_model(X_train):    \n",
    "    rnn = Sequential()\n",
    "    rnn.add(InputLayer(input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "    rnn.add(SimpleRNN(units=128, activation='hard_sigmoid', return_sequences=True))\n",
    "    rnn.add(SimpleRNN(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "    rnn.add(Dropout(0.2))\n",
    "    rnn.add(SimpleRNN(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "    rnn.add(SimpleRNN(units=32, activation='hard_sigmoid', return_sequences=False))\n",
    "    rnn.add(Dropout(0.2))\n",
    "    rnn.add(Dense(units=1, activation='sigmoid'))\n",
    "    rnn.compile(optimizer= keras.optimizers.Adam(learning_rate = 0.001), \n",
    "                 loss = \"binary_crossentropy\", metrics=['acc'])\n",
    "    return rnn\n",
    "\n",
    "def gru_model(X_train):\n",
    "    gru = Sequential()\n",
    "    gru.add(InputLayer(input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "    gru.add(GRU(units=128, activation='hard_sigmoid', return_sequences=True))\n",
    "    gru.add(GRU(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "    gru.add(Dropout(0.2))\n",
    "    gru.add(GRU(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "    gru.add(GRU(units=32, activation='hard_sigmoid', return_sequences=False))\n",
    "    gru.add(Dropout(0.2))\n",
    "    gru.add(Dense(units=1, activation='sigmoid'))\n",
    "    gru.compile(optimizer= keras.optimizers.Adam(learning_rate = 0.001), \n",
    "                 loss = \"binary_crossentropy\", metrics=['acc'])\n",
    "    return gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a046220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_cv(name):\n",
    "    path = '/project/LSH/'\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        # 1. Data load\n",
    "        x = np.load(path + 'x_(7727,10,4068).npy')\n",
    "        y = np.load(path + 'y_(7727,1).npy')\n",
    "\n",
    "        acc_list, precision_list, recall_list, f1_list, auc_list = [], [], [], [], []\n",
    "        sss = StratifiedShuffleSplit(n_splits=10, test_size = 0.2, random_state = 42)\n",
    "\n",
    "        # 4. Crossvalidation\n",
    "        for seed, (train_index, test_index) in tqdm(enumerate(sss.split(x, y))):\n",
    "            X_train, y_train = x[train_index,:,:], y[train_index]\n",
    "            X_test, y_test = x[test_index,:,:], y[test_index]\n",
    "            \n",
    "            early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=1, restore_best_weights=True)\n",
    "\n",
    "            if name == 'LSTM':\n",
    "                model = get_model()\n",
    "            elif name == 'RNN':\n",
    "                model = rnn_model(X_train)\n",
    "            elif name == 'GRU':\n",
    "                model = gru_model(X_train)\n",
    "                \n",
    "            model.fit(X_train, y_train, epochs=300, batch_size=516, validation_split=0.25, callbacks=[early_stop])\n",
    "\n",
    "            y_pred_test = model.predict(X_test)\n",
    "\n",
    "            y_pred_test[y_pred_test>0.5]=1\n",
    "            y_pred_test[y_pred_test<=0.5]=0\n",
    "\n",
    "            precision = precision_score(y_test, y_pred_test)\n",
    "            recall = recall_score(y_test, y_pred_test)\n",
    "            f1 = f1_score(y_test, y_pred_test)\n",
    "            roc_auc = roc_auc_score(y_test, y_pred_test)\n",
    "            acc = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "            acc_list.append(acc)\n",
    "            precision_list.append(precision)\n",
    "            recall_list.append(recall)\n",
    "            f1_list.append(f1)\n",
    "            auc_list.append(roc_auc)\n",
    "\n",
    "        print(f'{name} 정확도 : {np.mean(acc_list)}, Precision : {np.mean(precision_list)}, Recall : {np.mean(recall_list)}, F1 : {np.mean(f1_list)}, roc_auc : {np.mean(auc_list)}')   \n",
    "    return acc_list, precision_list, recall_list, f1_list, auc_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a965323",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bbe6087d7ad43fa8e869befaa716c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_168 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_169 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_170 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_171 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 5s 157ms/step - loss: 0.7008 - acc: 0.5169 - val_loss: 0.6708 - val_acc: 0.6054\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6778 - acc: 0.6140 - val_loss: 0.6746 - val_acc: 0.6054\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6720 - acc: 0.6106 - val_loss: 0.6705 - val_acc: 0.6054\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6734 - acc: 0.6030 - val_loss: 0.6703 - val_acc: 0.6054\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6705 - acc: 0.6086 - val_loss: 0.6697 - val_acc: 0.6054\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6714 - acc: 0.6078 - val_loss: 0.6687 - val_acc: 0.6054\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.6691 - acc: 0.6119 - val_loss: 0.6664 - val_acc: 0.6054\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6655 - acc: 0.6121 - val_loss: 0.6614 - val_acc: 0.6054\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6547 - acc: 0.6117 - val_loss: 0.6517 - val_acc: 0.6054\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 0.6393 - acc: 0.6155 - val_loss: 0.6306 - val_acc: 0.6054\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6062 - acc: 0.6401 - val_loss: 0.5978 - val_acc: 0.6591\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.5517 - acc: 0.7320 - val_loss: 0.5639 - val_acc: 0.7335\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.4921 - acc: 0.8039 - val_loss: 0.5462 - val_acc: 0.7374\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.4331 - acc: 0.8287 - val_loss: 0.5483 - val_acc: 0.7464\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.3945 - acc: 0.8477 - val_loss: 0.5632 - val_acc: 0.7387\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.3619 - acc: 0.8695 - val_loss: 0.5767 - val_acc: 0.7503\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 0.3381 - acc: 0.8816 - val_loss: 0.5946 - val_acc: 0.7361\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.3182 - acc: 0.8934 - val_loss: 0.6076 - val_acc: 0.7419\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.2992 - acc: 0.9018 - val_loss: 0.6235 - val_acc: 0.7432\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2861 - acc: 0.9105 - val_loss: 0.6405 - val_acc: 0.7361\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.2735 - acc: 0.9154 - val_loss: 0.6820 - val_acc: 0.7212\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2674 - acc: 0.9172 - val_loss: 0.6692 - val_acc: 0.7419\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2740 - acc: 0.9115 - val_loss: 0.6813 - val_acc: 0.7225\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2508 - acc: 0.9238 - val_loss: 0.6579 - val_acc: 0.7484\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2335 - acc: 0.9342 - val_loss: 0.6758 - val_acc: 0.7432\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2229 - acc: 0.9374 - val_loss: 0.6978 - val_acc: 0.7432\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.2177 - acc: 0.9398 - val_loss: 0.7112 - val_acc: 0.7497\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.2129 - acc: 0.9394 - val_loss: 0.7277 - val_acc: 0.7335\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2091 - acc: 0.9437 - val_loss: 0.7268 - val_acc: 0.7432\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.1967 - acc: 0.9476 - val_loss: 0.7362 - val_acc: 0.7432\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.1919 - acc: 0.9504 - val_loss: 0.7475 - val_acc: 0.7432\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.1864 - acc: 0.9517 - val_loss: 0.7580 - val_acc: 0.7419\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1820 - acc: 0.9534Restoring model weights from the end of the best epoch: 13.\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.1820 - acc: 0.9534 - val_loss: 0.7897 - val_acc: 0.7316\n",
      "Epoch 00033: early stopping\n",
      "WARNING:tensorflow:Layer lstm_172 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_173 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_174 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_175 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 5s 158ms/step - loss: 0.6787 - acc: 0.6024 - val_loss: 0.6678 - val_acc: 0.6132\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 101ms/step - loss: 0.6751 - acc: 0.6026 - val_loss: 0.6672 - val_acc: 0.6132\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6751 - acc: 0.6037 - val_loss: 0.6672 - val_acc: 0.6132\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.6733 - acc: 0.6063 - val_loss: 0.6669 - val_acc: 0.6132\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6705 - acc: 0.6091 - val_loss: 0.6664 - val_acc: 0.6132\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.6697 - acc: 0.6069 - val_loss: 0.6634 - val_acc: 0.6132\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6660 - acc: 0.6106 - val_loss: 0.6533 - val_acc: 0.6132\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6480 - acc: 0.6129 - val_loss: 0.6264 - val_acc: 0.6132\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.6054 - acc: 0.6533 - val_loss: 0.5703 - val_acc: 0.7516\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.5413 - acc: 0.7448 - val_loss: 0.5220 - val_acc: 0.7542\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.4860 - acc: 0.7851 - val_loss: 0.5111 - val_acc: 0.7471\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.4454 - acc: 0.8073 - val_loss: 0.4906 - val_acc: 0.7788\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.4206 - acc: 0.8278 - val_loss: 0.5190 - val_acc: 0.7684\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 0.3965 - acc: 0.8410 - val_loss: 0.5050 - val_acc: 0.7717\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.3656 - acc: 0.8542 - val_loss: 0.5090 - val_acc: 0.7704\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.3439 - acc: 0.8725 - val_loss: 0.5220 - val_acc: 0.7691\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.3181 - acc: 0.8833 - val_loss: 0.5409 - val_acc: 0.7652\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.3018 - acc: 0.8975 - val_loss: 0.5591 - val_acc: 0.7652\n",
      "Epoch 19/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 93ms/step - loss: 0.2854 - acc: 0.9016 - val_loss: 0.5732 - val_acc: 0.7633\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.2703 - acc: 0.9122 - val_loss: 0.5925 - val_acc: 0.7620\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2544 - acc: 0.9143 - val_loss: 0.6055 - val_acc: 0.7684\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2388 - acc: 0.9225 - val_loss: 0.6232 - val_acc: 0.7639\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2264 - acc: 0.9327 - val_loss: 0.6479 - val_acc: 0.7574\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2162 - acc: 0.9329 - val_loss: 0.6613 - val_acc: 0.7607\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2141 - acc: 0.9331 - val_loss: 0.6967 - val_acc: 0.7587\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2243 - acc: 0.9279 - val_loss: 0.6837 - val_acc: 0.7549\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2212 - acc: 0.9269 - val_loss: 0.6911 - val_acc: 0.7516\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.1929 - acc: 0.9439 - val_loss: 0.7001 - val_acc: 0.7568\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.1875 - acc: 0.9456 - val_loss: 0.7125 - val_acc: 0.7458\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.1754 - acc: 0.9525 - val_loss: 0.7316 - val_acc: 0.7555\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.1734 - acc: 0.9530 - val_loss: 0.7525 - val_acc: 0.7510\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1712 - acc: 0.9534Restoring model weights from the end of the best epoch: 12.\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.1712 - acc: 0.9534 - val_loss: 0.7689 - val_acc: 0.7490\n",
      "Epoch 00032: early stopping\n",
      "WARNING:tensorflow:Layer lstm_176 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_177 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_178 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_179 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 5s 158ms/step - loss: 0.7010 - acc: 0.5206 - val_loss: 0.6663 - val_acc: 0.6171\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6793 - acc: 0.6056 - val_loss: 0.6657 - val_acc: 0.6171\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6760 - acc: 0.6009 - val_loss: 0.6664 - val_acc: 0.6171\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6759 - acc: 0.5974 - val_loss: 0.6665 - val_acc: 0.6171\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.6724 - acc: 0.5991 - val_loss: 0.6646 - val_acc: 0.6171\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.6762 - acc: 0.6028 - val_loss: 0.6637 - val_acc: 0.6171\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6719 - acc: 0.6050 - val_loss: 0.6617 - val_acc: 0.6171\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6725 - acc: 0.6035 - val_loss: 0.6535 - val_acc: 0.6171\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.6566 - acc: 0.6112 - val_loss: 0.6343 - val_acc: 0.6171\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6275 - acc: 0.6242 - val_loss: 0.5989 - val_acc: 0.6171\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.5794 - acc: 0.6861 - val_loss: 0.5520 - val_acc: 0.7354\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.5276 - acc: 0.7603 - val_loss: 0.5174 - val_acc: 0.7497\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.4754 - acc: 0.7965 - val_loss: 0.4960 - val_acc: 0.7749\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.4395 - acc: 0.8170 - val_loss: 0.4961 - val_acc: 0.7736\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.4073 - acc: 0.8360 - val_loss: 0.4988 - val_acc: 0.7749\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.3963 - acc: 0.8395 - val_loss: 0.5000 - val_acc: 0.7704\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.3624 - acc: 0.8580 - val_loss: 0.5110 - val_acc: 0.7671\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.3506 - acc: 0.8708 - val_loss: 0.5129 - val_acc: 0.7730\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.3376 - acc: 0.8729 - val_loss: 0.5372 - val_acc: 0.7743\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.3215 - acc: 0.8816 - val_loss: 0.5350 - val_acc: 0.7749\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.3033 - acc: 0.8936 - val_loss: 0.5485 - val_acc: 0.7626\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2856 - acc: 0.9038 - val_loss: 0.5646 - val_acc: 0.7697\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.2653 - acc: 0.9137 - val_loss: 0.5934 - val_acc: 0.7620\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2572 - acc: 0.9154 - val_loss: 0.6134 - val_acc: 0.7684\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.2403 - acc: 0.9251 - val_loss: 0.6341 - val_acc: 0.7600\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2272 - acc: 0.9327 - val_loss: 0.6472 - val_acc: 0.7620\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2228 - acc: 0.9342 - val_loss: 0.6729 - val_acc: 0.7620\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2144 - acc: 0.9357 - val_loss: 0.6758 - val_acc: 0.7549\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2002 - acc: 0.9443 - val_loss: 0.6948 - val_acc: 0.7574\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.1908 - acc: 0.9489 - val_loss: 0.7104 - val_acc: 0.7510\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.1886 - acc: 0.9474 - val_loss: 0.7252 - val_acc: 0.7633\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.1994 - acc: 0.9411 - val_loss: 0.7264 - val_acc: 0.7568\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2019 - acc: 0.9398Restoring model weights from the end of the best epoch: 13.\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2019 - acc: 0.9398 - val_loss: 0.7316 - val_acc: 0.7497\n",
      "Epoch 00033: early stopping\n",
      "WARNING:tensorflow:Layer lstm_180 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_181 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_182 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_183 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 5s 152ms/step - loss: 0.7005 - acc: 0.5273 - val_loss: 0.6611 - val_acc: 0.6274\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.6834 - acc: 0.6000 - val_loss: 0.6602 - val_acc: 0.6274\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6807 - acc: 0.5920 - val_loss: 0.6648 - val_acc: 0.6274\n",
      "Epoch 4/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6780 - acc: 0.5916 - val_loss: 0.6608 - val_acc: 0.6274\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6804 - acc: 0.5946 - val_loss: 0.6592 - val_acc: 0.6274\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6702 - acc: 0.6024 - val_loss: 0.6583 - val_acc: 0.6274\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6732 - acc: 0.6004 - val_loss: 0.6528 - val_acc: 0.6274\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.6644 - acc: 0.6052 - val_loss: 0.6405 - val_acc: 0.6274\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.6414 - acc: 0.6194 - val_loss: 0.6166 - val_acc: 0.6274\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 140ms/step - loss: 0.6063 - acc: 0.6628 - val_loss: 0.5798 - val_acc: 0.7038\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.5493 - acc: 0.7379 - val_loss: 0.5479 - val_acc: 0.7380\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.4922 - acc: 0.7896 - val_loss: 0.5351 - val_acc: 0.7484\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.4448 - acc: 0.8157 - val_loss: 0.5202 - val_acc: 0.7568\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.4094 - acc: 0.8350 - val_loss: 0.5193 - val_acc: 0.7665\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.3881 - acc: 0.8455 - val_loss: 0.5305 - val_acc: 0.7678\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.3701 - acc: 0.8554 - val_loss: 0.5435 - val_acc: 0.7568\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.3382 - acc: 0.8753 - val_loss: 0.5459 - val_acc: 0.7658\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.3171 - acc: 0.8898 - val_loss: 0.5678 - val_acc: 0.7626\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.2996 - acc: 0.8986 - val_loss: 0.5894 - val_acc: 0.7607\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.2788 - acc: 0.9083 - val_loss: 0.6181 - val_acc: 0.7529\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2631 - acc: 0.9135 - val_loss: 0.6369 - val_acc: 0.7497\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.2446 - acc: 0.9210 - val_loss: 0.6511 - val_acc: 0.7523\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2278 - acc: 0.9316 - val_loss: 0.6808 - val_acc: 0.7464\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.2189 - acc: 0.9366 - val_loss: 0.7135 - val_acc: 0.7497\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2130 - acc: 0.9389 - val_loss: 0.7258 - val_acc: 0.7477\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.1999 - acc: 0.9433 - val_loss: 0.7267 - val_acc: 0.7458\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.1963 - acc: 0.9469 - val_loss: 0.7567 - val_acc: 0.7387\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.1844 - acc: 0.9487 - val_loss: 0.7738 - val_acc: 0.7374\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 0.1769 - acc: 0.9530 - val_loss: 0.7862 - val_acc: 0.7367\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.1749 - acc: 0.9538 - val_loss: 0.7988 - val_acc: 0.7367\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.1684 - acc: 0.9530 - val_loss: 0.8187 - val_acc: 0.7348\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.1795 - acc: 0.9487 - val_loss: 0.8169 - val_acc: 0.7354\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.1837 - acc: 0.9454 - val_loss: 0.8958 - val_acc: 0.7057\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1815 - acc: 0.9458Restoring model weights from the end of the best epoch: 14.\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.1815 - acc: 0.9458 - val_loss: 0.8053 - val_acc: 0.7439\n",
      "Epoch 00034: early stopping\n",
      "WARNING:tensorflow:Layer lstm_184 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_185 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_186 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_187 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 5s 158ms/step - loss: 0.6728 - acc: 0.6117 - val_loss: 0.6864 - val_acc: 0.5796\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6695 - acc: 0.6194 - val_loss: 0.6830 - val_acc: 0.5796\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6697 - acc: 0.6181 - val_loss: 0.6855 - val_acc: 0.5796\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 0.6672 - acc: 0.6203 - val_loss: 0.6826 - val_acc: 0.5796\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6662 - acc: 0.6203 - val_loss: 0.6810 - val_acc: 0.5796\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6629 - acc: 0.6207 - val_loss: 0.6775 - val_acc: 0.5796\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6530 - acc: 0.6218 - val_loss: 0.6609 - val_acc: 0.5796\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6279 - acc: 0.6317 - val_loss: 0.6214 - val_acc: 0.6061\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.5707 - acc: 0.7094 - val_loss: 0.5613 - val_acc: 0.7354\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.5077 - acc: 0.7661 - val_loss: 0.5342 - val_acc: 0.7568\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.4551 - acc: 0.8011 - val_loss: 0.5183 - val_acc: 0.7587\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.4121 - acc: 0.8252 - val_loss: 0.5174 - val_acc: 0.7626\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.3805 - acc: 0.8485 - val_loss: 0.5510 - val_acc: 0.7574\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.3490 - acc: 0.8649 - val_loss: 0.5512 - val_acc: 0.7600\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.3205 - acc: 0.8744 - val_loss: 0.5764 - val_acc: 0.7587\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.3041 - acc: 0.8910 - val_loss: 0.5807 - val_acc: 0.7464\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 123ms/step - loss: 0.3104 - acc: 0.8783 - val_loss: 0.6057 - val_acc: 0.7477\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2671 - acc: 0.9077 - val_loss: 0.5959 - val_acc: 0.7380\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.2606 - acc: 0.9105 - val_loss: 0.6616 - val_acc: 0.7406\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.2428 - acc: 0.9182 - val_loss: 0.6455 - val_acc: 0.7413\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 97ms/step - loss: 0.2260 - acc: 0.9299 - val_loss: 0.6864 - val_acc: 0.7393\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2102 - acc: 0.9344 - val_loss: 0.7195 - val_acc: 0.7329\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.2074 - acc: 0.9361 - val_loss: 0.7227 - val_acc: 0.7283\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.1997 - acc: 0.9413 - val_loss: 0.7348 - val_acc: 0.7335\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.1954 - acc: 0.9394 - val_loss: 0.7896 - val_acc: 0.7290\n",
      "Epoch 26/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 91ms/step - loss: 0.1833 - acc: 0.9454 - val_loss: 0.7725 - val_acc: 0.7329\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.1730 - acc: 0.9519 - val_loss: 0.7801 - val_acc: 0.7296\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.1752 - acc: 0.9480 - val_loss: 0.8386 - val_acc: 0.7225\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.1645 - acc: 0.9562 - val_loss: 0.8278 - val_acc: 0.7245\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.1561 - acc: 0.9581 - val_loss: 0.8271 - val_acc: 0.7303\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.1521 - acc: 0.9607 - val_loss: 0.8564 - val_acc: 0.7232\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1478 - acc: 0.9629Restoring model weights from the end of the best epoch: 12.\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.1478 - acc: 0.9629 - val_loss: 0.8674 - val_acc: 0.7225\n",
      "Epoch 00032: early stopping\n",
      "WARNING:tensorflow:Layer lstm_188 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_189 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_190 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_191 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 5s 157ms/step - loss: 0.6717 - acc: 0.6108 - val_loss: 0.6766 - val_acc: 0.5957\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6699 - acc: 0.6091 - val_loss: 0.6748 - val_acc: 0.5957\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6718 - acc: 0.6110 - val_loss: 0.6766 - val_acc: 0.5957\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6712 - acc: 0.6138 - val_loss: 0.6741 - val_acc: 0.5957\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6686 - acc: 0.6149 - val_loss: 0.6737 - val_acc: 0.5957\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6645 - acc: 0.6155 - val_loss: 0.6674 - val_acc: 0.5957\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6546 - acc: 0.6153 - val_loss: 0.6472 - val_acc: 0.5957\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6181 - acc: 0.6436 - val_loss: 0.6026 - val_acc: 0.6772\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.5590 - acc: 0.7202 - val_loss: 0.5486 - val_acc: 0.7316\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.4911 - acc: 0.7771 - val_loss: 0.5415 - val_acc: 0.7354\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.4491 - acc: 0.8032 - val_loss: 0.5291 - val_acc: 0.7477\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 139ms/step - loss: 0.4061 - acc: 0.8311 - val_loss: 0.5334 - val_acc: 0.7542\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.3782 - acc: 0.8529 - val_loss: 0.5410 - val_acc: 0.7477\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.3526 - acc: 0.8660 - val_loss: 0.5675 - val_acc: 0.7587\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 97ms/step - loss: 0.3363 - acc: 0.8714 - val_loss: 0.5604 - val_acc: 0.7523\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.3081 - acc: 0.8895 - val_loss: 0.5723 - val_acc: 0.7503\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2904 - acc: 0.8977 - val_loss: 0.5942 - val_acc: 0.7568\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.2797 - acc: 0.9044 - val_loss: 0.6318 - val_acc: 0.7464\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2685 - acc: 0.9059 - val_loss: 0.6240 - val_acc: 0.7587\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2475 - acc: 0.9245 - val_loss: 0.6322 - val_acc: 0.7497\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.2354 - acc: 0.9299 - val_loss: 0.6614 - val_acc: 0.7426\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2253 - acc: 0.9316 - val_loss: 0.6791 - val_acc: 0.7497\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2091 - acc: 0.9383 - val_loss: 0.6944 - val_acc: 0.7510\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.1980 - acc: 0.9437 - val_loss: 0.7191 - val_acc: 0.7432\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.1874 - acc: 0.9471 - val_loss: 0.7445 - val_acc: 0.7413\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.1872 - acc: 0.9446 - val_loss: 0.7540 - val_acc: 0.7413\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.1717 - acc: 0.9540 - val_loss: 0.7772 - val_acc: 0.7387\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.1633 - acc: 0.9588 - val_loss: 0.7948 - val_acc: 0.7361\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.1609 - acc: 0.9594 - val_loss: 0.8121 - val_acc: 0.7329\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.1546 - acc: 0.9597 - val_loss: 0.8322 - val_acc: 0.7335\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1488 - acc: 0.9605Restoring model weights from the end of the best epoch: 11.\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.1488 - acc: 0.9605 - val_loss: 0.8300 - val_acc: 0.7296\n",
      "Epoch 00031: early stopping\n",
      "WARNING:tensorflow:Layer lstm_192 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_193 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_194 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_195 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 5s 151ms/step - loss: 0.6828 - acc: 0.5698 - val_loss: 0.6831 - val_acc: 0.5964\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.6768 - acc: 0.6125 - val_loss: 0.6754 - val_acc: 0.5964\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6689 - acc: 0.6114 - val_loss: 0.6741 - val_acc: 0.5964\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.6723 - acc: 0.6093 - val_loss: 0.6744 - val_acc: 0.5964\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.6692 - acc: 0.6132 - val_loss: 0.6750 - val_acc: 0.5964\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6676 - acc: 0.6112 - val_loss: 0.6716 - val_acc: 0.5964\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 131ms/step - loss: 0.6652 - acc: 0.6134 - val_loss: 0.6669 - val_acc: 0.5964\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6592 - acc: 0.6147 - val_loss: 0.6524 - val_acc: 0.5964\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.6351 - acc: 0.6252 - val_loss: 0.6201 - val_acc: 0.5964\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.5920 - acc: 0.6792 - val_loss: 0.5754 - val_acc: 0.7283\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.5281 - acc: 0.7599 - val_loss: 0.5357 - val_acc: 0.7536\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.4751 - acc: 0.7888 - val_loss: 0.5131 - val_acc: 0.7529\n",
      "Epoch 13/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 94ms/step - loss: 0.4306 - acc: 0.8198 - val_loss: 0.5058 - val_acc: 0.7652\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.3976 - acc: 0.8365 - val_loss: 0.5189 - val_acc: 0.7523\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.3755 - acc: 0.8507 - val_loss: 0.5301 - val_acc: 0.7574\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.3451 - acc: 0.8714 - val_loss: 0.5463 - val_acc: 0.7639\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.3371 - acc: 0.8688 - val_loss: 0.5763 - val_acc: 0.7510\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.3334 - acc: 0.8738 - val_loss: 0.5576 - val_acc: 0.7555\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2979 - acc: 0.8947 - val_loss: 0.5786 - val_acc: 0.7587\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2762 - acc: 0.9046 - val_loss: 0.5862 - val_acc: 0.7581\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.2553 - acc: 0.9163 - val_loss: 0.6085 - val_acc: 0.7568\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.2453 - acc: 0.9225 - val_loss: 0.6321 - val_acc: 0.7529\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2310 - acc: 0.9282 - val_loss: 0.6508 - val_acc: 0.7536\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.2259 - acc: 0.9307 - val_loss: 0.6821 - val_acc: 0.7471\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2193 - acc: 0.9301 - val_loss: 0.6865 - val_acc: 0.7542\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.1989 - acc: 0.9430 - val_loss: 0.6968 - val_acc: 0.7503\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.1903 - acc: 0.9463 - val_loss: 0.7153 - val_acc: 0.7516\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.1814 - acc: 0.9502 - val_loss: 0.7367 - val_acc: 0.7471\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.1750 - acc: 0.9517 - val_loss: 0.7570 - val_acc: 0.7503\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.1657 - acc: 0.9566 - val_loss: 0.7741 - val_acc: 0.7464\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.1630 - acc: 0.9562 - val_loss: 0.7940 - val_acc: 0.7458\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.1571 - acc: 0.9573 - val_loss: 0.8038 - val_acc: 0.7445\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1633 - acc: 0.9547Restoring model weights from the end of the best epoch: 13.\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.1633 - acc: 0.9547 - val_loss: 0.8384 - val_acc: 0.7445\n",
      "Epoch 00033: early stopping\n",
      "WARNING:tensorflow:Layer lstm_196 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_197 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_198 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_199 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 5s 150ms/step - loss: 0.7179 - acc: 0.4882 - val_loss: 0.6671 - val_acc: 0.6138\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.6874 - acc: 0.6006 - val_loss: 0.6705 - val_acc: 0.6138\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6770 - acc: 0.6041 - val_loss: 0.6670 - val_acc: 0.6138\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.6783 - acc: 0.5909 - val_loss: 0.6677 - val_acc: 0.6138\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6790 - acc: 0.5909 - val_loss: 0.6665 - val_acc: 0.6138\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6746 - acc: 0.6015 - val_loss: 0.6656 - val_acc: 0.6138\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6748 - acc: 0.6032 - val_loss: 0.6642 - val_acc: 0.6138\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6712 - acc: 0.6056 - val_loss: 0.6612 - val_acc: 0.6138\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6662 - acc: 0.6093 - val_loss: 0.6527 - val_acc: 0.6138\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6543 - acc: 0.6123 - val_loss: 0.6340 - val_acc: 0.6138\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6249 - acc: 0.6334 - val_loss: 0.6018 - val_acc: 0.6138\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.5785 - acc: 0.6949 - val_loss: 0.5611 - val_acc: 0.7322\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 131ms/step - loss: 0.5193 - acc: 0.7691 - val_loss: 0.5385 - val_acc: 0.7406\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.4686 - acc: 0.8065 - val_loss: 0.5477 - val_acc: 0.7471\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.4408 - acc: 0.8164 - val_loss: 0.5519 - val_acc: 0.7232\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.4272 - acc: 0.8235 - val_loss: 0.5339 - val_acc: 0.7387\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.3955 - acc: 0.8468 - val_loss: 0.5319 - val_acc: 0.7536\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.3672 - acc: 0.8608 - val_loss: 0.5392 - val_acc: 0.7607\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.3464 - acc: 0.8751 - val_loss: 0.5513 - val_acc: 0.7600\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.3268 - acc: 0.8854 - val_loss: 0.5751 - val_acc: 0.7555\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.3093 - acc: 0.8949 - val_loss: 0.5883 - val_acc: 0.7542\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.2934 - acc: 0.9046 - val_loss: 0.6032 - val_acc: 0.7600\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.2804 - acc: 0.9100 - val_loss: 0.6120 - val_acc: 0.7490\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2657 - acc: 0.9176 - val_loss: 0.6289 - val_acc: 0.7587\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.2583 - acc: 0.9221 - val_loss: 0.6367 - val_acc: 0.7561\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.2461 - acc: 0.9266 - val_loss: 0.6489 - val_acc: 0.7536\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.2331 - acc: 0.9307 - val_loss: 0.6595 - val_acc: 0.7523\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2214 - acc: 0.9385 - val_loss: 0.6673 - val_acc: 0.7503\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.2166 - acc: 0.9413 - val_loss: 0.6844 - val_acc: 0.7536\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2019 - acc: 0.9465 - val_loss: 0.7033 - val_acc: 0.7477\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.1973 - acc: 0.9482 - val_loss: 0.7072 - val_acc: 0.7549\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 0.1913 - acc: 0.9508 - val_loss: 0.7299 - val_acc: 0.7387\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.1881 - acc: 0.9499 - val_loss: 0.7387 - val_acc: 0.7439\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.1814 - acc: 0.9549 - val_loss: 0.7407 - val_acc: 0.7477\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.1751 - acc: 0.9571 - val_loss: 0.7478 - val_acc: 0.7510\n",
      "Epoch 36/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 93ms/step - loss: 0.1730 - acc: 0.9571 - val_loss: 0.7601 - val_acc: 0.7516\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1729 - acc: 0.9577Restoring model weights from the end of the best epoch: 17.\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.1729 - acc: 0.9577 - val_loss: 0.7857 - val_acc: 0.7348\n",
      "Epoch 00037: early stopping\n",
      "WARNING:tensorflow:Layer lstm_200 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_201 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_202 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_203 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 5s 203ms/step - loss: 0.6747 - acc: 0.6028 - val_loss: 0.6628 - val_acc: 0.6229\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6763 - acc: 0.5983 - val_loss: 0.6639 - val_acc: 0.6229\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6741 - acc: 0.6039 - val_loss: 0.6625 - val_acc: 0.6229\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6742 - acc: 0.6063 - val_loss: 0.6627 - val_acc: 0.6229\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6711 - acc: 0.6060 - val_loss: 0.6607 - val_acc: 0.6229\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6706 - acc: 0.6026 - val_loss: 0.6548 - val_acc: 0.6229\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6552 - acc: 0.6078 - val_loss: 0.6292 - val_acc: 0.6229\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6204 - acc: 0.6393 - val_loss: 0.5803 - val_acc: 0.7245\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.5549 - acc: 0.7387 - val_loss: 0.5233 - val_acc: 0.7523\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.5079 - acc: 0.7653 - val_loss: 0.5168 - val_acc: 0.7393\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.4622 - acc: 0.7978 - val_loss: 0.4972 - val_acc: 0.7743\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.4280 - acc: 0.8194 - val_loss: 0.5168 - val_acc: 0.7587\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.4018 - acc: 0.8339 - val_loss: 0.5189 - val_acc: 0.7613\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.3752 - acc: 0.8462 - val_loss: 0.5160 - val_acc: 0.7581\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.3502 - acc: 0.8649 - val_loss: 0.5325 - val_acc: 0.7639\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.3277 - acc: 0.8787 - val_loss: 0.5416 - val_acc: 0.7587\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.3035 - acc: 0.8913 - val_loss: 0.5605 - val_acc: 0.7652\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.2975 - acc: 0.8921 - val_loss: 0.5964 - val_acc: 0.7549\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2821 - acc: 0.9005 - val_loss: 0.5809 - val_acc: 0.7523\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2646 - acc: 0.9081 - val_loss: 0.6093 - val_acc: 0.7529\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.2533 - acc: 0.9126 - val_loss: 0.6033 - val_acc: 0.7477\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 0.2395 - acc: 0.9195 - val_loss: 0.6367 - val_acc: 0.7594\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 138ms/step - loss: 0.2323 - acc: 0.9258 - val_loss: 0.6287 - val_acc: 0.7516\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.2188 - acc: 0.9294 - val_loss: 0.6337 - val_acc: 0.7536\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.2083 - acc: 0.9355 - val_loss: 0.6567 - val_acc: 0.7497\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.1904 - acc: 0.9441 - val_loss: 0.6838 - val_acc: 0.7510\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.1766 - acc: 0.9499 - val_loss: 0.6982 - val_acc: 0.7529\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.1704 - acc: 0.9517 - val_loss: 0.7163 - val_acc: 0.7458\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.1648 - acc: 0.9549 - val_loss: 0.7328 - val_acc: 0.7490\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.1521 - acc: 0.9607 - val_loss: 0.7460 - val_acc: 0.7497\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1505 - acc: 0.9605Restoring model weights from the end of the best epoch: 11.\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.1505 - acc: 0.9605 - val_loss: 0.7843 - val_acc: 0.7497\n",
      "Epoch 00031: early stopping\n",
      "WARNING:tensorflow:Layer lstm_204 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_205 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_206 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_207 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 5s 156ms/step - loss: 0.8302 - acc: 0.3881 - val_loss: 0.7103 - val_acc: 0.4101\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6881 - acc: 0.5569 - val_loss: 0.6843 - val_acc: 0.5899\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6802 - acc: 0.6149 - val_loss: 0.6888 - val_acc: 0.5899\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6722 - acc: 0.6162 - val_loss: 0.6795 - val_acc: 0.5899\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6692 - acc: 0.6106 - val_loss: 0.6770 - val_acc: 0.5899\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6735 - acc: 0.5996 - val_loss: 0.6769 - val_acc: 0.5899\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6707 - acc: 0.6095 - val_loss: 0.6779 - val_acc: 0.5899\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6714 - acc: 0.6117 - val_loss: 0.6783 - val_acc: 0.5899\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6692 - acc: 0.6145 - val_loss: 0.6774 - val_acc: 0.5899\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6697 - acc: 0.6101 - val_loss: 0.6766 - val_acc: 0.5899\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6690 - acc: 0.6121 - val_loss: 0.6759 - val_acc: 0.5899\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6661 - acc: 0.6136 - val_loss: 0.6753 - val_acc: 0.5899\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6648 - acc: 0.6160 - val_loss: 0.6720 - val_acc: 0.5899\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6585 - acc: 0.6168 - val_loss: 0.6654 - val_acc: 0.5899\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6519 - acc: 0.6177 - val_loss: 0.6530 - val_acc: 0.5899\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6347 - acc: 0.6222 - val_loss: 0.6319 - val_acc: 0.5899\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6025 - acc: 0.6434 - val_loss: 0.5970 - val_acc: 0.6598\n",
      "Epoch 18/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 90ms/step - loss: 0.5465 - acc: 0.7433 - val_loss: 0.5630 - val_acc: 0.7471\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.4927 - acc: 0.8039 - val_loss: 0.5347 - val_acc: 0.7458\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.4493 - acc: 0.8283 - val_loss: 0.5373 - val_acc: 0.7594\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.4104 - acc: 0.8501 - val_loss: 0.5363 - val_acc: 0.7549\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.3787 - acc: 0.8684 - val_loss: 0.5471 - val_acc: 0.7516\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.3560 - acc: 0.8790 - val_loss: 0.5661 - val_acc: 0.7471\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.3362 - acc: 0.8915 - val_loss: 0.5749 - val_acc: 0.7426\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 137ms/step - loss: 0.3292 - acc: 0.8908 - val_loss: 0.5701 - val_acc: 0.7542\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.3248 - acc: 0.8887 - val_loss: 0.6160 - val_acc: 0.7445\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 0.3118 - acc: 0.8939 - val_loss: 0.5925 - val_acc: 0.7510\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.2896 - acc: 0.9096 - val_loss: 0.5936 - val_acc: 0.7574\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2742 - acc: 0.9154 - val_loss: 0.6177 - val_acc: 0.7536\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2620 - acc: 0.9206 - val_loss: 0.6279 - val_acc: 0.7542\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 0.2608 - acc: 0.9262 - val_loss: 0.6538 - val_acc: 0.7503\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.2507 - acc: 0.9275 - val_loss: 0.6486 - val_acc: 0.7497\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2474 - acc: 0.9290 - val_loss: 0.6627 - val_acc: 0.7458\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2353 - acc: 0.9348 - val_loss: 0.6700 - val_acc: 0.7458\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.2252 - acc: 0.9385 - val_loss: 0.6736 - val_acc: 0.7529\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 0.2279 - acc: 0.9379 - val_loss: 0.6999 - val_acc: 0.7490\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2221 - acc: 0.9402 - val_loss: 0.6915 - val_acc: 0.7471\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2172 - acc: 0.9392 - val_loss: 0.7063 - val_acc: 0.7497\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2064 - acc: 0.9474Restoring model weights from the end of the best epoch: 19.\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.2064 - acc: 0.9474 - val_loss: 0.7105 - val_acc: 0.7497\n",
      "Epoch 00039: early stopping\n",
      "LSTM 정확도 : 0.7602846054333764, Precision : 0.8120813913825744, Recall : 0.7917372881355933, F1 : 0.801066945397603, roc_auc : 0.7513503716425474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.7645536869340233,\n",
       "  0.7652005174644243,\n",
       "  0.7464424320827943,\n",
       "  0.7600258732212161,\n",
       "  0.7671410090556274,\n",
       "  0.7684346701164295,\n",
       "  0.7613195342820182,\n",
       "  0.7580853816300129,\n",
       "  0.7684346701164295,\n",
       "  0.7432082794307892],\n",
       " [0.7971311475409836,\n",
       "  0.8087141339001063,\n",
       "  0.7899159663865546,\n",
       "  0.8208286674132139,\n",
       "  0.8086680761099366,\n",
       "  0.8447058823529412,\n",
       "  0.8074866310160428,\n",
       "  0.8064516129032258,\n",
       "  0.7971602434077079,\n",
       "  0.8397515527950311],\n",
       " [0.8241525423728814,\n",
       "  0.8061440677966102,\n",
       "  0.7966101694915254,\n",
       "  0.7764830508474576,\n",
       "  0.8103813559322034,\n",
       "  0.760593220338983,\n",
       "  0.7997881355932204,\n",
       "  0.7944915254237288,\n",
       "  0.8326271186440678,\n",
       "  0.7161016949152542],\n",
       " [0.8104166666666667,\n",
       "  0.8074270557029177,\n",
       "  0.7932489451476793,\n",
       "  0.7980402830702231,\n",
       "  0.8095238095238095,\n",
       "  0.8004459308807135,\n",
       "  0.8036189462480043,\n",
       "  0.80042689434365,\n",
       "  0.8145077720207254,\n",
       "  0.773013150371641],\n",
       " [0.7476244439439157,\n",
       "  0.7535703727687371,\n",
       "  0.7321921279351316,\n",
       "  0.7553511599752238,\n",
       "  0.7548584520524804,\n",
       "  0.7706620586744749,\n",
       "  0.7503924066670421,\n",
       "  0.7477441015822963,\n",
       "  0.7502006025114027,\n",
       "  0.75090799031477])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series_cv('LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89377588",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a2b588824d54866aa64ead268f56773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "9/9 [==============================] - 4s 112ms/step - loss: 0.7473 - acc: 0.4507 - val_loss: 0.6746 - val_acc: 0.6054\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.6813 - acc: 0.5940 - val_loss: 0.6799 - val_acc: 0.6054\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 0.6815 - acc: 0.6069 - val_loss: 0.6743 - val_acc: 0.6054\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.6745 - acc: 0.6050 - val_loss: 0.6701 - val_acc: 0.6054\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 0.6783 - acc: 0.5922 - val_loss: 0.6699 - val_acc: 0.6054\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 0.6771 - acc: 0.5933 - val_loss: 0.6693 - val_acc: 0.6054\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.6757 - acc: 0.6060 - val_loss: 0.6684 - val_acc: 0.6054\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 0.6725 - acc: 0.6080 - val_loss: 0.6669 - val_acc: 0.6054\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 0.6681 - acc: 0.6117 - val_loss: 0.6637 - val_acc: 0.6054\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 0.6579 - acc: 0.6179 - val_loss: 0.6552 - val_acc: 0.6054\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.6482 - acc: 0.6160 - val_loss: 0.6406 - val_acc: 0.6054\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.6288 - acc: 0.6293 - val_loss: 0.6227 - val_acc: 0.6054\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.6014 - acc: 0.6572 - val_loss: 0.5958 - val_acc: 0.7141\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 0.5605 - acc: 0.7327 - val_loss: 0.5639 - val_acc: 0.7400\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 0.5137 - acc: 0.7832 - val_loss: 0.5410 - val_acc: 0.7426\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.4678 - acc: 0.8056 - val_loss: 0.5392 - val_acc: 0.7400\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.4327 - acc: 0.8252 - val_loss: 0.5369 - val_acc: 0.7471\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 107ms/step - loss: 0.4155 - acc: 0.8332 - val_loss: 0.5468 - val_acc: 0.7251\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.3861 - acc: 0.8520 - val_loss: 0.5497 - val_acc: 0.7471\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.3678 - acc: 0.8626 - val_loss: 0.5601 - val_acc: 0.7374\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.3471 - acc: 0.8759 - val_loss: 0.5758 - val_acc: 0.7387\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.3299 - acc: 0.8824 - val_loss: 0.5854 - val_acc: 0.7477\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.3117 - acc: 0.8895 - val_loss: 0.5979 - val_acc: 0.7458\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.3022 - acc: 0.9020 - val_loss: 0.6117 - val_acc: 0.7426\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.2906 - acc: 0.9042 - val_loss: 0.6367 - val_acc: 0.7303\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.2785 - acc: 0.9085 - val_loss: 0.6307 - val_acc: 0.7451\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.2726 - acc: 0.9115 - val_loss: 0.6520 - val_acc: 0.7335\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.2659 - acc: 0.9172 - val_loss: 0.6431 - val_acc: 0.7426\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.2572 - acc: 0.9223 - val_loss: 0.6507 - val_acc: 0.7471\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.2416 - acc: 0.9297 - val_loss: 0.6592 - val_acc: 0.7458\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.2355 - acc: 0.9310 - val_loss: 0.6760 - val_acc: 0.7406\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.2332 - acc: 0.9335 - val_loss: 0.6885 - val_acc: 0.7406\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.2237 - acc: 0.9366 - val_loss: 0.6985 - val_acc: 0.7367\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.2182 - acc: 0.9411 - val_loss: 0.7069 - val_acc: 0.7335\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.2136 - acc: 0.9424 - val_loss: 0.7145 - val_acc: 0.7348\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.2139 - acc: 0.9422 - val_loss: 0.7178 - val_acc: 0.7361\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2085 - acc: 0.9443Restoring model weights from the end of the best epoch: 17.\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.2085 - acc: 0.9443 - val_loss: 0.7233 - val_acc: 0.7348\n",
      "Epoch 00037: early stopping\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 3s 116ms/step - loss: 0.7019 - acc: 0.5335 - val_loss: 0.6684 - val_acc: 0.6132\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.6935 - acc: 0.5998 - val_loss: 0.6699 - val_acc: 0.6132\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.6845 - acc: 0.5901 - val_loss: 0.6679 - val_acc: 0.6132\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.6802 - acc: 0.5853 - val_loss: 0.6667 - val_acc: 0.6132\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.6780 - acc: 0.5927 - val_loss: 0.6651 - val_acc: 0.6132\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.6749 - acc: 0.5981 - val_loss: 0.6633 - val_acc: 0.6132\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.6749 - acc: 0.5987 - val_loss: 0.6599 - val_acc: 0.6132\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.6659 - acc: 0.6019 - val_loss: 0.6497 - val_acc: 0.6132\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.6499 - acc: 0.6166 - val_loss: 0.6250 - val_acc: 0.6132\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.6203 - acc: 0.6485 - val_loss: 0.5935 - val_acc: 0.6973\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.5815 - acc: 0.7027 - val_loss: 0.5545 - val_acc: 0.7387\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.5327 - acc: 0.7573 - val_loss: 0.5225 - val_acc: 0.7490\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.4909 - acc: 0.7748 - val_loss: 0.4993 - val_acc: 0.7626\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.4571 - acc: 0.7961 - val_loss: 0.4890 - val_acc: 0.7717\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 0.4265 - acc: 0.8134 - val_loss: 0.4900 - val_acc: 0.7717\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.4017 - acc: 0.8332 - val_loss: 0.4928 - val_acc: 0.7697\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.3808 - acc: 0.8410 - val_loss: 0.5008 - val_acc: 0.7743\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.3583 - acc: 0.8509 - val_loss: 0.5092 - val_acc: 0.7704\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.3384 - acc: 0.8626 - val_loss: 0.5256 - val_acc: 0.7730\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.3209 - acc: 0.8757 - val_loss: 0.5419 - val_acc: 0.7697\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.3068 - acc: 0.8807 - val_loss: 0.5515 - val_acc: 0.7620\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.2922 - acc: 0.8895 - val_loss: 0.5701 - val_acc: 0.7658\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.2742 - acc: 0.8934 - val_loss: 0.5910 - val_acc: 0.7626\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.2632 - acc: 0.9051 - val_loss: 0.6065 - val_acc: 0.7607\n",
      "Epoch 25/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 60ms/step - loss: 0.2492 - acc: 0.9126 - val_loss: 0.6275 - val_acc: 0.7561\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.2362 - acc: 0.9163 - val_loss: 0.6560 - val_acc: 0.7536\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.2261 - acc: 0.9213 - val_loss: 0.6761 - val_acc: 0.7471\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.2238 - acc: 0.9228 - val_loss: 0.6834 - val_acc: 0.7529\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.2108 - acc: 0.9294 - val_loss: 0.6983 - val_acc: 0.7523\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.2024 - acc: 0.9333 - val_loss: 0.7139 - val_acc: 0.7536\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.1933 - acc: 0.9407 - val_loss: 0.7319 - val_acc: 0.7529\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.1840 - acc: 0.9446 - val_loss: 0.7589 - val_acc: 0.7497\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.1779 - acc: 0.9456 - val_loss: 0.7655 - val_acc: 0.7542\n",
      "Epoch 34/300\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 0.1688 - acc: 0.9479Restoring model weights from the end of the best epoch: 14.\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.1711 - acc: 0.9487 - val_loss: 0.7853 - val_acc: 0.7426\n",
      "Epoch 00034: early stopping\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 3s 122ms/step - loss: 0.6785 - acc: 0.5935 - val_loss: 0.6651 - val_acc: 0.6171\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.6783 - acc: 0.5948 - val_loss: 0.6653 - val_acc: 0.6171\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.6760 - acc: 0.5998 - val_loss: 0.6633 - val_acc: 0.6171\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.6706 - acc: 0.6047 - val_loss: 0.6608 - val_acc: 0.6171\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.6671 - acc: 0.6073 - val_loss: 0.6535 - val_acc: 0.6171\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.6543 - acc: 0.6132 - val_loss: 0.6296 - val_acc: 0.6171\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.6205 - acc: 0.6520 - val_loss: 0.5884 - val_acc: 0.7115\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.5816 - acc: 0.7053 - val_loss: 0.5503 - val_acc: 0.7400\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.5371 - acc: 0.7439 - val_loss: 0.5183 - val_acc: 0.7413\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.4982 - acc: 0.7696 - val_loss: 0.4927 - val_acc: 0.7749\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.4632 - acc: 0.7940 - val_loss: 0.4820 - val_acc: 0.7710\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.4424 - acc: 0.8052 - val_loss: 0.4772 - val_acc: 0.7820\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.4148 - acc: 0.8214 - val_loss: 0.4792 - val_acc: 0.7775\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.3909 - acc: 0.8375 - val_loss: 0.4928 - val_acc: 0.7684\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.3734 - acc: 0.8447 - val_loss: 0.4990 - val_acc: 0.7704\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.3589 - acc: 0.8561 - val_loss: 0.5101 - val_acc: 0.7730\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.3382 - acc: 0.8647 - val_loss: 0.5366 - val_acc: 0.7691\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.3220 - acc: 0.8725 - val_loss: 0.5338 - val_acc: 0.7587\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.3048 - acc: 0.8807 - val_loss: 0.5541 - val_acc: 0.7646\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.2912 - acc: 0.8882 - val_loss: 0.5688 - val_acc: 0.7549\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.2755 - acc: 0.8988 - val_loss: 0.5917 - val_acc: 0.7652\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.2685 - acc: 0.9003 - val_loss: 0.6041 - val_acc: 0.7581\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.2474 - acc: 0.9126 - val_loss: 0.6231 - val_acc: 0.7516\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.2396 - acc: 0.9178 - val_loss: 0.6483 - val_acc: 0.7626\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.2270 - acc: 0.9225 - val_loss: 0.6600 - val_acc: 0.7497\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.2208 - acc: 0.9256 - val_loss: 0.6779 - val_acc: 0.7510\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.2096 - acc: 0.9335 - val_loss: 0.6900 - val_acc: 0.7484\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.2022 - acc: 0.9351 - val_loss: 0.7201 - val_acc: 0.7426\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.1899 - acc: 0.9422 - val_loss: 0.7290 - val_acc: 0.7484\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.1826 - acc: 0.9435 - val_loss: 0.7486 - val_acc: 0.7529\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.1773 - acc: 0.9495 - val_loss: 0.7665 - val_acc: 0.7523\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1723 - acc: 0.9491Restoring model weights from the end of the best epoch: 12.\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.1723 - acc: 0.9491 - val_loss: 0.7876 - val_acc: 0.7471\n",
      "Epoch 00032: early stopping\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 3s 163ms/step - loss: 0.6894 - acc: 0.5752 - val_loss: 0.6622 - val_acc: 0.6274\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.6875 - acc: 0.5868 - val_loss: 0.6621 - val_acc: 0.6274\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 0.6810 - acc: 0.5769 - val_loss: 0.6601 - val_acc: 0.6274\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 0.6776 - acc: 0.5994 - val_loss: 0.6562 - val_acc: 0.6274\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.6745 - acc: 0.5994 - val_loss: 0.6545 - val_acc: 0.6274\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 0.6654 - acc: 0.6022 - val_loss: 0.6419 - val_acc: 0.6274\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.6431 - acc: 0.6242 - val_loss: 0.6155 - val_acc: 0.6675\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.6078 - acc: 0.6718 - val_loss: 0.5842 - val_acc: 0.6960\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 0.5668 - acc: 0.7206 - val_loss: 0.5602 - val_acc: 0.7167\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 0.5195 - acc: 0.7556 - val_loss: 0.5295 - val_acc: 0.7393\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.4830 - acc: 0.7782 - val_loss: 0.5111 - val_acc: 0.7490\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.4553 - acc: 0.7920 - val_loss: 0.5040 - val_acc: 0.7607\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.4244 - acc: 0.8095 - val_loss: 0.4982 - val_acc: 0.7684\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.3996 - acc: 0.8276 - val_loss: 0.4959 - val_acc: 0.7762\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 0.3763 - acc: 0.8423 - val_loss: 0.5023 - val_acc: 0.7736\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.3578 - acc: 0.8488 - val_loss: 0.5156 - val_acc: 0.7697\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.3397 - acc: 0.8557 - val_loss: 0.5280 - val_acc: 0.7717\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.3197 - acc: 0.8695 - val_loss: 0.5487 - val_acc: 0.7684\n",
      "Epoch 19/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 59ms/step - loss: 0.3040 - acc: 0.8770 - val_loss: 0.5770 - val_acc: 0.7639\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.2942 - acc: 0.8820 - val_loss: 0.5772 - val_acc: 0.7639\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.2719 - acc: 0.8947 - val_loss: 0.5988 - val_acc: 0.7626\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 0.2639 - acc: 0.9003 - val_loss: 0.6240 - val_acc: 0.7600\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.2453 - acc: 0.9059 - val_loss: 0.6489 - val_acc: 0.7555\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.2380 - acc: 0.9137 - val_loss: 0.6756 - val_acc: 0.7561\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.2231 - acc: 0.9208 - val_loss: 0.7004 - val_acc: 0.7497\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.2205 - acc: 0.9223 - val_loss: 0.7418 - val_acc: 0.7219\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.2149 - acc: 0.9206 - val_loss: 0.7248 - val_acc: 0.7471\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 107ms/step - loss: 0.1998 - acc: 0.9297 - val_loss: 0.7516 - val_acc: 0.7322\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.1919 - acc: 0.9335 - val_loss: 0.7665 - val_acc: 0.7361\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.1788 - acc: 0.9443 - val_loss: 0.7920 - val_acc: 0.7277\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.1709 - acc: 0.9467 - val_loss: 0.8053 - val_acc: 0.7335\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.1661 - acc: 0.9487 - val_loss: 0.8364 - val_acc: 0.7264\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.1573 - acc: 0.9538 - val_loss: 0.8548 - val_acc: 0.7309\n",
      "Epoch 34/300\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 0.1628 - acc: 0.9501Restoring model weights from the end of the best epoch: 14.\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.1600 - acc: 0.9506 - val_loss: 0.8740 - val_acc: 0.7238\n",
      "Epoch 00034: early stopping\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 3s 124ms/step - loss: 1.0040 - acc: 0.3806 - val_loss: 0.7799 - val_acc: 0.4204\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.7462 - acc: 0.4572 - val_loss: 0.6807 - val_acc: 0.5796\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.6776 - acc: 0.5978 - val_loss: 0.6964 - val_acc: 0.5796\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 0.6850 - acc: 0.6132 - val_loss: 0.7014 - val_acc: 0.5796\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.6811 - acc: 0.6119 - val_loss: 0.6904 - val_acc: 0.5796\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.6769 - acc: 0.6071 - val_loss: 0.6833 - val_acc: 0.5796\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.6775 - acc: 0.5987 - val_loss: 0.6820 - val_acc: 0.5796\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.6765 - acc: 0.5989 - val_loss: 0.6829 - val_acc: 0.5796\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.6713 - acc: 0.6030 - val_loss: 0.6840 - val_acc: 0.5796\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.6750 - acc: 0.6117 - val_loss: 0.6842 - val_acc: 0.5796\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.6733 - acc: 0.6071 - val_loss: 0.6839 - val_acc: 0.5796\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.6719 - acc: 0.6088 - val_loss: 0.6834 - val_acc: 0.5796\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.6691 - acc: 0.6088 - val_loss: 0.6822 - val_acc: 0.5796\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.6722 - acc: 0.6067 - val_loss: 0.6819 - val_acc: 0.5796\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.6718 - acc: 0.6065 - val_loss: 0.6808 - val_acc: 0.5796\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.6720 - acc: 0.6119 - val_loss: 0.6792 - val_acc: 0.5796\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.6633 - acc: 0.6162 - val_loss: 0.6747 - val_acc: 0.5796\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.6578 - acc: 0.6216 - val_loss: 0.6693 - val_acc: 0.5796\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.6526 - acc: 0.6231 - val_loss: 0.6614 - val_acc: 0.5796\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.6456 - acc: 0.6239 - val_loss: 0.6524 - val_acc: 0.5796\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.6268 - acc: 0.6412 - val_loss: 0.6375 - val_acc: 0.5796\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 0.6049 - acc: 0.6524 - val_loss: 0.6142 - val_acc: 0.5796\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.5742 - acc: 0.7018 - val_loss: 0.5847 - val_acc: 0.7477\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.5307 - acc: 0.7661 - val_loss: 0.5602 - val_acc: 0.7426\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.4882 - acc: 0.8082 - val_loss: 0.5374 - val_acc: 0.7549\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.4540 - acc: 0.8300 - val_loss: 0.5378 - val_acc: 0.7516\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 0.4149 - acc: 0.8529 - val_loss: 0.5342 - val_acc: 0.7568\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 0.3918 - acc: 0.8617 - val_loss: 0.5403 - val_acc: 0.7516\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.3758 - acc: 0.8686 - val_loss: 0.5504 - val_acc: 0.7490\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.3608 - acc: 0.8775 - val_loss: 0.5758 - val_acc: 0.7510\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.3418 - acc: 0.8833 - val_loss: 0.5735 - val_acc: 0.7464\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.3273 - acc: 0.8947 - val_loss: 0.5895 - val_acc: 0.7477\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.3107 - acc: 0.9008 - val_loss: 0.5997 - val_acc: 0.7445\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.3034 - acc: 0.9074 - val_loss: 0.6157 - val_acc: 0.7406\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.2910 - acc: 0.9107 - val_loss: 0.6307 - val_acc: 0.7290\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.2948 - acc: 0.9044 - val_loss: 0.6523 - val_acc: 0.7361\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.2794 - acc: 0.9148 - val_loss: 0.6391 - val_acc: 0.7348\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.2680 - acc: 0.9213 - val_loss: 0.6485 - val_acc: 0.7322\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.2634 - acc: 0.9243 - val_loss: 0.6723 - val_acc: 0.7335\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 0.2563 - acc: 0.9254 - val_loss: 0.6728 - val_acc: 0.7335\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.2576 - acc: 0.9277 - val_loss: 0.6766 - val_acc: 0.7309\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.2541 - acc: 0.9254 - val_loss: 0.6949 - val_acc: 0.7270\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.2446 - acc: 0.9297 - val_loss: 0.6905 - val_acc: 0.7270\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 0.2399 - acc: 0.9333 - val_loss: 0.7109 - val_acc: 0.7316\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.2363 - acc: 0.9353 - val_loss: 0.7123 - val_acc: 0.7329\n",
      "Epoch 46/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 65ms/step - loss: 0.2301 - acc: 0.9359 - val_loss: 0.7136 - val_acc: 0.7290\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2284 - acc: 0.9389Restoring model weights from the end of the best epoch: 27.\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.2284 - acc: 0.9389 - val_loss: 0.7251 - val_acc: 0.7335\n",
      "Epoch 00047: early stopping\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 4s 119ms/step - loss: 0.7047 - acc: 0.5597 - val_loss: 0.6888 - val_acc: 0.5957\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.6893 - acc: 0.5940 - val_loss: 0.6742 - val_acc: 0.5957\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.6855 - acc: 0.5763 - val_loss: 0.6730 - val_acc: 0.5957\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.6831 - acc: 0.5935 - val_loss: 0.6735 - val_acc: 0.5957\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.6775 - acc: 0.5981 - val_loss: 0.6694 - val_acc: 0.5957\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.6732 - acc: 0.5991 - val_loss: 0.6623 - val_acc: 0.5957\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.6545 - acc: 0.6203 - val_loss: 0.6425 - val_acc: 0.5957\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.6248 - acc: 0.6492 - val_loss: 0.6165 - val_acc: 0.6481\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.5887 - acc: 0.6865 - val_loss: 0.5816 - val_acc: 0.7109\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.5436 - acc: 0.7329 - val_loss: 0.5472 - val_acc: 0.7251\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.4977 - acc: 0.7685 - val_loss: 0.5199 - val_acc: 0.7426\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.4565 - acc: 0.7968 - val_loss: 0.5093 - val_acc: 0.7523\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.4244 - acc: 0.8177 - val_loss: 0.5127 - val_acc: 0.7581\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.3997 - acc: 0.8265 - val_loss: 0.5205 - val_acc: 0.7574\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.3847 - acc: 0.8321 - val_loss: 0.5527 - val_acc: 0.7510\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.3632 - acc: 0.8505 - val_loss: 0.5427 - val_acc: 0.7568\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.3417 - acc: 0.8632 - val_loss: 0.5444 - val_acc: 0.7613\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.3269 - acc: 0.8718 - val_loss: 0.5600 - val_acc: 0.7516\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.3114 - acc: 0.8798 - val_loss: 0.5773 - val_acc: 0.7523\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.2945 - acc: 0.8876 - val_loss: 0.6043 - val_acc: 0.7510\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.2868 - acc: 0.8898 - val_loss: 0.6009 - val_acc: 0.7445\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.2776 - acc: 0.8971 - val_loss: 0.6196 - val_acc: 0.7464\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.2599 - acc: 0.9038 - val_loss: 0.6349 - val_acc: 0.7477\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.2593 - acc: 0.9018 - val_loss: 0.6469 - val_acc: 0.7464\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.2413 - acc: 0.9107 - val_loss: 0.6769 - val_acc: 0.7342\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.2296 - acc: 0.9202 - val_loss: 0.6776 - val_acc: 0.7426\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.2221 - acc: 0.9197 - val_loss: 0.7208 - val_acc: 0.7439\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.2137 - acc: 0.9245 - val_loss: 0.7208 - val_acc: 0.7335\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.2023 - acc: 0.9331 - val_loss: 0.7335 - val_acc: 0.7464\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.1972 - acc: 0.9320 - val_loss: 0.7535 - val_acc: 0.7380\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.1803 - acc: 0.9428 - val_loss: 0.7772 - val_acc: 0.7354\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1744 - acc: 0.9467Restoring model weights from the end of the best epoch: 12.\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.1744 - acc: 0.9467 - val_loss: 0.8061 - val_acc: 0.7387\n",
      "Epoch 00032: early stopping\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 3s 122ms/step - loss: 0.6857 - acc: 0.5877 - val_loss: 0.6791 - val_acc: 0.5964\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.6736 - acc: 0.5983 - val_loss: 0.6735 - val_acc: 0.5964\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.6809 - acc: 0.5968 - val_loss: 0.6745 - val_acc: 0.5964\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.6730 - acc: 0.6015 - val_loss: 0.6704 - val_acc: 0.5964\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.6676 - acc: 0.6119 - val_loss: 0.6641 - val_acc: 0.5964\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.6555 - acc: 0.6194 - val_loss: 0.6451 - val_acc: 0.5964\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.6286 - acc: 0.6369 - val_loss: 0.6063 - val_acc: 0.7076\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.5830 - acc: 0.6954 - val_loss: 0.5733 - val_acc: 0.7025\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.5506 - acc: 0.7225 - val_loss: 0.5405 - val_acc: 0.7316\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.5022 - acc: 0.7653 - val_loss: 0.5218 - val_acc: 0.7367\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.4659 - acc: 0.7821 - val_loss: 0.5037 - val_acc: 0.7549\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.4383 - acc: 0.8030 - val_loss: 0.4994 - val_acc: 0.7555\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.4102 - acc: 0.8190 - val_loss: 0.4925 - val_acc: 0.7639\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.3877 - acc: 0.8302 - val_loss: 0.5019 - val_acc: 0.7665\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.3656 - acc: 0.8444 - val_loss: 0.5171 - val_acc: 0.7633\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.3475 - acc: 0.8552 - val_loss: 0.5546 - val_acc: 0.7523\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.3413 - acc: 0.8559 - val_loss: 0.5435 - val_acc: 0.7536\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.3234 - acc: 0.8708 - val_loss: 0.5487 - val_acc: 0.7549\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.3131 - acc: 0.8725 - val_loss: 0.5793 - val_acc: 0.7613\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.2903 - acc: 0.8882 - val_loss: 0.5838 - val_acc: 0.7633\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.2739 - acc: 0.8982 - val_loss: 0.6007 - val_acc: 0.7568\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.2600 - acc: 0.9046 - val_loss: 0.6273 - val_acc: 0.7529\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.2463 - acc: 0.9163 - val_loss: 0.6495 - val_acc: 0.7484\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.2434 - acc: 0.9133 - val_loss: 0.6681 - val_acc: 0.7490\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.2296 - acc: 0.9223 - val_loss: 0.6976 - val_acc: 0.7510\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.2199 - acc: 0.9228 - val_loss: 0.7146 - val_acc: 0.7380\n",
      "Epoch 27/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 64ms/step - loss: 0.2231 - acc: 0.9215 - val_loss: 0.7698 - val_acc: 0.7451\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.2237 - acc: 0.9202 - val_loss: 0.7279 - val_acc: 0.7458\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.2004 - acc: 0.9333 - val_loss: 0.7585 - val_acc: 0.7542\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 110ms/step - loss: 0.1938 - acc: 0.9392 - val_loss: 0.7589 - val_acc: 0.7464\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.1915 - acc: 0.9381 - val_loss: 0.7871 - val_acc: 0.7439\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.1765 - acc: 0.9465 - val_loss: 0.8041 - val_acc: 0.7380\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1748 - acc: 0.9474Restoring model weights from the end of the best epoch: 13.\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.1748 - acc: 0.9474 - val_loss: 0.8236 - val_acc: 0.7354\n",
      "Epoch 00033: early stopping\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 4s 118ms/step - loss: 0.6784 - acc: 0.5946 - val_loss: 0.6666 - val_acc: 0.6138\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.6783 - acc: 0.5935 - val_loss: 0.6661 - val_acc: 0.6138\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.6777 - acc: 0.6002 - val_loss: 0.6652 - val_acc: 0.6138\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 0.6736 - acc: 0.5927 - val_loss: 0.6628 - val_acc: 0.6138\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.6657 - acc: 0.6067 - val_loss: 0.6552 - val_acc: 0.6138\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.6544 - acc: 0.6151 - val_loss: 0.6323 - val_acc: 0.6138\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.6250 - acc: 0.6391 - val_loss: 0.5927 - val_acc: 0.6915\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.5853 - acc: 0.6971 - val_loss: 0.5557 - val_acc: 0.7180\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.5405 - acc: 0.7398 - val_loss: 0.5234 - val_acc: 0.7464\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.4897 - acc: 0.7782 - val_loss: 0.5041 - val_acc: 0.7484\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.4526 - acc: 0.7968 - val_loss: 0.5016 - val_acc: 0.7510\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.4195 - acc: 0.8177 - val_loss: 0.4997 - val_acc: 0.7620\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.4017 - acc: 0.8257 - val_loss: 0.5370 - val_acc: 0.7458\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.3825 - acc: 0.8375 - val_loss: 0.5089 - val_acc: 0.7717\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.3595 - acc: 0.8485 - val_loss: 0.5208 - val_acc: 0.7704\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.3396 - acc: 0.8576 - val_loss: 0.5326 - val_acc: 0.7633\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.3189 - acc: 0.8706 - val_loss: 0.5549 - val_acc: 0.7587\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.3042 - acc: 0.8779 - val_loss: 0.5702 - val_acc: 0.7626\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.2846 - acc: 0.8889 - val_loss: 0.5901 - val_acc: 0.7594\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.2758 - acc: 0.8921 - val_loss: 0.6155 - val_acc: 0.7613\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.2606 - acc: 0.9012 - val_loss: 0.6431 - val_acc: 0.7542\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.2468 - acc: 0.9083 - val_loss: 0.6513 - val_acc: 0.7529\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.2414 - acc: 0.9120 - val_loss: 0.6683 - val_acc: 0.7523\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.2201 - acc: 0.9230 - val_loss: 0.6869 - val_acc: 0.7432\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.2092 - acc: 0.9316 - val_loss: 0.7063 - val_acc: 0.7464\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.2020 - acc: 0.9301 - val_loss: 0.7314 - val_acc: 0.7439\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.2028 - acc: 0.9331 - val_loss: 0.7672 - val_acc: 0.7451\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.1957 - acc: 0.9355 - val_loss: 0.7605 - val_acc: 0.7374\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.1888 - acc: 0.9402 - val_loss: 0.7637 - val_acc: 0.7497\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.1771 - acc: 0.9452 - val_loss: 0.7735 - val_acc: 0.7451\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.1694 - acc: 0.9465 - val_loss: 0.7976 - val_acc: 0.7413\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1659 - acc: 0.9502Restoring model weights from the end of the best epoch: 12.\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.1659 - acc: 0.9502 - val_loss: 0.8031 - val_acc: 0.7316\n",
      "Epoch 00032: early stopping\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 3s 117ms/step - loss: 0.6852 - acc: 0.5933 - val_loss: 0.6685 - val_acc: 0.6229\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.6837 - acc: 0.5743 - val_loss: 0.6616 - val_acc: 0.6229\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.6763 - acc: 0.5961 - val_loss: 0.6612 - val_acc: 0.6229\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.6757 - acc: 0.5940 - val_loss: 0.6594 - val_acc: 0.6229\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.6707 - acc: 0.5991 - val_loss: 0.6541 - val_acc: 0.6229\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.6591 - acc: 0.6080 - val_loss: 0.6377 - val_acc: 0.6229\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.6353 - acc: 0.6276 - val_loss: 0.6051 - val_acc: 0.6740\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.5986 - acc: 0.6839 - val_loss: 0.5652 - val_acc: 0.7303\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.5501 - acc: 0.7269 - val_loss: 0.5262 - val_acc: 0.7477\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.5016 - acc: 0.7657 - val_loss: 0.5028 - val_acc: 0.7555\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.4632 - acc: 0.7905 - val_loss: 0.4954 - val_acc: 0.7568\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.4315 - acc: 0.8056 - val_loss: 0.4961 - val_acc: 0.7717\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.4081 - acc: 0.8179 - val_loss: 0.4980 - val_acc: 0.7736\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 103ms/step - loss: 0.3841 - acc: 0.8375 - val_loss: 0.5076 - val_acc: 0.7704\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.3670 - acc: 0.8468 - val_loss: 0.5177 - val_acc: 0.7658\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.3456 - acc: 0.8557 - val_loss: 0.5307 - val_acc: 0.7594\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.3377 - acc: 0.8557 - val_loss: 0.5400 - val_acc: 0.7516\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.3298 - acc: 0.8624 - val_loss: 0.5419 - val_acc: 0.7561\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.3061 - acc: 0.8766 - val_loss: 0.5594 - val_acc: 0.7510\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.2881 - acc: 0.8850 - val_loss: 0.5735 - val_acc: 0.7561\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.2757 - acc: 0.8919 - val_loss: 0.5896 - val_acc: 0.7471\n",
      "Epoch 22/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 62ms/step - loss: 0.2637 - acc: 0.8990 - val_loss: 0.6136 - val_acc: 0.7542\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.2523 - acc: 0.9053 - val_loss: 0.6322 - val_acc: 0.7426\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.2422 - acc: 0.9083 - val_loss: 0.6518 - val_acc: 0.7542\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.2280 - acc: 0.9141 - val_loss: 0.6526 - val_acc: 0.7503\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.2203 - acc: 0.9210 - val_loss: 0.7146 - val_acc: 0.7439\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.2088 - acc: 0.9266 - val_loss: 0.6897 - val_acc: 0.7439\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.1942 - acc: 0.9348 - val_loss: 0.7351 - val_acc: 0.7439\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.1952 - acc: 0.9316 - val_loss: 0.7377 - val_acc: 0.7309\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.1889 - acc: 0.9389 - val_loss: 0.7711 - val_acc: 0.7367\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1773 - acc: 0.9424Restoring model weights from the end of the best epoch: 11.\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.1773 - acc: 0.9424 - val_loss: 0.7472 - val_acc: 0.7400\n",
      "Epoch 00031: early stopping\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 4s 119ms/step - loss: 0.7605 - acc: 0.4574 - val_loss: 0.6764 - val_acc: 0.5899\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.6842 - acc: 0.6052 - val_loss: 0.6980 - val_acc: 0.5899\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.6837 - acc: 0.6039 - val_loss: 0.6800 - val_acc: 0.5899\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.6819 - acc: 0.5877 - val_loss: 0.6751 - val_acc: 0.5899\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.6750 - acc: 0.5991 - val_loss: 0.6753 - val_acc: 0.5899\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.6766 - acc: 0.6024 - val_loss: 0.6762 - val_acc: 0.5899\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.6727 - acc: 0.6063 - val_loss: 0.6728 - val_acc: 0.5899\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.6702 - acc: 0.6065 - val_loss: 0.6672 - val_acc: 0.5899\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.6616 - acc: 0.6151 - val_loss: 0.6573 - val_acc: 0.5899\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.6433 - acc: 0.6261 - val_loss: 0.6341 - val_acc: 0.5899\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.6111 - acc: 0.6645 - val_loss: 0.6101 - val_acc: 0.6682\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.5782 - acc: 0.6982 - val_loss: 0.5735 - val_acc: 0.7063\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.5309 - acc: 0.7545 - val_loss: 0.5362 - val_acc: 0.7464\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.4866 - acc: 0.7780 - val_loss: 0.5144 - val_acc: 0.7529\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.4473 - acc: 0.8047 - val_loss: 0.5086 - val_acc: 0.7633\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.4186 - acc: 0.8268 - val_loss: 0.5065 - val_acc: 0.7684\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.3885 - acc: 0.8403 - val_loss: 0.5030 - val_acc: 0.7678\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.3670 - acc: 0.8518 - val_loss: 0.5116 - val_acc: 0.7678\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.3418 - acc: 0.8639 - val_loss: 0.5382 - val_acc: 0.7607\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.3225 - acc: 0.8712 - val_loss: 0.5436 - val_acc: 0.7620\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.3046 - acc: 0.8867 - val_loss: 0.5635 - val_acc: 0.7536\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.2835 - acc: 0.8986 - val_loss: 0.5752 - val_acc: 0.7497\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 0.2708 - acc: 0.9040 - val_loss: 0.5990 - val_acc: 0.7574\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.2550 - acc: 0.9094 - val_loss: 0.6180 - val_acc: 0.7529\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.2415 - acc: 0.9154 - val_loss: 0.6378 - val_acc: 0.7510\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.2311 - acc: 0.9234 - val_loss: 0.6529 - val_acc: 0.7426\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.2167 - acc: 0.9316 - val_loss: 0.6717 - val_acc: 0.7426\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.2139 - acc: 0.9351 - val_loss: 0.6856 - val_acc: 0.7419\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.2011 - acc: 0.9383 - val_loss: 0.7073 - val_acc: 0.7419\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.1898 - acc: 0.9463 - val_loss: 0.7228 - val_acc: 0.7426\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.1905 - acc: 0.9422 - val_loss: 0.7441 - val_acc: 0.7426\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.1851 - acc: 0.9499 - val_loss: 0.7508 - val_acc: 0.7400\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.1772 - acc: 0.9521 - val_loss: 0.7551 - val_acc: 0.7406\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.1678 - acc: 0.9540 - val_loss: 0.7744 - val_acc: 0.7393\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.1707 - acc: 0.9538 - val_loss: 0.7821 - val_acc: 0.7367\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.1660 - acc: 0.9558 - val_loss: 0.7905 - val_acc: 0.7406\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1578 - acc: 0.9609Restoring model weights from the end of the best epoch: 17.\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.1578 - acc: 0.9609 - val_loss: 0.7912 - val_acc: 0.7400\n",
      "Epoch 00037: early stopping\n",
      "RNN 정확도 : 0.7620957309184994, Precision : 0.799709052709451, Recall : 0.8147245762711866, F1 : 0.8069187606276055, roc_auc : 0.7471463412917395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.7658473479948253,\n",
       "  0.7684346701164295,\n",
       "  0.7457956015523933,\n",
       "  0.759379042690815,\n",
       "  0.7613195342820182,\n",
       "  0.7632600258732212,\n",
       "  0.7736093143596378,\n",
       "  0.7580853816300129,\n",
       "  0.7645536869340233,\n",
       "  0.7606727037516171],\n",
       " [0.8037578288100209,\n",
       "  0.7971602434077079,\n",
       "  0.8092031425364759,\n",
       "  0.7985386221294363,\n",
       "  0.7985462097611631,\n",
       "  0.7955010224948875,\n",
       "  0.8146186440677966,\n",
       "  0.7956431535269709,\n",
       "  0.7826510721247564,\n",
       "  0.8014705882352942],\n",
       " [0.815677966101695,\n",
       "  0.8326271186440678,\n",
       "  0.763771186440678,\n",
       "  0.8103813559322034,\n",
       "  0.8146186440677966,\n",
       "  0.8241525423728814,\n",
       "  0.8146186440677966,\n",
       "  0.8125,\n",
       "  0.850635593220339,\n",
       "  0.8082627118644068],\n",
       " [0.8096740273396426,\n",
       "  0.8145077720207254,\n",
       "  0.7858310626702998,\n",
       "  0.804416403785489,\n",
       "  0.8065023597273203,\n",
       "  0.809573361082206,\n",
       "  0.8146186440677966,\n",
       "  0.8039832285115305,\n",
       "  0.8152284263959391,\n",
       "  0.8048523206751055],\n",
       " [0.7516928036488542,\n",
       "  0.7502006025114027,\n",
       "  0.7406895799313025,\n",
       "  0.7448916746438425,\n",
       "  0.7461797539275861,\n",
       "  0.7459633143758095,\n",
       "  0.761960484824596,\n",
       "  0.7426287375415282,\n",
       "  0.7401018497663158,\n",
       "  0.7471546117461568])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series_cv('RNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e5e69cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d062f7b79746494b8a172a985f222f06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_160 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_161 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_162 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_163 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 5s 193ms/step - loss: 0.7178 - acc: 0.4956 - val_loss: 0.6708 - val_acc: 0.6054\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.6834 - acc: 0.5987 - val_loss: 0.6777 - val_acc: 0.6054\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.6871 - acc: 0.6015 - val_loss: 0.6715 - val_acc: 0.6054\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6754 - acc: 0.6052 - val_loss: 0.6706 - val_acc: 0.6054\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.6753 - acc: 0.5916 - val_loss: 0.6702 - val_acc: 0.6054\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 0.6754 - acc: 0.5994 - val_loss: 0.6704 - val_acc: 0.6054\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.6759 - acc: 0.6024 - val_loss: 0.6697 - val_acc: 0.6054\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.6775 - acc: 0.5961 - val_loss: 0.6682 - val_acc: 0.6054\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 98ms/step - loss: 0.6720 - acc: 0.6082 - val_loss: 0.6662 - val_acc: 0.6054\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.6671 - acc: 0.6037 - val_loss: 0.6610 - val_acc: 0.6054\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 0.6604 - acc: 0.6132 - val_loss: 0.6484 - val_acc: 0.6054\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6385 - acc: 0.6272 - val_loss: 0.6233 - val_acc: 0.6054\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.5968 - acc: 0.6775 - val_loss: 0.5899 - val_acc: 0.7193\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.5456 - acc: 0.7426 - val_loss: 0.5604 - val_acc: 0.7193\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.4906 - acc: 0.7855 - val_loss: 0.5384 - val_acc: 0.7413\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.4471 - acc: 0.8112 - val_loss: 0.5374 - val_acc: 0.7529\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.4140 - acc: 0.8313 - val_loss: 0.5504 - val_acc: 0.7503\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.3837 - acc: 0.8481 - val_loss: 0.5612 - val_acc: 0.7523\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.3646 - acc: 0.8606 - val_loss: 0.5635 - val_acc: 0.7413\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.3436 - acc: 0.8703 - val_loss: 0.5980 - val_acc: 0.7484\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.3237 - acc: 0.8813 - val_loss: 0.5964 - val_acc: 0.7549\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.3079 - acc: 0.8880 - val_loss: 0.6318 - val_acc: 0.7432\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.2859 - acc: 0.8999 - val_loss: 0.6421 - val_acc: 0.7445\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.2764 - acc: 0.9087 - val_loss: 0.6430 - val_acc: 0.7464\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2542 - acc: 0.9184 - val_loss: 0.6658 - val_acc: 0.7484\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2397 - acc: 0.9238 - val_loss: 0.6817 - val_acc: 0.7426\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2308 - acc: 0.9307 - val_loss: 0.6996 - val_acc: 0.7510\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2173 - acc: 0.9361 - val_loss: 0.7162 - val_acc: 0.7413\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2097 - acc: 0.9396 - val_loss: 0.7317 - val_acc: 0.7426\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.1972 - acc: 0.9463 - val_loss: 0.7507 - val_acc: 0.7406\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.1916 - acc: 0.9504 - val_loss: 0.7647 - val_acc: 0.7393\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.1872 - acc: 0.9515 - val_loss: 0.7779 - val_acc: 0.7400\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.1864 - acc: 0.9506 - val_loss: 0.7774 - val_acc: 0.7439\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.1791 - acc: 0.9523 - val_loss: 0.7839 - val_acc: 0.7419\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.1721 - acc: 0.9581 - val_loss: 0.7895 - val_acc: 0.7406\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1635 - acc: 0.9605Restoring model weights from the end of the best epoch: 16.\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.1635 - acc: 0.9605 - val_loss: 0.8042 - val_acc: 0.7374\n",
      "Epoch 00036: early stopping\n",
      "WARNING:tensorflow:Layer gru_164 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_165 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_166 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_167 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 4s 159ms/step - loss: 0.7612 - acc: 0.4339 - val_loss: 0.6796 - val_acc: 0.6132\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6826 - acc: 0.5909 - val_loss: 0.6727 - val_acc: 0.6132\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6917 - acc: 0.5996 - val_loss: 0.6696 - val_acc: 0.6132\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.6818 - acc: 0.5970 - val_loss: 0.6675 - val_acc: 0.6132\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6822 - acc: 0.5858 - val_loss: 0.6677 - val_acc: 0.6132\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6801 - acc: 0.5886 - val_loss: 0.6668 - val_acc: 0.6132\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6765 - acc: 0.6017 - val_loss: 0.6665 - val_acc: 0.6132\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.6800 - acc: 0.5929 - val_loss: 0.6660 - val_acc: 0.6132\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 0.6754 - acc: 0.6011 - val_loss: 0.6654 - val_acc: 0.6132\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.6742 - acc: 0.5976 - val_loss: 0.6640 - val_acc: 0.6132\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6738 - acc: 0.5981 - val_loss: 0.6614 - val_acc: 0.6132\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6680 - acc: 0.6050 - val_loss: 0.6554 - val_acc: 0.6132\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6582 - acc: 0.6108 - val_loss: 0.6435 - val_acc: 0.6132\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6443 - acc: 0.6194 - val_loss: 0.6203 - val_acc: 0.6132\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6139 - acc: 0.6438 - val_loss: 0.5871 - val_acc: 0.6552\n",
      "Epoch 16/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 92ms/step - loss: 0.5686 - acc: 0.7027 - val_loss: 0.5460 - val_acc: 0.7490\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.5184 - acc: 0.7683 - val_loss: 0.5162 - val_acc: 0.7594\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.4718 - acc: 0.8071 - val_loss: 0.4965 - val_acc: 0.7755\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.4341 - acc: 0.8233 - val_loss: 0.4934 - val_acc: 0.7723\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.4070 - acc: 0.8399 - val_loss: 0.5002 - val_acc: 0.7827\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.3823 - acc: 0.8557 - val_loss: 0.5032 - val_acc: 0.7768\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.3636 - acc: 0.8628 - val_loss: 0.5208 - val_acc: 0.7710\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.3434 - acc: 0.8734 - val_loss: 0.5444 - val_acc: 0.7730\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.3305 - acc: 0.8835 - val_loss: 0.5411 - val_acc: 0.7710\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.3131 - acc: 0.8928 - val_loss: 0.5586 - val_acc: 0.7684\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2983 - acc: 0.9020 - val_loss: 0.5709 - val_acc: 0.7594\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.3006 - acc: 0.8992 - val_loss: 0.5843 - val_acc: 0.7633\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.2810 - acc: 0.9090 - val_loss: 0.5914 - val_acc: 0.7510\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2722 - acc: 0.9126 - val_loss: 0.6241 - val_acc: 0.7639\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2627 - acc: 0.9169 - val_loss: 0.6167 - val_acc: 0.7607\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 141ms/step - loss: 0.2490 - acc: 0.9238 - val_loss: 0.6304 - val_acc: 0.7542\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.2390 - acc: 0.9301 - val_loss: 0.6480 - val_acc: 0.7613\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.2327 - acc: 0.9338 - val_loss: 0.6651 - val_acc: 0.7477\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2284 - acc: 0.9355 - val_loss: 0.6713 - val_acc: 0.7529\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 1s 103ms/step - loss: 0.2203 - acc: 0.9385 - val_loss: 0.6859 - val_acc: 0.7626\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.2155 - acc: 0.9407 - val_loss: 0.6902 - val_acc: 0.7477\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.2074 - acc: 0.9454 - val_loss: 0.7016 - val_acc: 0.7561\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.2038 - acc: 0.9443 - val_loss: 0.7115 - val_acc: 0.7497\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2043 - acc: 0.9452Restoring model weights from the end of the best epoch: 19.\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.2043 - acc: 0.9452 - val_loss: 0.7164 - val_acc: 0.7600\n",
      "Epoch 00039: early stopping\n",
      "WARNING:tensorflow:Layer gru_168 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_169 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_170 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_171 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 5s 152ms/step - loss: 0.6854 - acc: 0.5851 - val_loss: 0.6687 - val_acc: 0.6171\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.6802 - acc: 0.5862 - val_loss: 0.6655 - val_acc: 0.6171\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6810 - acc: 0.5983 - val_loss: 0.6653 - val_acc: 0.6171\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6775 - acc: 0.5955 - val_loss: 0.6655 - val_acc: 0.6171\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6769 - acc: 0.6056 - val_loss: 0.6649 - val_acc: 0.6171\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6751 - acc: 0.6052 - val_loss: 0.6646 - val_acc: 0.6171\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6767 - acc: 0.5987 - val_loss: 0.6630 - val_acc: 0.6171\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.6709 - acc: 0.6069 - val_loss: 0.6583 - val_acc: 0.6171\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.6608 - acc: 0.6088 - val_loss: 0.6438 - val_acc: 0.6171\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6404 - acc: 0.6261 - val_loss: 0.6129 - val_acc: 0.6261\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6010 - acc: 0.6947 - val_loss: 0.5694 - val_acc: 0.7354\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.5544 - acc: 0.7402 - val_loss: 0.5222 - val_acc: 0.7594\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.4992 - acc: 0.7732 - val_loss: 0.4906 - val_acc: 0.7755\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.4646 - acc: 0.7909 - val_loss: 0.4824 - val_acc: 0.7743\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.4311 - acc: 0.8136 - val_loss: 0.4810 - val_acc: 0.7781\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.4096 - acc: 0.8205 - val_loss: 0.4932 - val_acc: 0.7639\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.3894 - acc: 0.8421 - val_loss: 0.4950 - val_acc: 0.7626\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 140ms/step - loss: 0.3751 - acc: 0.8455 - val_loss: 0.4969 - val_acc: 0.7794\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.3508 - acc: 0.8632 - val_loss: 0.5093 - val_acc: 0.7749\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 0.3362 - acc: 0.8682 - val_loss: 0.5247 - val_acc: 0.7710\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 97ms/step - loss: 0.3181 - acc: 0.8809 - val_loss: 0.5374 - val_acc: 0.7626\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.3041 - acc: 0.8869 - val_loss: 0.5534 - val_acc: 0.7549\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.2843 - acc: 0.8995 - val_loss: 0.5729 - val_acc: 0.7594\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.2726 - acc: 0.9057 - val_loss: 0.5959 - val_acc: 0.7490\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.2633 - acc: 0.9053 - val_loss: 0.6105 - val_acc: 0.7536\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2402 - acc: 0.9221 - val_loss: 0.6292 - val_acc: 0.7497\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2352 - acc: 0.9247 - val_loss: 0.6518 - val_acc: 0.7574\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.2274 - acc: 0.9297 - val_loss: 0.6815 - val_acc: 0.7620\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2183 - acc: 0.9305 - val_loss: 0.6774 - val_acc: 0.7464\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.2071 - acc: 0.9405 - val_loss: 0.6943 - val_acc: 0.7477\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.1966 - acc: 0.9458 - val_loss: 0.7177 - val_acc: 0.7529\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.1944 - acc: 0.9448 - val_loss: 0.7334 - val_acc: 0.7419\n",
      "Epoch 33/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 92ms/step - loss: 0.1902 - acc: 0.9463 - val_loss: 0.7608 - val_acc: 0.7574\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.1915 - acc: 0.9446 - val_loss: 0.7456 - val_acc: 0.7439\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1769 - acc: 0.9489Restoring model weights from the end of the best epoch: 15.\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.1769 - acc: 0.9489 - val_loss: 0.7476 - val_acc: 0.7542\n",
      "Epoch 00035: early stopping\n",
      "WARNING:tensorflow:Layer gru_172 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_173 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_174 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_175 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 5s 162ms/step - loss: 0.6856 - acc: 0.5758 - val_loss: 0.6623 - val_acc: 0.6274\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6822 - acc: 0.5944 - val_loss: 0.6608 - val_acc: 0.6274\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6811 - acc: 0.5894 - val_loss: 0.6622 - val_acc: 0.6274\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6767 - acc: 0.5942 - val_loss: 0.6607 - val_acc: 0.6274\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6767 - acc: 0.6004 - val_loss: 0.6601 - val_acc: 0.6274\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.6767 - acc: 0.5994 - val_loss: 0.6609 - val_acc: 0.6274\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6695 - acc: 0.6039 - val_loss: 0.6547 - val_acc: 0.6274\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.6640 - acc: 0.6052 - val_loss: 0.6428 - val_acc: 0.6274\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6393 - acc: 0.6164 - val_loss: 0.6138 - val_acc: 0.6274\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6013 - acc: 0.6893 - val_loss: 0.5788 - val_acc: 0.7186\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.5494 - acc: 0.7400 - val_loss: 0.5436 - val_acc: 0.7354\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.5000 - acc: 0.7728 - val_loss: 0.5192 - val_acc: 0.7484\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.4614 - acc: 0.7955 - val_loss: 0.5105 - val_acc: 0.7516\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.4256 - acc: 0.8117 - val_loss: 0.5016 - val_acc: 0.7671\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.3981 - acc: 0.8268 - val_loss: 0.4982 - val_acc: 0.7749\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.3725 - acc: 0.8444 - val_loss: 0.5158 - val_acc: 0.7730\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.3535 - acc: 0.8576 - val_loss: 0.5288 - val_acc: 0.7671\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.3301 - acc: 0.8662 - val_loss: 0.5456 - val_acc: 0.7691\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.3142 - acc: 0.8775 - val_loss: 0.5725 - val_acc: 0.7678\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2964 - acc: 0.8861 - val_loss: 0.5895 - val_acc: 0.7639\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2747 - acc: 0.8982 - val_loss: 0.6172 - val_acc: 0.7620\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2591 - acc: 0.9044 - val_loss: 0.6441 - val_acc: 0.7607\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.2427 - acc: 0.9182 - val_loss: 0.6690 - val_acc: 0.7477\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2300 - acc: 0.9204 - val_loss: 0.6966 - val_acc: 0.7516\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2270 - acc: 0.9241 - val_loss: 0.7106 - val_acc: 0.7361\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2081 - acc: 0.9305 - val_loss: 0.7263 - val_acc: 0.7374\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.1938 - acc: 0.9402 - val_loss: 0.7403 - val_acc: 0.7458\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.1826 - acc: 0.9446 - val_loss: 0.7739 - val_acc: 0.7464\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.1759 - acc: 0.9482 - val_loss: 0.8057 - val_acc: 0.7393\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.1684 - acc: 0.9508 - val_loss: 0.8019 - val_acc: 0.7426\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.1593 - acc: 0.9558 - val_loss: 0.8273 - val_acc: 0.7342\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.1519 - acc: 0.9586 - val_loss: 0.8379 - val_acc: 0.7451\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 1s 139ms/step - loss: 0.1481 - acc: 0.9597 - val_loss: 0.8598 - val_acc: 0.7283\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.1574 - acc: 0.9543 - val_loss: 0.8583 - val_acc: 0.7374\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1396 - acc: 0.9609Restoring model weights from the end of the best epoch: 15.\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.1396 - acc: 0.9609 - val_loss: 0.8645 - val_acc: 0.7367\n",
      "Epoch 00035: early stopping\n",
      "WARNING:tensorflow:Layer gru_176 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_177 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_178 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_179 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 4s 159ms/step - loss: 0.7164 - acc: 0.4971 - val_loss: 0.6838 - val_acc: 0.5796\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6912 - acc: 0.6114 - val_loss: 0.7058 - val_acc: 0.5796\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6787 - acc: 0.6138 - val_loss: 0.6845 - val_acc: 0.5796\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6766 - acc: 0.5972 - val_loss: 0.6806 - val_acc: 0.5796\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6723 - acc: 0.6026 - val_loss: 0.6828 - val_acc: 0.5796\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6773 - acc: 0.6076 - val_loss: 0.6847 - val_acc: 0.5796\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6816 - acc: 0.6022 - val_loss: 0.6850 - val_acc: 0.5796\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6769 - acc: 0.6024 - val_loss: 0.6817 - val_acc: 0.5796\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6759 - acc: 0.6052 - val_loss: 0.6808 - val_acc: 0.5796\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6680 - acc: 0.6123 - val_loss: 0.6786 - val_acc: 0.5796\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 103ms/step - loss: 0.6649 - acc: 0.6123 - val_loss: 0.6718 - val_acc: 0.5796\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6531 - acc: 0.6239 - val_loss: 0.6574 - val_acc: 0.5796\n",
      "Epoch 13/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6294 - acc: 0.6365 - val_loss: 0.6233 - val_acc: 0.5796\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.5894 - acc: 0.6721 - val_loss: 0.5845 - val_acc: 0.7367\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.5377 - acc: 0.7417 - val_loss: 0.5482 - val_acc: 0.7497\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.4917 - acc: 0.7823 - val_loss: 0.5252 - val_acc: 0.7594\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.4498 - acc: 0.8091 - val_loss: 0.5477 - val_acc: 0.7464\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.4211 - acc: 0.8263 - val_loss: 0.5376 - val_acc: 0.7561\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.3963 - acc: 0.8395 - val_loss: 0.5286 - val_acc: 0.7652\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.3716 - acc: 0.8559 - val_loss: 0.5315 - val_acc: 0.7684\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.3506 - acc: 0.8675 - val_loss: 0.5465 - val_acc: 0.7646\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.3307 - acc: 0.8762 - val_loss: 0.5549 - val_acc: 0.7620\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 0.3112 - acc: 0.8880 - val_loss: 0.5888 - val_acc: 0.7594\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.3015 - acc: 0.8954 - val_loss: 0.5924 - val_acc: 0.7471\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2902 - acc: 0.8949 - val_loss: 0.5941 - val_acc: 0.7574\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2712 - acc: 0.9072 - val_loss: 0.6413 - val_acc: 0.7484\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2563 - acc: 0.9159 - val_loss: 0.6456 - val_acc: 0.7477\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2425 - acc: 0.9236 - val_loss: 0.6591 - val_acc: 0.7497\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2272 - acc: 0.9282 - val_loss: 0.6822 - val_acc: 0.7451\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2181 - acc: 0.9351 - val_loss: 0.6899 - val_acc: 0.7451\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2088 - acc: 0.9396 - val_loss: 0.7259 - val_acc: 0.7445\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2030 - acc: 0.9435 - val_loss: 0.7289 - val_acc: 0.7464\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.1907 - acc: 0.9480 - val_loss: 0.7355 - val_acc: 0.7439\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.1817 - acc: 0.9512 - val_loss: 0.7640 - val_acc: 0.7400\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.1803 - acc: 0.9540 - val_loss: 0.7583 - val_acc: 0.7471\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1783 - acc: 0.9534Restoring model weights from the end of the best epoch: 16.\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.1783 - acc: 0.9534 - val_loss: 0.8090 - val_acc: 0.7354\n",
      "Epoch 00036: early stopping\n",
      "WARNING:tensorflow:Layer gru_180 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_181 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_182 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_183 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 5s 154ms/step - loss: 0.7761 - acc: 0.4334 - val_loss: 0.6809 - val_acc: 0.5957\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6868 - acc: 0.5879 - val_loss: 0.6907 - val_acc: 0.5957\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.6892 - acc: 0.6080 - val_loss: 0.6808 - val_acc: 0.5957\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6835 - acc: 0.5957 - val_loss: 0.6742 - val_acc: 0.5957\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6833 - acc: 0.5773 - val_loss: 0.6739 - val_acc: 0.5957\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6824 - acc: 0.5823 - val_loss: 0.6745 - val_acc: 0.5957\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.6795 - acc: 0.5981 - val_loss: 0.6744 - val_acc: 0.5957\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6733 - acc: 0.6006 - val_loss: 0.6736 - val_acc: 0.5957\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6712 - acc: 0.5974 - val_loss: 0.6712 - val_acc: 0.5957\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6695 - acc: 0.6032 - val_loss: 0.6697 - val_acc: 0.5957\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6658 - acc: 0.6119 - val_loss: 0.6641 - val_acc: 0.5957\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.6556 - acc: 0.6145 - val_loss: 0.6547 - val_acc: 0.5957\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.6451 - acc: 0.6261 - val_loss: 0.6360 - val_acc: 0.5957\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6136 - acc: 0.6546 - val_loss: 0.6051 - val_acc: 0.6442\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.5780 - acc: 0.6980 - val_loss: 0.5732 - val_acc: 0.7348\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 0.5325 - acc: 0.7502 - val_loss: 0.5438 - val_acc: 0.7406\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.4877 - acc: 0.7894 - val_loss: 0.5278 - val_acc: 0.7458\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.4470 - acc: 0.8168 - val_loss: 0.5188 - val_acc: 0.7529\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.4126 - acc: 0.8378 - val_loss: 0.5352 - val_acc: 0.7568\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.3831 - acc: 0.8496 - val_loss: 0.5328 - val_acc: 0.7510\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.3634 - acc: 0.8630 - val_loss: 0.5432 - val_acc: 0.7542\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.3565 - acc: 0.8645 - val_loss: 0.5703 - val_acc: 0.7626\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.3378 - acc: 0.8753 - val_loss: 0.5577 - val_acc: 0.7561\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.3117 - acc: 0.8906 - val_loss: 0.5713 - val_acc: 0.7523\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.2957 - acc: 0.8990 - val_loss: 0.6058 - val_acc: 0.7419\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.2879 - acc: 0.9044 - val_loss: 0.6083 - val_acc: 0.7497\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.2733 - acc: 0.9148 - val_loss: 0.6187 - val_acc: 0.7451\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2564 - acc: 0.9230 - val_loss: 0.6412 - val_acc: 0.7406\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2490 - acc: 0.9249 - val_loss: 0.6504 - val_acc: 0.7484\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2362 - acc: 0.9314 - val_loss: 0.6610 - val_acc: 0.7477\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2338 - acc: 0.9346 - val_loss: 0.6738 - val_acc: 0.7510\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.2276 - acc: 0.9342 - val_loss: 0.6825 - val_acc: 0.7484\n",
      "Epoch 33/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2221 - acc: 0.9376 - val_loss: 0.6903 - val_acc: 0.7445\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.2166 - acc: 0.9394 - val_loss: 0.7044 - val_acc: 0.7445\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2059 - acc: 0.9448 - val_loss: 0.7103 - val_acc: 0.7413\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.1959 - acc: 0.9497 - val_loss: 0.7307 - val_acc: 0.7400\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.1910 - acc: 0.9504 - val_loss: 0.7390 - val_acc: 0.7445\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1921 - acc: 0.9532Restoring model weights from the end of the best epoch: 18.\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.1921 - acc: 0.9532 - val_loss: 0.7541 - val_acc: 0.7413\n",
      "Epoch 00038: early stopping\n",
      "WARNING:tensorflow:Layer gru_184 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_185 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_186 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_187 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 5s 158ms/step - loss: 0.6799 - acc: 0.6035 - val_loss: 0.6747 - val_acc: 0.5964\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6770 - acc: 0.5918 - val_loss: 0.6751 - val_acc: 0.5964\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6761 - acc: 0.6082 - val_loss: 0.6754 - val_acc: 0.5964\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6732 - acc: 0.6043 - val_loss: 0.6748 - val_acc: 0.5964\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6706 - acc: 0.6106 - val_loss: 0.6742 - val_acc: 0.5964\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.6687 - acc: 0.6136 - val_loss: 0.6739 - val_acc: 0.5964\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6658 - acc: 0.6160 - val_loss: 0.6697 - val_acc: 0.5964\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6622 - acc: 0.6155 - val_loss: 0.6604 - val_acc: 0.5964\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.6445 - acc: 0.6239 - val_loss: 0.6304 - val_acc: 0.5964\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6017 - acc: 0.6833 - val_loss: 0.5882 - val_acc: 0.7141\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.5497 - acc: 0.7340 - val_loss: 0.5459 - val_acc: 0.7361\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.4984 - acc: 0.7743 - val_loss: 0.5180 - val_acc: 0.7516\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.4641 - acc: 0.7927 - val_loss: 0.5216 - val_acc: 0.7471\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.4380 - acc: 0.8030 - val_loss: 0.5371 - val_acc: 0.7484\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.4164 - acc: 0.8205 - val_loss: 0.5124 - val_acc: 0.7555\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.3930 - acc: 0.8334 - val_loss: 0.4978 - val_acc: 0.7639\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.3692 - acc: 0.8479 - val_loss: 0.5083 - val_acc: 0.7639\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.3493 - acc: 0.8546 - val_loss: 0.5231 - val_acc: 0.7620\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.3350 - acc: 0.8673 - val_loss: 0.5485 - val_acc: 0.7639\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.3135 - acc: 0.8796 - val_loss: 0.5556 - val_acc: 0.7607\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2993 - acc: 0.8861 - val_loss: 0.5657 - val_acc: 0.7626\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2732 - acc: 0.9016 - val_loss: 0.5879 - val_acc: 0.7639\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.2571 - acc: 0.9105 - val_loss: 0.6104 - val_acc: 0.7600\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2419 - acc: 0.9187 - val_loss: 0.6386 - val_acc: 0.7613\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2327 - acc: 0.9264 - val_loss: 0.6596 - val_acc: 0.7561\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2229 - acc: 0.9292 - val_loss: 0.6946 - val_acc: 0.7568\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2188 - acc: 0.9288 - val_loss: 0.6915 - val_acc: 0.7497\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.2105 - acc: 0.9284 - val_loss: 0.7108 - val_acc: 0.7477\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.1941 - acc: 0.9422 - val_loss: 0.7190 - val_acc: 0.7451\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 0.1857 - acc: 0.9443 - val_loss: 0.7514 - val_acc: 0.7516\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.1778 - acc: 0.9456 - val_loss: 0.7687 - val_acc: 0.7426\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.1807 - acc: 0.9448 - val_loss: 0.7821 - val_acc: 0.7497\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.1677 - acc: 0.9528 - val_loss: 0.7795 - val_acc: 0.7387\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.1574 - acc: 0.9577 - val_loss: 0.7931 - val_acc: 0.7413\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.1496 - acc: 0.9603 - val_loss: 0.8218 - val_acc: 0.7445\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1586 - acc: 0.9571Restoring model weights from the end of the best epoch: 16.\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.1586 - acc: 0.9571 - val_loss: 0.8242 - val_acc: 0.7387\n",
      "Epoch 00036: early stopping\n",
      "WARNING:tensorflow:Layer gru_188 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_189 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_190 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_191 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 5s 163ms/step - loss: 0.7205 - acc: 0.4848 - val_loss: 0.6717 - val_acc: 0.6138\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6829 - acc: 0.5890 - val_loss: 0.6712 - val_acc: 0.6138\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.6860 - acc: 0.6028 - val_loss: 0.6676 - val_acc: 0.6138\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.6821 - acc: 0.5978 - val_loss: 0.6671 - val_acc: 0.6138\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.6783 - acc: 0.5907 - val_loss: 0.6670 - val_acc: 0.6138\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.6785 - acc: 0.5929 - val_loss: 0.6662 - val_acc: 0.6138\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6714 - acc: 0.6047 - val_loss: 0.6657 - val_acc: 0.6138\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6772 - acc: 0.6019 - val_loss: 0.6647 - val_acc: 0.6138\n",
      "Epoch 9/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 95ms/step - loss: 0.6730 - acc: 0.6082 - val_loss: 0.6631 - val_acc: 0.6138\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.6707 - acc: 0.6076 - val_loss: 0.6598 - val_acc: 0.6138\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6651 - acc: 0.6026 - val_loss: 0.6525 - val_acc: 0.6138\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.6561 - acc: 0.6138 - val_loss: 0.6370 - val_acc: 0.6138\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.6328 - acc: 0.6289 - val_loss: 0.6081 - val_acc: 0.6158\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.5931 - acc: 0.6803 - val_loss: 0.5758 - val_acc: 0.7122\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.5430 - acc: 0.7480 - val_loss: 0.5421 - val_acc: 0.7342\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.4941 - acc: 0.7858 - val_loss: 0.5282 - val_acc: 0.7503\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.4540 - acc: 0.8082 - val_loss: 0.5140 - val_acc: 0.7510\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.4279 - acc: 0.8209 - val_loss: 0.5208 - val_acc: 0.7536\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.4018 - acc: 0.8328 - val_loss: 0.5183 - val_acc: 0.7626\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.3748 - acc: 0.8518 - val_loss: 0.5206 - val_acc: 0.7704\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.3558 - acc: 0.8598 - val_loss: 0.5312 - val_acc: 0.7678\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.3377 - acc: 0.8682 - val_loss: 0.5532 - val_acc: 0.7639\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.3225 - acc: 0.8790 - val_loss: 0.5576 - val_acc: 0.7607\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.2999 - acc: 0.8917 - val_loss: 0.5796 - val_acc: 0.7536\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2830 - acc: 0.8986 - val_loss: 0.5921 - val_acc: 0.7594\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2693 - acc: 0.9072 - val_loss: 0.6192 - val_acc: 0.7451\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2511 - acc: 0.9184 - val_loss: 0.6402 - val_acc: 0.7568\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2415 - acc: 0.9243 - val_loss: 0.6485 - val_acc: 0.7464\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2307 - acc: 0.9310 - val_loss: 0.6658 - val_acc: 0.7432\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2233 - acc: 0.9331 - val_loss: 0.6806 - val_acc: 0.7490\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.2040 - acc: 0.9435 - val_loss: 0.6999 - val_acc: 0.7484\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.1958 - acc: 0.9469 - val_loss: 0.7154 - val_acc: 0.7497\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.1914 - acc: 0.9495 - val_loss: 0.7390 - val_acc: 0.7523\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.1850 - acc: 0.9499 - val_loss: 0.7502 - val_acc: 0.7406\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.1792 - acc: 0.9551 - val_loss: 0.7639 - val_acc: 0.7445\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.1741 - acc: 0.9553 - val_loss: 0.7735 - val_acc: 0.7400\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1780 - acc: 0.9547Restoring model weights from the end of the best epoch: 17.\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.1780 - acc: 0.9547 - val_loss: 0.7847 - val_acc: 0.7516\n",
      "Epoch 00037: early stopping\n",
      "WARNING:tensorflow:Layer gru_192 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_193 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_194 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_195 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 5s 179ms/step - loss: 0.7207 - acc: 0.4971 - val_loss: 0.6630 - val_acc: 0.6229\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6869 - acc: 0.5940 - val_loss: 0.6655 - val_acc: 0.6229\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6870 - acc: 0.5918 - val_loss: 0.6627 - val_acc: 0.6229\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.6937 - acc: 0.5683 - val_loss: 0.6645 - val_acc: 0.6229\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.6834 - acc: 0.5761 - val_loss: 0.6625 - val_acc: 0.6229\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.6846 - acc: 0.5903 - val_loss: 0.6617 - val_acc: 0.6229\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.6811 - acc: 0.5862 - val_loss: 0.6616 - val_acc: 0.6229\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.6760 - acc: 0.5991 - val_loss: 0.6601 - val_acc: 0.6229\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6755 - acc: 0.5959 - val_loss: 0.6577 - val_acc: 0.6229\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 97ms/step - loss: 0.6749 - acc: 0.5976 - val_loss: 0.6533 - val_acc: 0.6229\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.6653 - acc: 0.6047 - val_loss: 0.6426 - val_acc: 0.6229\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6466 - acc: 0.6239 - val_loss: 0.6221 - val_acc: 0.6235\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.6144 - acc: 0.6630 - val_loss: 0.5816 - val_acc: 0.7063\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.5657 - acc: 0.7169 - val_loss: 0.5423 - val_acc: 0.7413\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.5188 - acc: 0.7607 - val_loss: 0.5405 - val_acc: 0.7413\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.4817 - acc: 0.7903 - val_loss: 0.5182 - val_acc: 0.7516\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.4451 - acc: 0.8086 - val_loss: 0.5146 - val_acc: 0.7549\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.4160 - acc: 0.8203 - val_loss: 0.5046 - val_acc: 0.7697\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.3874 - acc: 0.8423 - val_loss: 0.5159 - val_acc: 0.7684\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.3744 - acc: 0.8451 - val_loss: 0.5253 - val_acc: 0.7658\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.3491 - acc: 0.8611 - val_loss: 0.5300 - val_acc: 0.7684\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.3306 - acc: 0.8714 - val_loss: 0.5406 - val_acc: 0.7613\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.3126 - acc: 0.8846 - val_loss: 0.5551 - val_acc: 0.7671\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.2964 - acc: 0.8913 - val_loss: 0.5749 - val_acc: 0.7633\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2774 - acc: 0.9012 - val_loss: 0.5952 - val_acc: 0.7587\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.2568 - acc: 0.9092 - val_loss: 0.6108 - val_acc: 0.7542\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2500 - acc: 0.9143 - val_loss: 0.6260 - val_acc: 0.7568\n",
      "Epoch 28/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2421 - acc: 0.9195 - val_loss: 0.6670 - val_acc: 0.7458\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2353 - acc: 0.9213 - val_loss: 0.6390 - val_acc: 0.7587\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.2099 - acc: 0.9355 - val_loss: 0.6583 - val_acc: 0.7549\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.1978 - acc: 0.9417 - val_loss: 0.6782 - val_acc: 0.7594\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.1844 - acc: 0.9467 - val_loss: 0.7038 - val_acc: 0.7555\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.1732 - acc: 0.9525 - val_loss: 0.7286 - val_acc: 0.7484\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.1753 - acc: 0.9489 - val_loss: 0.7534 - val_acc: 0.7490\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.1652 - acc: 0.9538 - val_loss: 0.7551 - val_acc: 0.7451\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 1s 138ms/step - loss: 0.1618 - acc: 0.9569 - val_loss: 0.7656 - val_acc: 0.7477\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.1482 - acc: 0.9618 - val_loss: 0.7775 - val_acc: 0.7471\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1451 - acc: 0.9640Restoring model weights from the end of the best epoch: 18.\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 0.1451 - acc: 0.9640 - val_loss: 0.7965 - val_acc: 0.7432\n",
      "Epoch 00038: early stopping\n",
      "WARNING:tensorflow:Layer gru_196 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_197 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_198 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_199 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 4s 160ms/step - loss: 0.6777 - acc: 0.6006 - val_loss: 0.6792 - val_acc: 0.5899\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.6758 - acc: 0.6017 - val_loss: 0.6777 - val_acc: 0.5899\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6763 - acc: 0.6058 - val_loss: 0.6790 - val_acc: 0.5899\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.6761 - acc: 0.6138 - val_loss: 0.6783 - val_acc: 0.5899\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6711 - acc: 0.6099 - val_loss: 0.6774 - val_acc: 0.5899\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.6683 - acc: 0.6132 - val_loss: 0.6763 - val_acc: 0.5899\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 101ms/step - loss: 0.6680 - acc: 0.6157 - val_loss: 0.6729 - val_acc: 0.5899\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6598 - acc: 0.6153 - val_loss: 0.6616 - val_acc: 0.5899\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6405 - acc: 0.6302 - val_loss: 0.6409 - val_acc: 0.5899\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.6081 - acc: 0.6632 - val_loss: 0.5944 - val_acc: 0.7005\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.5619 - acc: 0.7191 - val_loss: 0.5602 - val_acc: 0.7206\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.5166 - acc: 0.7588 - val_loss: 0.5285 - val_acc: 0.7426\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.4783 - acc: 0.7858 - val_loss: 0.5110 - val_acc: 0.7523\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.4463 - acc: 0.8043 - val_loss: 0.5027 - val_acc: 0.7555\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.4170 - acc: 0.8216 - val_loss: 0.5009 - val_acc: 0.7665\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.3907 - acc: 0.8345 - val_loss: 0.5069 - val_acc: 0.7600\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.3748 - acc: 0.8406 - val_loss: 0.5094 - val_acc: 0.7665\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.3618 - acc: 0.8494 - val_loss: 0.5211 - val_acc: 0.7646\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 0.3345 - acc: 0.8630 - val_loss: 0.5264 - val_acc: 0.7665\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.3169 - acc: 0.8809 - val_loss: 0.5433 - val_acc: 0.7633\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.2996 - acc: 0.8910 - val_loss: 0.5741 - val_acc: 0.7652\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.2857 - acc: 0.8932 - val_loss: 0.5738 - val_acc: 0.7587\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2727 - acc: 0.9029 - val_loss: 0.5915 - val_acc: 0.7542\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 139ms/step - loss: 0.2561 - acc: 0.9113 - val_loss: 0.6222 - val_acc: 0.7529\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2402 - acc: 0.9189 - val_loss: 0.6385 - val_acc: 0.7484\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.2229 - acc: 0.9260 - val_loss: 0.6555 - val_acc: 0.7477\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.2143 - acc: 0.9314 - val_loss: 0.6985 - val_acc: 0.7510\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.2031 - acc: 0.9361 - val_loss: 0.6909 - val_acc: 0.7529\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.2013 - acc: 0.9405 - val_loss: 0.7142 - val_acc: 0.7516\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.1939 - acc: 0.9424 - val_loss: 0.7376 - val_acc: 0.7464\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.1778 - acc: 0.9476 - val_loss: 0.7358 - val_acc: 0.7497\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.1720 - acc: 0.9547 - val_loss: 0.7484 - val_acc: 0.7471\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.1645 - acc: 0.9553 - val_loss: 0.8159 - val_acc: 0.7400\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.1664 - acc: 0.9536 - val_loss: 0.7656 - val_acc: 0.7458\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1641 - acc: 0.9532Restoring model weights from the end of the best epoch: 15.\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.1641 - acc: 0.9532 - val_loss: 0.8137 - val_acc: 0.7400\n",
      "Epoch 00035: early stopping\n",
      "GRU 정확도 : 0.7614489003880982, Precision : 0.806011170731144, Recall : 0.8039194915254237, F1 : 0.8043606389627478, roc_auc : 0.749384994932147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.7690815006468306,\n",
       "  0.7652005174644243,\n",
       "  0.7393272962483829,\n",
       "  0.7626131953428201,\n",
       "  0.7613195342820182,\n",
       "  0.776843467011643,\n",
       "  0.7742561448900388,\n",
       "  0.7419146183699871,\n",
       "  0.7703751617076326,\n",
       "  0.7535575679172057],\n",
       " [0.8112407211028632,\n",
       "  0.8202866593164277,\n",
       "  0.8091428571428572,\n",
       "  0.8105489773950484,\n",
       "  0.8061767838125665,\n",
       "  0.826608505997819,\n",
       "  0.804503582395087,\n",
       "  0.7563499529633114,\n",
       "  0.7971745711402624,\n",
       "  0.8180790960451978],\n",
       " [0.8103813559322034,\n",
       "  0.788135593220339,\n",
       "  0.75,\n",
       "  0.7976694915254238,\n",
       "  0.801906779661017,\n",
       "  0.8029661016949152,\n",
       "  0.8326271186440678,\n",
       "  0.8516949152542372,\n",
       "  0.836864406779661,\n",
       "  0.7669491525423728],\n",
       " [0.8108108108108107,\n",
       "  0.8038897893030795,\n",
       "  0.7784496976360638,\n",
       "  0.8040576615056061,\n",
       "  0.8040361125862985,\n",
       "  0.814615797958087,\n",
       "  0.8183237896928683,\n",
       "  0.8011958146487295,\n",
       "  0.8165374677002585,\n",
       "  0.7916894477856752],\n",
       " [0.7573501464046398,\n",
       "  0.7586857368095051,\n",
       "  0.7362956810631229,\n",
       "  0.7526553437693564,\n",
       "  0.7497905991328341,\n",
       "  0.7694232501830057,\n",
       "  0.7576756855678811,\n",
       "  0.7107311785573512,\n",
       "  0.751488681795146,\n",
       "  0.7497536460386283])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series_cv('GRU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a014d72",
   "metadata": {},
   "source": [
    "**patience=10, batch_size=516**\n",
    "- LSTM 정확도 : 0.7597671410090556, Precision : 0.8039505041180386, Recall : 0.8041313559322033, F1 : 0.8033880012512284, roc_auc : 0.7471653457401881\n",
    "- RNN 정확도 : 0.7627425614489003, Precision : 0.7991156217390653, Recall : 0.8175847457627119, F1 : 0.808028390346027, roc_auc : 0.7471644659046118\n",
    "- GRU 정확도 : 0.7630659767141009, Precision : 0.8091566493100693, Recall : 0.8014830508474576, F1 : 0.8048401379533783, roc_auc : 0.7521534855566192\n",
    "\n",
    "**patience=10, batch_size=128**\n",
    "- LSTM 정확도 : 0.7661707632600259, Precision : 0.8200091195069449, Recall : 0.7926906779661016, F1 : 0.8050001158256013, roc_auc : 0.7586376977870375\n",
    "- RNN 정확도 : 0.7650711513583441, Precision : 0.7975570379008297, Recall : 0.8270127118644067, F1 : 0.8109664051812471, roc_auc : 0.7474764555999774\n",
    "- GRU 정확도 : 0.76248382923674, Precision : 0.8119860136029988, Recall : 0.798093220338983, F1 : 0.8037714629552601, roc_auc : 0.7523688693057042\n",
    "\n",
    "**patience=20, batch_size=516**\n",
    "- LSTM 정확도 : 0.7602846054333764, Precision : 0.8120813913825744, Recall : 0.7917372881355933, F1 : 0.801066945397603, roc_auc : 0.7513503716425474\n",
    "- RNN 정확도 : 0.7620957309184994, Precision : 0.799709052709451, Recall : 0.8147245762711866, F1 : 0.8069187606276055, roc_auc : 0.7471463412917395\n",
    "- GRU 정확도 : 0.7614489003880982, Precision : 0.806011170731144, Recall : 0.8039194915254237, F1 : 0.8043606389627478, roc_auc : 0.749384994932147\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffad5392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d7730a2",
   "metadata": {},
   "source": [
    "# 비시계열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55bee6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_time_series_cv(name, model):\n",
    "    path = '/project/LSH/'\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        # 1. Data load\n",
    "        x = np.load(path + 'x_(7727,4068).npy')\n",
    "        y = np.load(path + 'y_(7727,1).npy')\n",
    "\n",
    "        # 3-1. Best model saving\n",
    "        MODEL_SAVE_FOLDER_PATH = './models/'\n",
    "        if not os.path.exists(MODEL_SAVE_FOLDER_PATH):\n",
    "            os.mkdir(MODEL_SAVE_FOLDER_PATH)\n",
    "\n",
    "        sss = StratifiedShuffleSplit(n_splits=10, test_size = 0.2, random_state = 42)\n",
    "        acc_list, precision_list, recall_list, f1_list, auc_list = [], [], [], [], []\n",
    "\n",
    "        # 4. Crossvalidation\n",
    "        for seed, (train_index, test_index) in tqdm(enumerate(sss.split(x, y))):\n",
    "            X_train, y_train = x[train_index,:], y[train_index]\n",
    "            X_test, y_test = x[test_index,:], y[test_index]\n",
    "            \n",
    "            model.fit(X_train, y_train)\n",
    "            pred = model.predict(X_test)\n",
    "            \n",
    "            precision = precision_score(y_test, pred)\n",
    "            recall = recall_score(y_test, pred)\n",
    "            f1 = f1_score(y_test, pred)\n",
    "            roc_auc = roc_auc_score(y_test, pred)\n",
    "            acc = accuracy_score(y_test, pred)\n",
    "            \n",
    "            acc_list.append(acc)\n",
    "            precision_list.append(precision)\n",
    "            recall_list.append(recall)\n",
    "            f1_list.append(f1)\n",
    "            auc_list.append(roc_auc)\n",
    "#             print(acc, precision, recall, f1, roc_auc)\n",
    "        print(f'{name} 정확도 : {np.mean(acc_list)}, Precision : {np.mean(precision_list)}, Recall : {np.mean(recall_list)}, F1 : {np.mean(f1_list)}, roc_auc : {np.mean(auc_list)}')\n",
    "        return [np.mean(acc_list), np.mean(precision_list), np.mean(recall_list), np.mean(f1_list), np.mean(auc_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811d63fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "282fe189",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c466ee31333544dc8c2ff77e732727a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.7714100905562742, Precision : 0.7880143713559553, Recall : 0.8560381355932203,                       F1 : 0.8205702274167062, roc_auc : 0.7473712272650487\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ba815f86e574dc59bd9b9e70829d6a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.48363518758085383, Precision : 0.763051849775897, Recall : 0.22415254237288135,                       F1 : 0.3461551606026837, roc_auc : 0.5573420519173378\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b1d87d36794da19a73e52940d6226a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.6774902975420438, Precision : 0.7486133177745142, Recall : 0.7103813559322034,                       F1 : 0.7289560231165056, roc_auc : 0.6681474885973309\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5ed184996fe4aee9f59fa735f658ca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.6817593790426908, Precision : 0.7683619640774133, Recall : 0.6855932203389831,                       F1 : 0.7245214670053552, roc_auc : 0.6806703643223154\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed995ec9df8746f891db5c63552f5534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.6590556274256145, Precision : 0.6645527630949094, Recall : 0.8919491525423728,                       F1 : 0.7615933484387356, roc_auc : 0.5929014865701898\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15eeca8534594acf8c7875c1445ffc83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.7470892626131953, Precision : 0.7495428648404614, Recall : 0.8798728813559322,                       F1 : 0.80947489699985, roc_auc : 0.70937165662481\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "713853af4eb1483d925429e625a2e31b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.7487710219922381, Precision : 0.7621837385223997, Recall : 0.8556144067796609,                       F1 : 0.8061432712320394, roc_auc : 0.7184218213300297\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b993b63244a4d63a2322d78ade9a416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.7335705045278137, Precision : 0.7803205079860873, Recall : 0.7847457627118645,                       F1 : 0.7824320472113311, roc_auc : 0.7190340109240385\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ccdfe30a88741ab89c2c97c066f220d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.7324062095730919, Precision : 0.7805731264861739, Recall : 0.7817796610169492,                       F1 : 0.7810421937229945, roc_auc : 0.718381524860634\n",
      "CPU times: user 9h 47min 9s, sys: 9h 16min 26s, total: 19h 3min 35s\n",
      "Wall time: 36min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "result = []\n",
    "\n",
    "# Support vector machine\n",
    "model = SVC()\n",
    "temp = non_time_series_cv(model)\n",
    "result.append({'model' : str(model), 'acc' : temp[0], 'precision' : temp[1],\n",
    "               'recall' : temp[2], 'f1' : temp[3], 'roc_auc' : temp[4]})\n",
    "\n",
    "# Gaussian naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "temp = non_time_series_cv(model)\n",
    "result.append({'model' : str(model), 'acc' : temp[0], 'precision' : temp[1],\n",
    "               'recall' : temp[2], 'f1' : temp[3], 'roc_auc' : temp[4]})\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "temp = non_time_series_cv(model)\n",
    "result.append({'model' : str(model), 'acc' : temp[0], 'precision' : temp[1],\n",
    "               'recall' : temp[2], 'f1' : temp[3], 'roc_auc' : temp[4]})\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model = BernoulliNB()\n",
    "temp = non_time_series_cv(model)\n",
    "result.append({'model' : str(model), 'acc' : temp[0], 'precision' : temp[1],\n",
    "               'recall' : temp[2], 'f1' : temp[3], 'roc_auc' : temp[4]})\n",
    "\n",
    "# K nearest neighbor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "temp = non_time_series_cv(model)\n",
    "result.append({'model' : str(model), 'acc' : temp[0], 'precision' : temp[1],\n",
    "               'recall' : temp[2], 'f1' : temp[3], 'roc_auc' : temp[4]})\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()\n",
    "result.append({'model' : str(model), 'acc' : temp[0], 'precision' : temp[1],\n",
    "               'recall' : temp[2], 'f1' : temp[3], 'roc_auc' : temp[4]})\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "temp = non_time_series_cv(model)\n",
    "result.append({'model' : str(model), 'acc' : temp[0], 'precision' : temp[1],\n",
    "               'recall' : temp[2], 'f1' : temp[3], 'roc_auc' : temp[4]})\n",
    "# Gradient boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model = GradientBoostingClassifier()\n",
    "temp = non_time_series_cv(model)\n",
    "result.append({'model' : str(model), 'acc' : temp[0], 'precision' : temp[1],\n",
    "               'recall' : temp[2], 'f1' : temp[3], 'roc_auc' : temp[4]})\n",
    "# Neural network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "model = MLPClassifier(max_iter=1000)\n",
    "temp = non_time_series_cv(model)\n",
    "result.append({'model' : str(model), 'acc' : temp[0], 'precision' : temp[1],\n",
    "               'recall' : temp[2], 'f1' : temp[3], 'roc_auc' : temp[4]})\n",
    "# AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "temp = non_time_series_cv(model)\n",
    "model = AdaBoostClassifier(n_estimators=500, \n",
    "                        random_state=10, s\n",
    "                        learning_rate=0.1)\n",
    "result.append({'model' : str(model), 'acc' : temp[0], 'precision' : temp[1],\n",
    "               'recall' : temp[2], 'f1' : temp[3], 'roc_auc' : temp[4]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80128259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e36e4cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>acc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.771410</td>\n",
       "      <td>0.788014</td>\n",
       "      <td>0.856038</td>\n",
       "      <td>0.820570</td>\n",
       "      <td>0.747371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>0.483635</td>\n",
       "      <td>0.763052</td>\n",
       "      <td>0.224153</td>\n",
       "      <td>0.346155</td>\n",
       "      <td>0.557342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.677490</td>\n",
       "      <td>0.748613</td>\n",
       "      <td>0.710381</td>\n",
       "      <td>0.728956</td>\n",
       "      <td>0.668147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BernoulliNB()</td>\n",
       "      <td>0.681759</td>\n",
       "      <td>0.768362</td>\n",
       "      <td>0.685593</td>\n",
       "      <td>0.724521</td>\n",
       "      <td>0.680670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.659056</td>\n",
       "      <td>0.664553</td>\n",
       "      <td>0.891949</td>\n",
       "      <td>0.761593</td>\n",
       "      <td>0.592901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.659056</td>\n",
       "      <td>0.664553</td>\n",
       "      <td>0.891949</td>\n",
       "      <td>0.761593</td>\n",
       "      <td>0.592901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.747089</td>\n",
       "      <td>0.749543</td>\n",
       "      <td>0.879873</td>\n",
       "      <td>0.809475</td>\n",
       "      <td>0.709372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>0.748771</td>\n",
       "      <td>0.762184</td>\n",
       "      <td>0.855614</td>\n",
       "      <td>0.806143</td>\n",
       "      <td>0.718422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MLPClassifier(max_iter=1000)</td>\n",
       "      <td>0.733571</td>\n",
       "      <td>0.780321</td>\n",
       "      <td>0.784746</td>\n",
       "      <td>0.782432</td>\n",
       "      <td>0.719034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AdaBoostClassifier(learning_rate=0.1, n_estima...</td>\n",
       "      <td>0.732406</td>\n",
       "      <td>0.780573</td>\n",
       "      <td>0.781780</td>\n",
       "      <td>0.781042</td>\n",
       "      <td>0.718382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model       acc  precision  \\\n",
       "0                                              SVC()  0.771410   0.788014   \n",
       "1                                       GaussianNB()  0.483635   0.763052   \n",
       "2                                    MultinomialNB()  0.677490   0.748613   \n",
       "3                                      BernoulliNB()  0.681759   0.768362   \n",
       "4                             KNeighborsClassifier()  0.659056   0.664553   \n",
       "5                           DecisionTreeClassifier()  0.659056   0.664553   \n",
       "6                           RandomForestClassifier()  0.747089   0.749543   \n",
       "7                       GradientBoostingClassifier()  0.748771   0.762184   \n",
       "8                       MLPClassifier(max_iter=1000)  0.733571   0.780321   \n",
       "9  AdaBoostClassifier(learning_rate=0.1, n_estima...  0.732406   0.780573   \n",
       "\n",
       "     recall        f1   roc_auc  \n",
       "0  0.856038  0.820570  0.747371  \n",
       "1  0.224153  0.346155  0.557342  \n",
       "2  0.710381  0.728956  0.668147  \n",
       "3  0.685593  0.724521  0.680670  \n",
       "4  0.891949  0.761593  0.592901  \n",
       "5  0.891949  0.761593  0.592901  \n",
       "6  0.879873  0.809475  0.709372  \n",
       "7  0.855614  0.806143  0.718422  \n",
       "8  0.784746  0.782432  0.719034  \n",
       "9  0.781780  0.781042  0.718382  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result.append({'model' : 'LSTM', 'mean' : 0.75789133})\n",
    "df = pd.DataFrame(result)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "348b7c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>0.483635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.659056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLPClassifier(max_iter=1000)</td>\n",
       "      <td>0.732471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.738422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>0.748448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoostClassifier(learning_rate=0.1, n_estima...</td>\n",
       "      <td>0.752199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.757891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.771410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model      mean\n",
       "1                                       GaussianNB()  0.483635\n",
       "2                             KNeighborsClassifier()  0.659056\n",
       "5                       MLPClassifier(max_iter=1000)  0.732471\n",
       "3                           RandomForestClassifier()  0.738422\n",
       "4                       GradientBoostingClassifier()  0.748448\n",
       "6  AdaBoostClassifier(learning_rate=0.1, n_estima...  0.752199\n",
       "7                                               LSTM  0.757891\n",
       "0                                              SVC()  0.771410"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc82bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7604b07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98403b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427528cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c6ebeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19d0336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b45ef8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "164.985px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

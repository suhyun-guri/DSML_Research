{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b463c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import Dropout, InputLayer, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "\n",
    "from sklearn import metrics \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "#한글설정\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "font_dirs = ['/usr/share/fonts/truetype/nanum', ]\n",
    "font_files = fm.findSystemFonts(fontpaths=font_dirs)\n",
    "\n",
    "for font_file in font_files:\n",
    "    fm.fontManager.addfont(font_file)\n",
    "    \n",
    "# 한글 출력을 위해서 폰트 옵션을 설정합니다.\n",
    "# \"axes.unicode_minus\" : 마이너스가 깨질 것을 방지\n",
    "\n",
    "sns.set(font=\"NanumBarunGothic\",\n",
    "        rc={\"axes.unicode_minus\":False},\n",
    "        style='darkgrid')\n",
    "\n",
    "#GPU 사용 설정, -1이면 CPU 사용\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\"\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:  # gpu가 있다면, 용량 한도를 5GB로 설정\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], \n",
    "                                                            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5*1024)])\n",
    "#     tf.config.experimental.set_virtual_device_configuration(gpus[1], \n",
    "#                                                             [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5*1024)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a14094d",
   "metadata": {},
   "source": [
    "<img src='./data/Method_allfit_Sequential.jpg' width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bb946b",
   "metadata": {},
   "source": [
    "# Training - all fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7c93f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random    \n",
    "seed_num = 42\n",
    "random.seed(seed_num)\n",
    "\n",
    "X = np.load('/project/LSH/x_(7727,10,4068).npy')\n",
    "y = np.load('/project/LSH/y_(7727,1).npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf210557",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_model(gpu_mode=False):\n",
    "    seed_num = 42\n",
    "    tf.random.set_seed(seed_num)\n",
    "    if gpu_mode:\n",
    "        lstm = Sequential()\n",
    "        lstm.add(InputLayer(input_shape=(X.shape[1],X.shape[2])))\n",
    "        lstm.add(CuDNNLSTM(units=128, return_sequences=True))\n",
    "        lstm.add(Activation('hard_sigmoid'))\n",
    "        lstm.add(CuDNNLSTM(units=64, return_sequences=True))\n",
    "        lstm.add(Activation('hard_sigmoid'))\n",
    "        lstm.add(Dropout(0.2))\n",
    "        lstm.add(CuDNNLSTM(units=64, return_sequences=True))\n",
    "        lstm.add(Activation('hard_sigmoid'))\n",
    "        lstm.add(CuDNNLSTM(units=32, return_sequences=False))\n",
    "        lstm.add(Activation('hard_sigmoid'))\n",
    "        lstm.add(Dropout(0.2))\n",
    "        lstm.add(Dense(units=1, activation='sigmoid'))\n",
    "    else:\n",
    "        lstm = Sequential()\n",
    "        lstm.add(InputLayer(input_shape=(x.shape[1],x.shape[2])))\n",
    "        lstm.add(LSTM(units=128, activation='hard_sigmoid', return_sequences=True))\n",
    "        lstm.add(LSTM(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "        lstm.add(Dropout(0.2))\n",
    "        lstm.add(LSTM(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "        lstm.add(LSTM(units=32, activation='hard_sigmoid', return_sequences=False))\n",
    "        lstm.add(Dropout(0.2))\n",
    "        lstm.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    optimizer = Adam(learning_rate = 0.001)\n",
    "    lstm.compile(optimizer=optimizer, loss = \"binary_crossentropy\", metrics=['acc'])\n",
    "    return lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fdb907",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MODEL_SAVE_FOLDER_PATH = './models/'\n",
    "# filepath = MODEL_SAVE_FOLDER_PATH + 'ALLFIT_{epoch:02d}-{val_acc:.4f}.hdf5'\n",
    "# ckpt = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_acc', save_best_only=True, save_weights_only=False, save_freq='epoch')\n",
    "\n",
    "# model = get_model(gpu_mode=False)\n",
    "# early_stop = EarlyStopping(monitor='val_acc', patience=50, verbose=1, restore_best_weights=True)\n",
    "# model.fit(X, y, validation_split=0.25, batch_size=128, epochs=500,  callbacks=[early_stop, ckpt], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6963ccfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./models/ALLFIT_17-0.7645.hdf5')\n",
    "# model = tf.keras.models.load_model('./models/ALLFIT_01-0.4865.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef0c680",
   "metadata": {},
   "source": [
    "## Check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb2e9f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dic={}\n",
    "for seed in range(0, 50, 5):\n",
    "    random.seed(seed)\n",
    "\n",
    "    x = np.load('/project/LSH/x_(7727,10,4068).npy')\n",
    "    y = np.load('/project/LSH/y_(7727,1).npy')\n",
    "\n",
    "    idx = list(range(len(x)))\n",
    "    random.shuffle(idx)\n",
    "\n",
    "    i = round(x.shape[0]*0.8)\n",
    "    X_train, y_train = x[idx[:i],:,:], y[idx[:i]]\n",
    "    X_test, y_test = x[idx[i:],:,:], y[idx[i:]]\n",
    "    \n",
    "    pred = model.predict(X_test)\n",
    "    pred[pred>0.5]=1\n",
    "    pred[pred<=0.5]=0\n",
    "    acc = metrics.accuracy_score(y_test, pred)\n",
    "    dic[seed]=acc\n",
    "    print(f'정확도 :{metrics.accuracy_score(y_test, pred)}, seed_num = {seed}')\n",
    "    \n",
    "df = pd.DataFrame.from_dict(dic, orient='index')\n",
    "print(f'seed = {seed_num}의 정확도 df 만들고 평균 확인 : {df.mean().values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ded473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39283c5a",
   "metadata": {},
   "source": [
    "# Entropy dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0747196d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(ratio_list):\n",
    "    one_ratio, zero_ratio = ratio_list[0], ratio_list[1] \n",
    "    return - ((one_ratio * (np.log2(one_ratio))) + (zero_ratio * (np.log2(zero_ratio))))\n",
    "\n",
    "X = np.load('/project/LSH/x_(7727,10,4068).npy')\n",
    "\n",
    "entropy_dict = {}\n",
    "for i in tqdm(range(len(COLS))):\n",
    "    one_ratio = X[:,:,i].sum() / (X.shape[0]*X.shape[1])\n",
    "    zero_ratio = 1 - one_ratio\n",
    "    entropy_num = entropy([one_ratio, zero_ratio])\n",
    "    entropy_dict[COLS[i]] = entropy_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3624956",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f64a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ab6765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69de2bbd",
   "metadata": {},
   "source": [
    "# 2. {E(0to1) - E(1to0)} * Entropy * Lambda (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5bc82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS = list(pd.read_csv('/project/LSH/total_data_7727.csv')['ITEMID'].sort_values().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fecfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./models/ALLFIT_17-0.7645.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0d3520",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in tqdm(range(X.shape[2])):\n",
    "    save_cols = X[:,:,i].copy()\n",
    "    #-----zero2one-----\n",
    "    X[:,:,i] = 1\n",
    "    pred1 = model.predict(X)\n",
    "    mean_pred1 = np.mean(pred1)\n",
    "    #-----one2zero-----\n",
    "    X[:,:,i] = 0\n",
    "    pred2 = model.predict(X)\n",
    "    mean_pred2 = np.mean(pred2)\n",
    "    \n",
    "    result.append({'feature' : str(COLS[i]), 'one2zero' : mean_pred2,'zero2one' : mean_pred1,\n",
    "                   'lambda0' : mean_pred2 - mean_pred1, 'lambda1' : (mean_pred2 - mean_pred1) * entropy_dict[COLS[i]]})\n",
    "\n",
    "    #값 복원\n",
    "    X[:,:,i] = save_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63196c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result).sort_values('lambda0', ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e401b81c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fbbda9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "489923d3",
   "metadata": {},
   "source": [
    "# 3. Feature Importance - Sequential Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd0d05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10 = []\n",
    "for n in range(10):\n",
    "    if len(top10) > 1:\n",
    "        print(top10)\n",
    "        result = []\n",
    "        for i in tqdm(range(X.shape[2])):\n",
    "            save_cols = X[:,:,top10].copy()\n",
    "            #-----zero2one-----\n",
    "            X[:,:,top10] = 1\n",
    "            pred1 = model.predict(X, batch_size=10000, workers=-1, use_multiprocessing=True)\n",
    "            mean_pred1 = np.mean(pred1)\n",
    "            #-----one2zero-----\n",
    "            X[:,:,top10] = 0\n",
    "            pred2 = model.predict(X, batch_size=10000, workers=-1, use_multiprocessing=True)\n",
    "            mean_pred2 = np.mean(pred2)\n",
    "            result.append({'feature_index' : i, 'one2zero' : mean_pred2,'zero2one' : mean_pred1,\n",
    "                           'lambda0' : mean_pred2 - mean_pred1, 'lambda1' : (mean_pred2 - mean_pred1) * entropy_dict[COLS[i]]})\n",
    "        df = pd.DataFrame(result).sort_values('lambda0', ascending=False)\n",
    "        top10.append(df.feature_index[n])\n",
    "    else:\n",
    "        result = []\n",
    "        for i in tqdm(range(X.shape[2])):\n",
    "            save_cols = X[:,:,i].copy()\n",
    "            #-----zero2one-----\n",
    "            X[:,:,i] = 1\n",
    "            pred1 = model.predict(X, batch_size=10000, workers=-1, use_multiprocessing=True)\n",
    "            mean_pred1 = np.mean(pred1)\n",
    "            #-----one2zero-----\n",
    "            X[:,:,i] = 0\n",
    "            pred2 = model.predict(X, batch_size=10000, workers=-1, use_multiprocessing=True)\n",
    "            mean_pred2 = np.mean(pred2)\n",
    "\n",
    "            result.append({'feature_index' : i, 'one2zero' : mean_pred2,'zero2one' : mean_pred1,\n",
    "                           'lambda0' : mean_pred2 - mean_pred1, 'lambda1' : (mean_pred2 - mean_pred1) * entropy_dict[COLS[i]]})\n",
    "\n",
    "        df = pd.DataFrame(result).sort_values('lambda0', ascending=False)\n",
    "        top10.append(df.feature_index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20eb688",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/Sequential_top10.txt', 'w') as file:\n",
    "    file.write(top10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d053b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139fb8c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75ccee82",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546f6d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization(top10_list):\n",
    "    #-----데이터 로드-----\n",
    "    X = np.load('/project/LSH/x_(7727,10,4068).npy')\n",
    "    y = np.load('/project/LSH/y_(7727,1).npy')\n",
    "    #-----컬럼이름 로드-----\n",
    "    COLS = list(pd.read_csv('/project/LSH/total_data_7727.csv')['ITEMID'].sort_values().unique())\n",
    "    #-----사망/퇴원 환자 분리-----\n",
    "    d_index, s_index = np.where(y==1)[0], np.where(y==0)[0]\n",
    "    d_X, s_X = X[d_index], X[s_index]\n",
    "    result_d, result_s = [], []\n",
    "    #-----사망/퇴원 환자별 item 1의 합계 구하기-----\n",
    "    #day - 10일\n",
    "    for d in range(10):\n",
    "        #4068 - ITEM\n",
    "        for f in range(d_X.shape[-1]):\n",
    "            d_sum = d_X[:,d,f].sum()/d_X.shape[0]\n",
    "            s_sum = s_X[:,d,f].sum()/s_X.shape[0]\n",
    "            result_d.append({'cols':COLS[f], 'day':10-d,'per':d_sum})\n",
    "            result_s.append({'cols':COLS[f], 'day':10-d,'per':s_sum})\n",
    "    #-----최종 합계 df-----\n",
    "    d_df = pd.DataFrame(result_d).sort_values(['cols','day']).reset_index(drop=True)\n",
    "    s_df = pd.DataFrame(result_s).sort_values(['cols','day']).reset_index(drop=True)\n",
    "    #-----Visualization-----\n",
    "    plt.figure(figsize = (13,12), dpi=150)\n",
    "    for i, f in enumerate(top10_list):\n",
    "        plt.subplot(4,3,1+i)\n",
    "        plt.title(f)\n",
    "        ax = sns.lineplot(data = d_df[d_df['cols']==int(f)], x = 'day', y='per', label='사망')\n",
    "        ax = sns.lineplot(data = s_df[s_df['cols']==int(f)], x = 'day', y='per', label='퇴원')\n",
    "        ax.invert_xaxis()\n",
    "        ax.legend(loc='upper left')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396262d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f9b8ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1667f10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256.949px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

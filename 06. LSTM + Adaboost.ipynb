{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bb79b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bde59951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436406b6",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0357c3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6182, 10, 4069), (6182,), (1545, 10, 4069), (1545,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random    \n",
    "seed_num = 48\n",
    "random.seed(seed_num)\n",
    "\n",
    "x = np.load('/project/LSH/x_(7727,10,4069).npy')\n",
    "y = np.load('/project/LSH/y_(7727,1).npy')\n",
    "\n",
    "idx = list(range(len(x)))\n",
    "random.shuffle(idx)\n",
    "\n",
    "i = round(x.shape[0]*0.8)\n",
    "X_train, y_train = x[idx[:i],:,:], y[idx[:i]]\n",
    "X_test, y_test = x[idx[i:],:,:], y[idx[i:]]\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526b2b0a",
   "metadata": {},
   "source": [
    "# Revised KerasClassifier\n",
    "- https://github.com/veniversum/keras/blob/9a401eb2e184fda7238a6259c1b8b02c645e4e9c/keras/wrappers/scikit_learn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f802e9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "293a5e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Wrapper for using the Scikit-Learn API with Keras models.\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import copy\n",
    "import types\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from tensorflow import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils.generic_utils import has_arg\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import BaseWrapper\n",
    "\n",
    "class BaseWrapper(object):\n",
    "    \"\"\"Base class for the Keras scikit-learn wrapper.\n",
    "\n",
    "    Warning: This class should not be used directly.\n",
    "    Use descendant classes instead.\n",
    "\n",
    "    # Arguments\n",
    "        build_fn: callable function or class instance\n",
    "        **sk_params: model parameters & fitting parameters\n",
    "\n",
    "    The `build_fn` should construct, compile and return a Keras model, which\n",
    "    will then be used to fit/predict. One of the following\n",
    "    three values could be passed to `build_fn`:\n",
    "    1. A function\n",
    "    2. An instance of a class that implements the `__call__` method\n",
    "    3. None. This means you implement a class that inherits from either\n",
    "    `KerasClassifier` or `KerasRegressor`. The `__call__` method of the\n",
    "    present class will then be treated as the default `build_fn`.\n",
    "\n",
    "    `sk_params` takes both model parameters and fitting parameters. Legal model\n",
    "    parameters are the arguments of `build_fn`. Note that like all other\n",
    "    estimators in scikit-learn, `build_fn` should provide default values for\n",
    "    its arguments, so that you could create the estimator without passing any\n",
    "    values to `sk_params`.\n",
    "\n",
    "    `sk_params` could also accept parameters for calling `fit`, `predict`,\n",
    "    `predict_proba`, and `score` methods (e.g., `epochs`, `batch_size`).\n",
    "    fitting (predicting) parameters are selected in the following order:\n",
    "\n",
    "    1. Values passed to the dictionary arguments of\n",
    "    `fit`, `predict`, `predict_proba`, and `score` methods\n",
    "    2. Values passed to `sk_params`\n",
    "    3. The default values of the `keras.models.Sequential`\n",
    "    `fit`, `predict`, `predict_proba` and `score` methods\n",
    "\n",
    "    When using scikit-learn's `grid_search` API, legal tunable parameters are\n",
    "    those you could pass to `sk_params`, including fitting parameters.\n",
    "    In other words, you could use `grid_search` to search for the best\n",
    "    `batch_size` or `epochs` as well as the model parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, build_fn=None, **sk_params):\n",
    "        self.build_fn = build_fn\n",
    "        self.sk_params = sk_params\n",
    "        self.check_params(sk_params)\n",
    "\n",
    "    def check_params(self, params):\n",
    "        \"\"\"Checks for user typos in `params`.\n",
    "\n",
    "        # Arguments\n",
    "            params: dictionary; the parameters to be checked\n",
    "\n",
    "        # Raises\n",
    "            ValueError: if any member of `params` is not a valid argument.\n",
    "        \"\"\"\n",
    "        legal_params_fns = [Sequential.fit, Sequential.predict,\n",
    "                            Sequential.predict_classes, Sequential.evaluate]\n",
    "        if self.build_fn is None:\n",
    "            legal_params_fns.append(self.__call__)\n",
    "        elif (not isinstance(self.build_fn, types.FunctionType) and\n",
    "              not isinstance(self.build_fn, types.MethodType)):\n",
    "            legal_params_fns.append(self.build_fn.__call__)\n",
    "        else:\n",
    "            legal_params_fns.append(self.build_fn)\n",
    "\n",
    "        for params_name in params:\n",
    "            for fn in legal_params_fns:\n",
    "                if has_arg(fn, params_name):\n",
    "                    break\n",
    "            else:\n",
    "                if params_name != 'nb_epoch':\n",
    "                    raise ValueError(\n",
    "                        '{} is not a legal parameter'.format(params_name))\n",
    "\n",
    "    def get_params(self, **params):\n",
    "        \"\"\"Gets parameters for this estimator.\n",
    "\n",
    "        # Arguments\n",
    "            **params: ignored (exists for API compatibility).\n",
    "\n",
    "        # Returns\n",
    "            Dictionary of parameter names mapped to their values.\n",
    "        \"\"\"\n",
    "        res = copy.deepcopy(self.sk_params)\n",
    "        res.update({'build_fn': self.build_fn})\n",
    "        return res\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        \"\"\"Sets the parameters of this estimator.\n",
    "\n",
    "        # Arguments\n",
    "            **params: Dictionary of parameter names mapped to their values.\n",
    "\n",
    "        # Returns\n",
    "            self\n",
    "        \"\"\"\n",
    "        self.check_params(params)\n",
    "        self.sk_params.update(params)\n",
    "        return self\n",
    "\n",
    "    def fit(self, x, y, **kwargs):\n",
    "        \"\"\"Constructs a new model with `build_fn` & fit the model to `(x, y)`.\n",
    "\n",
    "        # Arguments\n",
    "            x : array-like, shape `(n_samples, n_features)`\n",
    "                Training samples where `n_samples` is the number of samples\n",
    "                and `n_features` is the number of features.\n",
    "            y : array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n",
    "                True labels for `x`.\n",
    "            **kwargs: dictionary arguments\n",
    "                Legal arguments are the arguments of `Sequential.fit`\n",
    "\n",
    "        # Returns\n",
    "            history : object\n",
    "                details about the training history at each epoch.\n",
    "        \"\"\"\n",
    "        if self.build_fn is None:\n",
    "            self.model = self.__call__(**self.filter_sk_params(self.__call__))\n",
    "        elif (not isinstance(self.build_fn, types.FunctionType) and\n",
    "              not isinstance(self.build_fn, types.MethodType)):\n",
    "            self.model = self.build_fn(\n",
    "                **self.filter_sk_params(self.build_fn.__call__))\n",
    "        else:\n",
    "            self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
    "\n",
    "        loss_name = self.model.loss\n",
    "        if hasattr(loss_name, '__name__'):\n",
    "            loss_name = loss_name.__name__\n",
    "        if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:\n",
    "            y = to_categorical(y)\n",
    "\n",
    "        fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n",
    "        fit_args.update(kwargs)\n",
    "\n",
    "        history = self.model.fit(x, y, **fit_args)\n",
    "\n",
    "        return history\n",
    "\n",
    "    def filter_sk_params(self, fn, override=None):\n",
    "        \"\"\"Filters `sk_params` and returns those in `fn`'s arguments.\n",
    "\n",
    "        # Arguments\n",
    "            fn : arbitrary function\n",
    "            override: dictionary, values to override `sk_params`\n",
    "\n",
    "        # Returns\n",
    "            res : dictionary containing variables\n",
    "                in both `sk_params` and `fn`'s arguments.\n",
    "        \"\"\"\n",
    "        override = override or {}\n",
    "        res = {}\n",
    "        for name, value in self.sk_params.items():\n",
    "            if has_arg(fn, name):\n",
    "                res.update({name: value})\n",
    "        res.update(override)\n",
    "        return res\n",
    "\n",
    "\n",
    "class KerasClassifier(BaseWrapper):\n",
    "    \"\"\"Implementation of the scikit-learn classifier API for Keras.\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, x, y, sample_weight=None, **kwargs):\n",
    "        \"\"\"Constructs a new model with `build_fn` & fit the model to `(x, y)`.\n",
    "\n",
    "        # Arguments\n",
    "            x : array-like, shape `(n_samples, n_features)`\n",
    "                Training samples where `n_samples` is the number of samples\n",
    "                and `n_features` is the number of features.\n",
    "            y : array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n",
    "                True labels for `x`.\n",
    "            **kwargs: dictionary arguments\n",
    "                Legal arguments are the arguments of `Sequential.fit`\n",
    "\n",
    "        # Returns\n",
    "            history : object\n",
    "                details about the training history at each epoch.\n",
    "\n",
    "        # Raises\n",
    "            ValueError: In case of invalid shape for `y` argument.\n",
    "        \"\"\"\n",
    "        y = np.array(y)\n",
    "        if len(y.shape) == 2 and y.shape[1] > 1:\n",
    "            self.classes_ = np.arange(y.shape[1])\n",
    "        elif (len(y.shape) == 2 and y.shape[1] == 1) or len(y.shape) == 1:\n",
    "            self.classes_ = np.unique(y)\n",
    "            y = np.searchsorted(self.classes_, y)\n",
    "        else:\n",
    "            raise ValueError('Invalid shape for y: ' + str(y.shape))\n",
    "        self.n_classes_ = len(self.classes_)\n",
    "        if sample_weight is not None:\n",
    "            kwargs['sample_weight'] = sample_weight\n",
    "        return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
    "\n",
    "    def predict(self, x, **kwargs):\n",
    "        \"\"\"Returns the class predictions for the given test data.\n",
    "\n",
    "        # Arguments\n",
    "            x: array-like, shape `(n_samples, n_features)`\n",
    "                Test samples where `n_samples` is the number of samples\n",
    "                and `n_features` is the number of features.\n",
    "            **kwargs: dictionary arguments\n",
    "                Legal arguments are the arguments\n",
    "                of `Sequential.predict_classes`.\n",
    "\n",
    "        # Returns\n",
    "            preds: array-like, shape `(n_samples,)`\n",
    "                Class predictions.\n",
    "        \"\"\"\n",
    "        kwargs = self.filter_sk_params(Sequential.predict_classes, kwargs)\n",
    "        classes = self.model.predict_classes(x, **kwargs)\n",
    "        return self.classes_[classes]\n",
    "\n",
    "    def predict_proba(self, x, **kwargs):\n",
    "        \"\"\"Returns class probability estimates for the given test data.\n",
    "\n",
    "        # Arguments\n",
    "            x: array-like, shape `(n_samples, n_features)`\n",
    "                Test samples where `n_samples` is the number of samples\n",
    "                and `n_features` is the number of features.\n",
    "            **kwargs: dictionary arguments\n",
    "                Legal arguments are the arguments\n",
    "                of `Sequential.predict_classes`.\n",
    "\n",
    "        # Returns\n",
    "            proba: array-like, shape `(n_samples, n_outputs)`\n",
    "                Class probability estimates.\n",
    "                In the case of binary classification,\n",
    "                to match the scikit-learn API,\n",
    "                will return an array of shape `(n_samples, 2)`\n",
    "                (instead of `(n_sample, 1)` as in Keras).\n",
    "        \"\"\"\n",
    "        kwargs = self.filter_sk_params(Sequential.predict_proba, kwargs)\n",
    "        probs = self.model.predict_proba(x, **kwargs)\n",
    "\n",
    "        # check if binary classification\n",
    "        if probs.shape[1] == 1:\n",
    "            # first column is probability of class 0 and second is of class 1\n",
    "            probs = np.hstack([1 - probs, probs])\n",
    "        return probs\n",
    "\n",
    "    def score(self, x, y, **kwargs):\n",
    "        \"\"\"Returns the mean accuracy on the given test data and labels.\n",
    "\n",
    "        # Arguments\n",
    "            x: array-like, shape `(n_samples, n_features)`\n",
    "                Test samples where `n_samples` is the number of samples\n",
    "                and `n_features` is the number of features.\n",
    "            y: array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n",
    "                True labels for `x`.\n",
    "            **kwargs: dictionary arguments\n",
    "                Legal arguments are the arguments of `Sequential.evaluate`.\n",
    "\n",
    "        # Returns\n",
    "            score: float\n",
    "                Mean accuracy of predictions on `x` wrt. `y`.\n",
    "\n",
    "        # Raises\n",
    "            ValueError: If the underlying model isn't configured to\n",
    "                compute accuracy. You should pass `metrics=[\"accuracy\"]` to\n",
    "                the `.compile()` method of the model.\n",
    "        \"\"\"\n",
    "        y = np.searchsorted(self.classes_, y)\n",
    "        kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n",
    "\n",
    "        loss_name = self.model.loss\n",
    "        if hasattr(loss_name, '__name__'):\n",
    "            loss_name = loss_name.__name__\n",
    "        if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:\n",
    "            y = to_categorical(y)\n",
    "\n",
    "        outputs = self.model.evaluate(x, y, **kwargs)\n",
    "        if not isinstance(outputs, list):\n",
    "            outputs = [outputs]\n",
    "        for name, output in zip(self.model.metrics_names, outputs):\n",
    "            if name == 'acc':\n",
    "                return output\n",
    "        raise ValueError('The model is not configured to compute accuracy. '\n",
    "                         'You should pass `metrics=[\"accuracy\"]` to '\n",
    "                         'the `model.compile()` method.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78723caf",
   "metadata": {},
   "source": [
    "# Apply AdaboostClassifier\n",
    "## adaboost1, get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5783db33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n",
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "seed_num = 42\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Dropout, LSTM, InputLayer\n",
    "from sklearn.ensemble import VotingClassifier, AdaBoostClassifier\n",
    "\n",
    "from sklearn import metrics \n",
    "from tensorflow import keras\n",
    "# from keras.wrappers.scikit_learn import KerasClassifier\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "\n",
    "\n",
    "def get_model(seed_num):\n",
    "    tf.random.set_seed(seed_num)\n",
    "\n",
    "    lstm = Sequential()\n",
    "    lstm.add(InputLayer(input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "    lstm.add(LSTM(units=128, activation='hard_sigmoid', return_sequences=True))\n",
    "    lstm.add(LSTM(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "    lstm.add(Dropout(0.2))\n",
    "    lstm.add(LSTM(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "    lstm.add(LSTM(units=32, activation='hard_sigmoid', return_sequences=False))\n",
    "    lstm.add(Dropout(0.2))\n",
    "    lstm.add(Dense(units=1, activation='sigmoid'))\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = 0.001, decay=0.001)\n",
    "    lstm.compile(optimizer= optimizer, loss = \"binary_crossentropy\", metrics=['acc'], sample_weight_mode = 'temporal')\n",
    "    return lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c8b24f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaboost\n",
    "# GRU_Predictors = KerasClassifier(build_fn=lambda:lstm, epochs=20, batch_size=256)\n",
    "lstm_Predictors = KerasClassifier(build_fn=lambda:get_model(seed_num), epochs=20, batch_size=256)\n",
    "lstm_Predictors._estimator_type=\"classifier\"\n",
    "final_model = AdaBoostClassifier(lstm_Predictors, n_estimators=100, random_state=42, learning_rate=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c80c227",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 92ms/step - loss: 1.1015e-04 - acc: 0.5919\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 1.1018e-04 - acc: 0.5950\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 1.0948e-04 - acc: 0.5992\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 1.0941e-04 - acc: 0.5958\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 1.0933e-04 - acc: 0.5953\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 95ms/step - loss: 1.0905e-04 - acc: 0.6043\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 95ms/step - loss: 1.0952e-04 - acc: 0.5982\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 93ms/step - loss: 1.0943e-04 - acc: 0.6032\n",
      "Epoch 9/20\n",
      "10/25 [===========>..................] - ETA: 1s - loss: 1.0966e-04 - acc: 0.5984"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0miboost\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;31m# Boosting step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             sample_weight, estimator_weight, estimator_error = self._boost(\n\u001b[0m\u001b[1;32m    146\u001b[0m                 \u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \"\"\"\n\u001b[1;32m    547\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"SAMME.R\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-b2226260ee2e>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-b2226260ee2e>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "final_model.fit(X_train,y_train, sample_weight=np.ones(X_train.shape[0])/X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a02e74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971efe0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e83d2bbb",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AdaBoostClassifier' object has no attribute 'n_classes_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-40c745b4a78f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'정확도 :'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m         \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m         \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AdaBoostClassifier' object has no attribute 'n_classes_'"
     ]
    }
   ],
   "source": [
    "preds = final_model.predict(X_test)\n",
    "preds[preds>0.5] = 1\n",
    "preds[preds<=0.5] = 0\n",
    "from sklearn import metrics\n",
    "print('정확도 :', metrics.accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8c4630",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcb28af",
   "metadata": {},
   "source": [
    "## adaboost 2\n",
    "- 참고한 github\n",
    "- https://github.com/limitless083/timeseries-forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65139810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def calc_error(y, y_):\n",
    "    return np.sqrt((y - y_) ** 2)\n",
    "\n",
    "\n",
    "class AdaBoost:\n",
    "    def __init__(self, trainX, trainY):\n",
    "        self.trainX = trainX\n",
    "        self.trainY = trainY\n",
    "        self.N = len(self.trainX)\n",
    "        self.weights = np.ones(self.N) / self.N\n",
    "        self.alphas = []\n",
    "        self.models = []\n",
    "\n",
    "    def set_rule(self, model):\n",
    "        predict = model.predict(self.trainX)\n",
    "        errors = []\n",
    "        for i in range(self.N):\n",
    "            errors.append(self.weights[i] * calc_error(self.trainY[i], predict[i, 0]))\n",
    "        e = np.sum(errors)\n",
    "        alpha = 0.5 * np.log((1 - e) / e)\n",
    "        print('e=%.4f a=%.4f' % (e, alpha))\n",
    "        w = np.zeros(self.N)\n",
    "        for i in range(self.N):\n",
    "            w[i] = self.weights[i] * np.exp(alpha * errors[i] / e)\n",
    "        self.weights = w / w.sum()\n",
    "        self.models.append(model)\n",
    "        self.alphas.append(alpha)\n",
    "\n",
    "    def predict(self, x_set):\n",
    "        n_models = len(self.models)\n",
    "        alpha_sum = np.sum(self.alphas)\n",
    "        final_predict = np.zeros(1)\n",
    "        for i in range(n_models):\n",
    "            predict = self.models[i].predict(x_set)\n",
    "            final_predict = final_predict + predict[:, 0] * self.alphas[i]\n",
    "        final_predict = final_predict / alpha_sum\n",
    "\n",
    "        return final_predict.reshape(len(x_set), 1)\n",
    "\n",
    "    def evaluate(self):\n",
    "        n_models = len(self.models)\n",
    "        alpha_sum = np.sum(self.alphas)\n",
    "        final_predict = np.zeros(len(self.trainX))\n",
    "        for i in range(n_models):\n",
    "            predict = self.models[i].predict(self.trainX)\n",
    "            final_predict = final_predict + predict[:, 0] * self.alphas[i]\n",
    "        final_predict = final_predict / alpha_sum\n",
    "        errors = []\n",
    "        for i in range(self.N):\n",
    "            errors.append(calc_error(self.trainY[i], final_predict[i]))\n",
    "        return np.sum(errors)\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78447586",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "40/40 - 5s - loss: 1.0949e-04 - acc: 0.5925\n",
      "Epoch 2/20\n",
      "40/40 - 3s - loss: 1.0935e-04 - acc: 0.5979\n",
      "Epoch 3/20\n",
      "40/40 - 3s - loss: 1.0992e-04 - acc: 0.5959\n",
      "Epoch 4/20\n",
      "40/40 - 3s - loss: 1.0989e-04 - acc: 0.6000\n",
      "Epoch 5/20\n",
      "40/40 - 3s - loss: 1.0933e-04 - acc: 0.5951\n",
      "Epoch 6/20\n",
      "40/40 - 3s - loss: 1.0938e-04 - acc: 0.5995\n",
      "Epoch 7/20\n",
      "40/40 - 3s - loss: 1.0936e-04 - acc: 0.6014\n",
      "Epoch 8/20\n",
      "40/40 - 3s - loss: 1.0958e-04 - acc: 0.6000\n",
      "Epoch 9/20\n",
      "40/40 - 3s - loss: 1.0910e-04 - acc: 0.6011\n",
      "Epoch 10/20\n",
      "40/40 - 3s - loss: 1.0926e-04 - acc: 0.6029\n",
      "Epoch 11/20\n",
      "40/40 - 3s - loss: 1.0906e-04 - acc: 0.6026\n",
      "Epoch 12/20\n",
      "40/40 - 3s - loss: 1.0922e-04 - acc: 0.6064\n",
      "Epoch 13/20\n",
      "40/40 - 3s - loss: 1.0903e-04 - acc: 0.6032\n",
      "Epoch 14/20\n",
      "40/40 - 3s - loss: 1.0909e-04 - acc: 0.6042\n",
      "Epoch 15/20\n",
      "40/40 - 3s - loss: 1.0904e-04 - acc: 0.6035\n",
      "Epoch 16/20\n",
      "40/40 - 3s - loss: 1.0910e-04 - acc: 0.6042\n",
      "Epoch 17/20\n",
      "40/40 - 3s - loss: 1.0886e-04 - acc: 0.6058\n",
      "Epoch 18/20\n",
      "40/40 - 3s - loss: 1.0883e-04 - acc: 0.6045\n",
      "Epoch 19/20\n",
      "40/40 - 3s - loss: 1.0904e-04 - acc: 0.6038\n",
      "Epoch 20/20\n",
      "40/40 - 3s - loss: 1.0888e-04 - acc: 0.6060\n",
      "e=0.4778 a=0.0444\n",
      "final error:  2953.856681569422\n"
     ]
    }
   ],
   "source": [
    "adaboost = AdaBoost(X_train, y_train)\n",
    "for i in range(1):\n",
    "    sample_weights = adaboost.get_weights()\n",
    "    model = get_model(seed_num)\n",
    "    model.fit(X_train, y_train, epochs=20, batch_size=156, verbose=2, sample_weight=sample_weights)\n",
    "    adaboost.set_rule(model)\n",
    "print(\"final error: \", adaboost.evaluate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3f8c687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6284789644012945"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred[pred>0.5] = 1; pred[pred<=0.5] = 0\n",
    "metrics.accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c57f61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f562a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23a8518a",
   "metadata": {},
   "source": [
    "## adaboost 3\n",
    "- 참고한 자료\n",
    "- https://stackoverflow.com/questions/64558810/how-to-use-a-keras-model-inside-of-sklearns-adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df3f0555",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyKerasClassifier(KerasClassifier):\n",
    "    def fit(self, x, y, sample_weight=None, **kwargs):\n",
    "        y = np.array(y)\n",
    "        if len(y.shape) == 2 and y.shape[1] > 1:\n",
    "            self.classes_ = np.arange(y.shape[1])\n",
    "        elif (len(y.shape) == 2 and y.shape[1] == 1) or len(y.shape) == 1:\n",
    "            self.classes_ = np.unique(y)\n",
    "            y = np.searchsorted(self.classes_, y)\n",
    "        else:\n",
    "            raise ValueError('Invalid shape for y: ' + str(y.shape))\n",
    "        self.n_classes_ = len(self.classes_)\n",
    "        if sample_weight is not None:\n",
    "            kwargs['sample_weight'] = sample_weight\n",
    "            print(type(sample_weight))\n",
    "        return super(MyKerasClassifier, self).fit(x, y, **kwargs)\n",
    "    def predict(self, x, **kwargs):\n",
    "        kwargs = self.filter_sk_params(Sequential.predict_classes, kwargs)\n",
    "        classes = self.model.predict_classes(x, **kwargs)\n",
    "        return self.classes_[classes].flatten()\n",
    "        #return super(KerasClassifier, self).fit(x, y, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a8fa9fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Epoch 1/20\n",
      "40/40 - 16s - loss: 1.0959e-04 - acc: 0.5932\n",
      "Epoch 2/20\n",
      "40/40 - 3s - loss: 1.0909e-04 - acc: 0.6030\n",
      "Epoch 3/20\n",
      "40/40 - 3s - loss: 1.0925e-04 - acc: 0.5992\n",
      "Epoch 4/20\n",
      "40/40 - 3s - loss: 1.0919e-04 - acc: 0.6030\n",
      "Epoch 5/20\n",
      "40/40 - 3s - loss: 1.0931e-04 - acc: 0.5982\n",
      "Epoch 6/20\n",
      "40/40 - 3s - loss: 1.0895e-04 - acc: 0.6050\n",
      "Epoch 7/20\n",
      "40/40 - 3s - loss: 1.0938e-04 - acc: 0.6053\n",
      "Epoch 8/20\n",
      "40/40 - 3s - loss: 1.0933e-04 - acc: 0.6006\n",
      "Epoch 9/20\n",
      "40/40 - 3s - loss: 1.0891e-04 - acc: 0.6050\n",
      "Epoch 10/20\n",
      "40/40 - 3s - loss: 1.0880e-04 - acc: 0.6056\n",
      "Epoch 11/20\n",
      "40/40 - 3s - loss: 1.0915e-04 - acc: 0.6038\n",
      "Epoch 12/20\n",
      "40/40 - 3s - loss: 1.0866e-04 - acc: 0.6060\n",
      "Epoch 13/20\n",
      "40/40 - 3s - loss: 1.0878e-04 - acc: 0.6051\n",
      "Epoch 14/20\n",
      "40/40 - 3s - loss: 1.0874e-04 - acc: 0.6066\n",
      "Epoch 15/20\n",
      "40/40 - 3s - loss: 1.0881e-04 - acc: 0.6058\n",
      "Epoch 16/20\n",
      "40/40 - 3s - loss: 1.0876e-04 - acc: 0.6056\n",
      "Epoch 17/20\n",
      "40/40 - 3s - loss: 1.0860e-04 - acc: 0.6061\n",
      "Epoch 18/20\n",
      "40/40 - 3s - loss: 1.0867e-04 - acc: 0.6058\n",
      "Epoch 19/20\n",
      "40/40 - 3s - loss: 1.0877e-04 - acc: 0.6064\n",
      "Epoch 20/20\n",
      "40/40 - 3s - loss: 1.0859e-04 - acc: 0.6061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 - 2s\n",
      "<class 'numpy.ndarray'>\n",
      "Epoch 1/20\n",
      "40/40 - 6s - loss: 1.1402e-04 - acc: 0.5325\n",
      "Epoch 2/20\n",
      "40/40 - 3s - loss: 1.1279e-04 - acc: 0.5209\n",
      "Epoch 3/20\n",
      "40/40 - 3s - loss: 1.1291e-04 - acc: 0.4982\n",
      "Epoch 4/20\n",
      "40/40 - 3s - loss: 1.1285e-04 - acc: 0.5045\n",
      "Epoch 5/20\n",
      "40/40 - 3s - loss: 1.1300e-04 - acc: 0.4995\n",
      "Epoch 6/20\n",
      "40/40 - 3s - loss: 1.1267e-04 - acc: 0.5055\n",
      "Epoch 7/20\n",
      "40/40 - 3s - loss: 1.1306e-04 - acc: 0.5152\n",
      "Epoch 8/20\n",
      "40/40 - 3s - loss: 1.1295e-04 - acc: 0.4934\n",
      "Epoch 9/20\n",
      "40/40 - 3s - loss: 1.1261e-04 - acc: 0.4913\n",
      "Epoch 10/20\n",
      "40/40 - 3s - loss: 1.1251e-04 - acc: 0.5333\n",
      "Epoch 11/20\n",
      "40/40 - 3s - loss: 1.1283e-04 - acc: 0.4948\n",
      "Epoch 12/20\n",
      "40/40 - 3s - loss: 1.1232e-04 - acc: 0.5210\n",
      "Epoch 13/20\n",
      "40/40 - 3s - loss: 1.1250e-04 - acc: 0.5160\n",
      "Epoch 14/20\n",
      "40/40 - 3s - loss: 1.1236e-04 - acc: 0.5134\n",
      "Epoch 15/20\n",
      "40/40 - 3s - loss: 1.1250e-04 - acc: 0.5070\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d45ffe294336>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mboosted_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mboosted_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0miboost\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;31m# Boosting step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             sample_weight, estimator_weight, estimator_error = self._boost(\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \"\"\"\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SAMME.R'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-f4a4bc5199e2>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMyKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_sk_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-12bca8c9feae>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-12bca8c9feae>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "base_estimator = MyKerasClassifier(build_fn=lambda:get_model(seed_num), epochs=20, batch_size=156, verbose=2)\n",
    "boosted_classifier = AdaBoostClassifier(base_estimator=base_estimator,n_estimators=10,random_state=42)\n",
    "\n",
    "boosted_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee15040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "boosted_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b92b47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bd344f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb5e31c4",
   "metadata": {},
   "source": [
    "# Apply VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df643139",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('model1', <__main__.KerasClassifier object at 0x7f2a1231eee0>), ('model2', <__main__.KerasClassifier object at 0x7f2a1231efd0>), ('model3', <__main__.KerasClassifier object at 0x7f2a1231e1c0>), ('model4', <__main__.KerasClassifier object at 0x7f2a1231e250>), ('model5', <__main__.KerasClassifier object at 0x7f2a1231e400>), ('model6', <__main__.KerasClassifier object at 0x7f2a1231eeb0>), ('model7', <__main__.KerasClassifier object at 0x7f2a1231e910>), ('model8', <__main__.KerasClassifier object at 0x7f2a12324190>), ('model9', <__main__.KerasClassifier object at 0x7f2a123248b0>), ('model10', <__main__.KerasClassifier object at 0x7f2a12324880>)]\n"
     ]
    }
   ],
   "source": [
    "# voting\n",
    "# GRU_Predictors = KerasClassifier(build_fn=lambda:lstm, epochs=20, batch_size=256)\n",
    "# lstm_Predictors = KerasClassifier(build_fn=lambda:get_model(seed_num), epochs=20, batch_size=256)\n",
    "#LSTM 쌓기\n",
    "estimator = []\n",
    "for i in range(1,11):\n",
    "    LSTM_Predictors = KerasClassifier(build_fn=lambda:get_model(None), epochs=20, batch_size=256)\n",
    "    LSTM_Predictors._estimator_type=\"classifier\"\n",
    "    estimator.append((f'model{i}', LSTM_Predictors))\n",
    "print(estimator) \n",
    "voting_model = VotingClassifier(estimators=estimator, voting = 'soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c5bf7c94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 89ms/step - loss: 0.6960 - acc: 0.5524\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 87ms/step - loss: 0.6756 - acc: 0.5996\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 88ms/step - loss: 0.6735 - acc: 0.5962\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 86ms/step - loss: 0.6398 - acc: 0.6212\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.5548 - acc: 0.7260\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.4901 - acc: 0.7810\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.4339 - acc: 0.8140\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.3994 - acc: 0.8326\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.3748 - acc: 0.8505\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.3459 - acc: 0.8688\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.3255 - acc: 0.8766\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.3212 - acc: 0.8829\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.2912 - acc: 0.8940\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.2853 - acc: 0.9005\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.2643 - acc: 0.9110\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.2479 - acc: 0.9183\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.2392 - acc: 0.9191\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.2267 - acc: 0.9283\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.2139 - acc: 0.9327\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.2159 - acc: 0.9321\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 8s 90ms/step - loss: 0.7313 - acc: 0.5290\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 88ms/step - loss: 0.6809 - acc: 0.5806\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 88ms/step - loss: 0.6721 - acc: 0.6013\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 88ms/step - loss: 0.6725 - acc: 0.5980\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 87ms/step - loss: 0.6509 - acc: 0.6127\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.5828 - acc: 0.6870\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.4989 - acc: 0.7853\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.4462 - acc: 0.8122\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.4151 - acc: 0.8302\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.3846 - acc: 0.8478\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.3637 - acc: 0.8636\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.3446 - acc: 0.8738\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.3355 - acc: 0.8754\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.3065 - acc: 0.8952\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.2904 - acc: 0.9034\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.3048 - acc: 0.8919\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.2771 - acc: 0.9089\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 88ms/step - loss: 0.2629 - acc: 0.9183\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.2646 - acc: 0.9135\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 87ms/step - loss: 0.2510 - acc: 0.9230\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 90ms/step - loss: 0.6791 - acc: 0.5869\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.6739 - acc: 0.6006\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.6639 - acc: 0.6042\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.5941 - acc: 0.6897\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.5049 - acc: 0.7688\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 93ms/step - loss: 0.4529 - acc: 0.7997\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.4220 - acc: 0.8213\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.3872 - acc: 0.8444\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.3645 - acc: 0.8544\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.3376 - acc: 0.8709\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.3239 - acc: 0.8806\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 93ms/step - loss: 0.3041 - acc: 0.8889\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.2922 - acc: 0.8916\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.2763 - acc: 0.9038\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.2586 - acc: 0.9096\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.2408 - acc: 0.9199\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.2344 - acc: 0.9232\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.2131 - acc: 0.9330\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.2082 - acc: 0.9358\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.2090 - acc: 0.9308\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 92ms/step - loss: 0.6789 - acc: 0.5916\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.6751 - acc: 0.6043\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 88ms/step - loss: 0.6723 - acc: 0.6055\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.6333 - acc: 0.6446\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.5240 - acc: 0.7561\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.4647 - acc: 0.7889\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.4326 - acc: 0.8117\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.3952 - acc: 0.8350\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.3762 - acc: 0.8445\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.3439 - acc: 0.8641\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.3305 - acc: 0.8703\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.3122 - acc: 0.8834\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.2919 - acc: 0.8934\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.2793 - acc: 0.9016\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.2578 - acc: 0.9151\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.2456 - acc: 0.9169\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.2367 - acc: 0.9253\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.2236 - acc: 0.9269\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.2379 - acc: 0.9201\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.2505 - acc: 0.9039\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 9s 91ms/step - loss: 0.6862 - acc: 0.5836\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.6748 - acc: 0.5979\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.6672 - acc: 0.6064\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 88ms/step - loss: 0.6176 - acc: 0.6543\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 88ms/step - loss: 0.5187 - acc: 0.7561\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.4530 - acc: 0.8039\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 2s 91ms/step - loss: 0.4151 - acc: 0.8213\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.3837 - acc: 0.8442\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.3642 - acc: 0.8505\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.3366 - acc: 0.8714\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.3229 - acc: 0.8801\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 93ms/step - loss: 0.2991 - acc: 0.8932\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.2816 - acc: 0.9015\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.2895 - acc: 0.8926\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.2657 - acc: 0.9088\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.2431 - acc: 0.9191\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.2312 - acc: 0.9236\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.2267 - acc: 0.9264\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.2115 - acc: 0.9361\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 88ms/step - loss: 0.2055 - acc: 0.9387\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 91ms/step - loss: 0.6788 - acc: 0.5971\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.6726 - acc: 0.6056\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.6696 - acc: 0.6043\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 88ms/step - loss: 0.6247 - acc: 0.6399\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 88ms/step - loss: 0.5178 - acc: 0.7606\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.4493 - acc: 0.8022\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.4128 - acc: 0.8259\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.3913 - acc: 0.8348\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.3627 - acc: 0.8520\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.3462 - acc: 0.8623\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.3208 - acc: 0.8784\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.3073 - acc: 0.8860\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.2995 - acc: 0.8855\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.2793 - acc: 0.9004\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.2607 - acc: 0.9123\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.2484 - acc: 0.9175\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.2440 - acc: 0.9164\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.2342 - acc: 0.9217\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.2146 - acc: 0.9322\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 88ms/step - loss: 0.2013 - acc: 0.9395\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 6s 93ms/step - loss: 0.6890 - acc: 0.5730\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.6779 - acc: 0.5954\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.6710 - acc: 0.6050\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.6451 - acc: 0.6145\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 88ms/step - loss: 0.5566 - acc: 0.7300\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.4747 - acc: 0.7913\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.4338 - acc: 0.8154\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.4123 - acc: 0.8261\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.3748 - acc: 0.8479\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.3563 - acc: 0.8593\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.3349 - acc: 0.8716\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.3139 - acc: 0.8868\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.2911 - acc: 0.8999\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.2796 - acc: 0.9049\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.2697 - acc: 0.9099\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.2536 - acc: 0.9151\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.2386 - acc: 0.9238\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.2241 - acc: 0.9291\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.2181 - acc: 0.9342\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.2160 - acc: 0.9309\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 91ms/step - loss: 0.6846 - acc: 0.5764\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.6759 - acc: 0.6005\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 88ms/step - loss: 0.6708 - acc: 0.6035\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.6350 - acc: 0.6349\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 88ms/step - loss: 0.5303 - acc: 0.7511\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.4553 - acc: 0.7989\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.4179 - acc: 0.8230\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.3882 - acc: 0.8376\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.3719 - acc: 0.8475\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.3420 - acc: 0.8653\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.3186 - acc: 0.8808\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.3051 - acc: 0.8915\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.2902 - acc: 0.8981\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.2739 - acc: 0.9050\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.2644 - acc: 0.9086\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.2439 - acc: 0.9204\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.2309 - acc: 0.9243\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.2219 - acc: 0.9287\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.2108 - acc: 0.9329\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.2179 - acc: 0.9282\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 92ms/step - loss: 0.6779 - acc: 0.5956\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.6725 - acc: 0.6050\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.6710 - acc: 0.6060\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.6382 - acc: 0.6242\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.5397 - acc: 0.7383\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.4715 - acc: 0.7892\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.4324 - acc: 0.8109\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.3980 - acc: 0.8353\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.3743 - acc: 0.8491\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.3446 - acc: 0.8664\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.3303 - acc: 0.8771\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.3123 - acc: 0.8873\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 2s 91ms/step - loss: 0.3083 - acc: 0.8864\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.2877 - acc: 0.8957\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 93ms/step - loss: 0.2817 - acc: 0.8999\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.2586 - acc: 0.9131\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 88ms/step - loss: 0.2447 - acc: 0.9190\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 88ms/step - loss: 0.2369 - acc: 0.9258\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 88ms/step - loss: 0.2423 - acc: 0.9191\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 88ms/step - loss: 0.2297 - acc: 0.9232\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 6s 92ms/step - loss: 0.7077 - acc: 0.5385\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.6801 - acc: 0.5859\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.6765 - acc: 0.5977\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 91ms/step - loss: 0.6703 - acc: 0.6000\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.6360 - acc: 0.6195\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 94ms/step - loss: 0.5493 - acc: 0.7410\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.4768 - acc: 0.7983\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 93ms/step - loss: 0.4462 - acc: 0.8140\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.4070 - acc: 0.8329\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.3769 - acc: 0.8533\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 94ms/step - loss: 0.3530 - acc: 0.8677\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 94ms/step - loss: 0.3320 - acc: 0.8793\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 93ms/step - loss: 0.3183 - acc: 0.8871\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 95ms/step - loss: 0.2965 - acc: 0.9016\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 94ms/step - loss: 0.2780 - acc: 0.9102\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.2764 - acc: 0.9065\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.2618 - acc: 0.9162\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 88ms/step - loss: 0.2586 - acc: 0.9164\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.2378 - acc: 0.9264\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.2296 - acc: 0.9325\n",
      "CPU times: user 5h 36min 28s, sys: 47min 10s, total: 6h 23min 39s\n",
      "Wall time: 8min 16s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('model1',\n",
       "                              <__main__.KerasClassifier object at 0x7f2a1231eee0>),\n",
       "                             ('model2',\n",
       "                              <__main__.KerasClassifier object at 0x7f2a1231efd0>),\n",
       "                             ('model3',\n",
       "                              <__main__.KerasClassifier object at 0x7f2a1231e1c0>),\n",
       "                             ('model4',\n",
       "                              <__main__.KerasClassifier object at 0x7f2a1231e250>),\n",
       "                             ('model5',\n",
       "                              <__main__.KerasClassifier object at 0x7f2a1231e400>),\n",
       "                             ('model6',\n",
       "                              <__main__.KerasClassifier object at 0x7f2a1231eeb0>),\n",
       "                             ('model7',\n",
       "                              <__main__.KerasClassifier object at 0x7f2a1231e910>),\n",
       "                             ('model8',\n",
       "                              <__main__.KerasClassifier object at 0x7f2a12324190>),\n",
       "                             ('model9',\n",
       "                              <__main__.KerasClassifier object at 0x7f2a123248b0>),\n",
       "                             ('model10',\n",
       "                              <__main__.KerasClassifier object at 0x7f2a12324880>)],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "voting_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c504e750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guri99/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:430: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.7715210355987056\n"
     ]
    }
   ],
   "source": [
    "preds = voting_model.predict(X_test)\n",
    "from sklearn import metrics\n",
    "print('정확도 :', metrics.accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ace675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18c65ae4",
   "metadata": {},
   "source": [
    "# Adaboost-GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5433d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_num = 48\n",
    "def get_gru_model(seed_num):\n",
    "    tf.random.set_seed(seed_num)\n",
    "\n",
    "    gru = Sequential()\n",
    "    gru.add(InputLayer(input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "    gru.add(GRU(units=128, activation='hard_sigmoid', return_sequences=True))\n",
    "    gru.add(GRU(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "    gru.add(Dropout(0.2))\n",
    "    gru.add(GRU(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "    gru.add(GRU(units=32, activation='hard_sigmoid', return_sequences=False))\n",
    "    gru.add(Dropout(0.2))\n",
    "    gru.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    gru.compile(optimizer= \"adam\", loss = \"binary_crossentropy\", metrics=['acc'])\n",
    "    return gru\n",
    "\n",
    "# adaboost\n",
    "# GRU_Predictors = KerasClassifier(build_fn=lambda:gru, epochs=20, batch_size=256)\n",
    "gru_Predictors = KerasClassifier(build_fn=lambda:get_gru_model(seed_num), epochs=20, batch_size=256)\n",
    "gru_model = AdaBoostClassifier(gru_Predictors, n_estimators=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "57883fc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 73ms/step - loss: 1.1196e-04 - acc: 0.5808\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1028e-04 - acc: 0.5911\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1036e-04 - acc: 0.5858\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1049e-04 - acc: 0.5904\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1094e-04 - acc: 0.5820\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.0939e-04 - acc: 0.5893\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.0990e-04 - acc: 0.5938\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1004e-04 - acc: 0.5930\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1012e-04 - acc: 0.5943\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.0929e-04 - acc: 0.6065\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.0902e-04 - acc: 0.6070\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.0977e-04 - acc: 0.5926\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 1.0889e-04 - acc: 0.6091\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.0931e-04 - acc: 0.6003\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.0972e-04 - acc: 0.6009\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.0909e-04 - acc: 0.6022\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.0884e-04 - acc: 0.6055\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.0945e-04 - acc: 0.5999\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.0890e-04 - acc: 0.6064\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.0817e-04 - acc: 0.6131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 74ms/step - loss: 1.1916e-04 - acc: 0.5625\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1438e-04 - acc: 0.4882\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1424e-04 - acc: 0.5040\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1437e-04 - acc: 0.5045\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1482e-04 - acc: 0.4828\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1316e-04 - acc: 0.5082\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1378e-04 - acc: 0.5064\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1391e-04 - acc: 0.4710\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1379e-04 - acc: 0.4917\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1325e-04 - acc: 0.5208\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 1.1289e-04 - acc: 0.5037\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1338e-04 - acc: 0.4832\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1283e-04 - acc: 0.5207\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1302e-04 - acc: 0.4976\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1335e-04 - acc: 0.5153\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1280e-04 - acc: 0.4985\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1259e-04 - acc: 0.5105\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1313e-04 - acc: 0.5102\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 1.1262e-04 - acc: 0.5204\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1198e-04 - acc: 0.4967\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 74ms/step - loss: 1.1918e-04 - acc: 0.5622\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1438e-04 - acc: 0.4876\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1425e-04 - acc: 0.5036\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1437e-04 - acc: 0.5032\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1483e-04 - acc: 0.4823\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1316e-04 - acc: 0.5073\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1379e-04 - acc: 0.5065\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1392e-04 - acc: 0.4683\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1379e-04 - acc: 0.4902\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1325e-04 - acc: 0.5185\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1289e-04 - acc: 0.5004\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1339e-04 - acc: 0.4845\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1284e-04 - acc: 0.5205\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1302e-04 - acc: 0.4956\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1335e-04 - acc: 0.5144\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1280e-04 - acc: 0.4956\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1259e-04 - acc: 0.5076\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1313e-04 - acc: 0.5079\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 1.1262e-04 - acc: 0.5189\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1199e-04 - acc: 0.4939\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 73ms/step - loss: 1.1918e-04 - acc: 0.5622\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1438e-04 - acc: 0.4876\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1425e-04 - acc: 0.5036\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1437e-04 - acc: 0.5032\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1483e-04 - acc: 0.4823\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1316e-04 - acc: 0.5073\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1379e-04 - acc: 0.5065\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1392e-04 - acc: 0.4683\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1379e-04 - acc: 0.4902\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1325e-04 - acc: 0.5185\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1289e-04 - acc: 0.5004\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1339e-04 - acc: 0.4845\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1284e-04 - acc: 0.5205\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1302e-04 - acc: 0.4956\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1335e-04 - acc: 0.5144\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1280e-04 - acc: 0.4956\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1259e-04 - acc: 0.5075\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1313e-04 - acc: 0.5079\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1262e-04 - acc: 0.5189\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1199e-04 - acc: 0.4939\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 6s 75ms/step - loss: 1.1918e-04 - acc: 0.5622\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1438e-04 - acc: 0.4876\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1425e-04 - acc: 0.5036\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1437e-04 - acc: 0.5032\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1483e-04 - acc: 0.4823\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1316e-04 - acc: 0.5073\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1379e-04 - acc: 0.5065\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1392e-04 - acc: 0.4683\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1379e-04 - acc: 0.4902\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1325e-04 - acc: 0.5185\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1289e-04 - acc: 0.5004\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1339e-04 - acc: 0.4845\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1284e-04 - acc: 0.5205\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1302e-04 - acc: 0.4956\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1335e-04 - acc: 0.5144\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1280e-04 - acc: 0.4956\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1259e-04 - acc: 0.5075\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1313e-04 - acc: 0.5079\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1262e-04 - acc: 0.5189\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 1.1199e-04 - acc: 0.4939\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 73ms/step - loss: 1.1918e-04 - acc: 0.5622\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1438e-04 - acc: 0.4876\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1425e-04 - acc: 0.5036\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1437e-04 - acc: 0.5032\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1483e-04 - acc: 0.4823\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1316e-04 - acc: 0.5073\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1379e-04 - acc: 0.5065\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1392e-04 - acc: 0.4683\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1380e-04 - acc: 0.4902\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1325e-04 - acc: 0.5185\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1289e-04 - acc: 0.5004\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1339e-04 - acc: 0.4845\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1284e-04 - acc: 0.5205\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1302e-04 - acc: 0.4956\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1335e-04 - acc: 0.5144\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1280e-04 - acc: 0.4956\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1259e-04 - acc: 0.5075\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1313e-04 - acc: 0.5079\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1262e-04 - acc: 0.5189\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1199e-04 - acc: 0.4939\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 72ms/step - loss: 1.1918e-04 - acc: 0.5622\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1438e-04 - acc: 0.4876\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1425e-04 - acc: 0.5036\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1437e-04 - acc: 0.5032\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1483e-04 - acc: 0.4823\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1316e-04 - acc: 0.5073\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1379e-04 - acc: 0.5065\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1392e-04 - acc: 0.4683\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1380e-04 - acc: 0.4902\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1325e-04 - acc: 0.5185\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1289e-04 - acc: 0.5004\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1339e-04 - acc: 0.4845\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 1.1284e-04 - acc: 0.5205\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1302e-04 - acc: 0.4956\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1335e-04 - acc: 0.5144\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1280e-04 - acc: 0.4956\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1259e-04 - acc: 0.5076\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1313e-04 - acc: 0.5079\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 1.1262e-04 - acc: 0.5190\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1199e-04 - acc: 0.4939\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 73ms/step - loss: 1.1918e-04 - acc: 0.5622\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1438e-04 - acc: 0.4876\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1425e-04 - acc: 0.5036\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1437e-04 - acc: 0.5032\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1483e-04 - acc: 0.4823\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1316e-04 - acc: 0.5073\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1379e-04 - acc: 0.5065\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1392e-04 - acc: 0.4683\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1380e-04 - acc: 0.4902\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1325e-04 - acc: 0.5185\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1289e-04 - acc: 0.5004\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1339e-04 - acc: 0.4845\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1284e-04 - acc: 0.5205\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1302e-04 - acc: 0.4956\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1335e-04 - acc: 0.5144\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1280e-04 - acc: 0.4956\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1259e-04 - acc: 0.5076\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1313e-04 - acc: 0.5079\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 1.1262e-04 - acc: 0.5190\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 1.1199e-04 - acc: 0.4939\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 73ms/step - loss: 1.1918e-04 - acc: 0.5622\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1438e-04 - acc: 0.4876\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1425e-04 - acc: 0.5036\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1437e-04 - acc: 0.5032\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1483e-04 - acc: 0.4823\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1316e-04 - acc: 0.5073\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1379e-04 - acc: 0.5065\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1392e-04 - acc: 0.4683\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 1.1380e-04 - acc: 0.4902\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 1.1325e-04 - acc: 0.5185\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1289e-04 - acc: 0.5004\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1339e-04 - acc: 0.4845\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1284e-04 - acc: 0.5205\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 1.1302e-04 - acc: 0.4956\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1335e-04 - acc: 0.5144\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1280e-04 - acc: 0.4956\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1259e-04 - acc: 0.5076\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1313e-04 - acc: 0.5079\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 1.1262e-04 - acc: 0.5190\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 1.1199e-04 - acc: 0.4939\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 74ms/step - loss: 1.1918e-04 - acc: 0.5622\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1438e-04 - acc: 0.4876\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1425e-04 - acc: 0.5036\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1437e-04 - acc: 0.5032\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1483e-04 - acc: 0.4823\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1316e-04 - acc: 0.5073\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1379e-04 - acc: 0.5065\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1392e-04 - acc: 0.4683\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1380e-04 - acc: 0.4902\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1325e-04 - acc: 0.5185\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1289e-04 - acc: 0.5004\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1339e-04 - acc: 0.4845\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1284e-04 - acc: 0.5205\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.1302e-04 - acc: 0.4956\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.1335e-04 - acc: 0.5144\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1280e-04 - acc: 0.4956\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1.1259e-04 - acc: 0.5076\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.1313e-04 - acc: 0.5079\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1.1262e-04 - acc: 0.5190\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 1.1199e-04 - acc: 0.4939\n",
      "CPU times: user 4h 40min 2s, sys: 42min 40s, total: 5h 22min 43s\n",
      "Wall time: 7min 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=<__main__.KerasClassifier object at 0x7f3a133592b0>,\n",
       "                   n_estimators=10, random_state=42)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "gru_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc1c042d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.6284789644012945\n"
     ]
    }
   ],
   "source": [
    "preds = gru_model.predict(X_test)\n",
    "preds[preds>0.5] = 1\n",
    "preds[preds<=0.5] = 0\n",
    "from sklearn import metrics\n",
    "print('정확도 :', metrics.accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2788da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2a2aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bdf705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41fcf2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b42b7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ef9fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd423d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25606137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "164.974px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
